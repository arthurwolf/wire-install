[16:31:51] # Logging to: wire-install-2021-Aug-12-16-31-51.log in log/ and tmp/
[16:31:51] # Shutting down virtual machine "Wire Demo Client Clone"
[16:31:51] # Deleting virtual machine "Wire Demo Client Clone"
[16:31:52] # Creating virtual machine "Wire Demo Client Clone" from snapshot
[16:31:53] # Starting virtual machine "Wire Demo Client Clone"
[16:32:03] # Initial install of tmux on 192.168.1.121
[16:32:13] # Running command «sudo date --set="Thu Aug 12 2021 16:31:56 GMT+0200 (Central European Summer Time)"» on 192.168.1.121
        wire@wire-client:~$ sudo date --set="Thu Aug 12 2021 16:31:56 GMT+0200 (Central
        European Summer Time)"
        [sudo] password for wire:
        Thu Aug 12 14:31:56 UTC 2021
[16:32:14] # Initial install of tmux on 95.216.208.159
[16:32:23] # Running command «sudo date --set="Thu Aug 12 2021 16:32:13 GMT+0200 (Central European Summer Time)"» on 95.216.208.159
        wire@arthur-demo:~$ sudo date --set="Thu Aug 12 2021 16:32:13 GMT+0200 (Central
        European Summer Time)"
        [sudo] password for wire:
        Thu Aug 12 16:32:13 CEST 2021
[16:32:29] # Running command «cat /proc/cpuinfo | grep processor | wc -l» on 192.168.1.121
        wire@wire-client:~$ cat /proc/cpuinfo | grep processor | wc -l
        2
[16:32:35] # Running command «free -m && uptime» on 192.168.1.121
        wire@wire-client:~$ free -m && uptime
                      total        used        free      shared  buff/cache   available
        Mem:           2928         114        2612           0         201        2668
        Swap:          3943           0        3943
         14:32:17 up 2 min,  0 users,  load average: 0.61, 0.35, 0.13
[16:32:40] # Running command «cat /proc/cpuinfo | grep processor | wc -l» on 95.216.208.159
        wire@arthur-demo:~$ cat /proc/cpuinfo | grep processor | wc -l
        8
[16:32:45] # Running command «free -m && uptime» on 95.216.208.159
        wire@arthur-demo:~$ free -m && uptime
                      total        used        free      shared  buff/cache   available
        Mem:          15661         106       15407           0         147       15316
        Swap:             0           0           0
         16:32:42 up 9 min,  0 users,  load average: 0.00, 0.00, 0.00
[16:32:50] # Running command «cd» on 192.168.1.121
        wire@wire-client:~$ cd
[16:32:56] # Running command «cat /etc/hostname» on 192.168.1.121
        wire@wire-client:~$ cat /etc/hostname
        wire-client
[16:33:02] # Running command «pwd» on 192.168.1.121
        wire@wire-client:~$ pwd
        /home/wire
[16:33:08] # Running command «date» on 192.168.1.121
        wire@wire-client:~$ date
        Thu Aug 12 14:33:05 UTC 2021
[16:33:14] # Running command «uptime» on 192.168.1.121
        wire@wire-client:~$ uptime
         14:33:11 up 2 min,  0 users,  load average: 0.31, 0.30, 0.13
[16:33:37] # Running command «sudo apt update» on 192.168.1.121
        wire@wire-client:~$ sudo apt update
        [sudo] password for wire:
        Hit:1 http://fr.archive.ubuntu.com/ubuntu bionic InRelease
        Get:2 http://fr.archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]
        Get:3 http://fr.archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]
        Get:4 http://fr.archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]
        Get:5 http://fr.archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [21
        65 kB]
        Get:6 http://fr.archive.ubuntu.com/ubuntu bionic-updates/main Translation-en [42
        7 kB]
        Get:7 http://fr.archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packag
        es [418 kB]
        Get:8 http://fr.archive.ubuntu.com/ubuntu bionic-updates/restricted Translation-
        en [56.8 kB]
        Get:9 http://fr.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages
         [1744 kB]
        Get:10 http://fr.archive.ubuntu.com/ubuntu bionic-updates/universe Translation-e
        n [373 kB]
        Get:11 http://fr.archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packa
        ges [30.9 kB]
        Get:12 http://fr.archive.ubuntu.com/ubuntu bionic-updates/multiverse Translation
        -en [6988 B]
        Get:13 http://fr.archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [
        1818 kB]
        Get:14 http://fr.archive.ubuntu.com/ubuntu bionic-security/main Translation-en [
        335 kB]
        Get:15 http://fr.archive.ubuntu.com/ubuntu bionic-security/restricted amd64 Pack
        ages [394 kB]
        Get:16 http://fr.archive.ubuntu.com/ubuntu bionic-security/restricted Translatio
        n-en [53.0 kB]
        Get:17 http://fr.archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packag
        es [1133 kB]
        Get:18 http://fr.archive.ubuntu.com/ubuntu bionic-security/universe Translation-
        en [257 kB]
        Get:19 http://fr.archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 Pack
        ages [20.9 kB]
        Get:20 http://fr.archive.ubuntu.com/ubuntu bionic-security/multiverse Translatio
        n-en [4732 B]
        Fetched 9491 kB in 4s (2453 kB/s)
        Reading package lists... Done
        Building dependency tree
        Reading state information... Done
        81 packages can be upgraded. Run 'apt list --upgradable' to see them.
[16:34:50] # Running command «sudo dpkg --configure -a» on 192.168.1.121
        wire@wire-client:~$ sudo dpkg --configure -a
        Setting up initramfs-tools (0.130ubuntu3.9) ...
        update-initramfs: deferring update (trigger activated)
        Processing triggers for initramfs-tools (0.130ubuntu3.9) ...
        update-initramfs: Generating /boot/initrd.img-4.15.0-144-generic
[16:36:32] # Running command «sudo apt install docker.io» on 192.168.1.121
        wire@wire-client:~$ sudo apt install docker.io
        Reading package lists... Done
        Building dependency tree
        Reading state information... Done
        The following additional packages will be installed:
          bridge-utils containerd pigz runc ubuntu-fan
        Suggested packages:
          ifupdown aufs-tools cgroupfs-mount | cgroup-lite debootstrap docker-doc rinse zfs-fuse | zfsutils
        The following NEW packages will be installed:
          bridge-utils containerd docker.io pigz runc ubuntu-fan
        0 upgraded, 6 newly installed, 0 to remove and 81 not upgraded.
        Need to get 74.0 MB of archives.
        After this operation, 359 MB of additional disk space will be used.
        Do you want to continue? [Y/n] y
        Get:1 http://fr.archive.ubuntu.com/ubuntu bionic/universe amd64 pigz amd64 2.4-1 [57.4 kB]
        Get:2 http://fr.archive.ubuntu.com/ubuntu bionic/main amd64 bridge-utils amd64 1.5-15ubuntu1 [30.1 kB]
        Get:3 http://fr.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 runc amd64 1.0.0~rc95-0ubuntu1~18.04.2 [4087 kB]
        Get:4 http://fr.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 containerd amd64 1.5.2-0ubuntu1~18.04.2 [32.9 MB]
        Get:5 http://fr.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 docker.io amd64 20.10.7-0ubuntu1~18.04.1 [36.9 MB]
        Get:6 http://fr.archive.ubuntu.com/ubuntu bionic/main amd64 ubuntu-fan all 0.12.10 [34.7 kB]
        Fetched 74.0 MB in 14s (5445 kB/s)
        Preconfiguring packages ...
        Selecting previously unselected package pigz.
        (Reading database ... 67143 files and directories currently installed.)
        Preparing to unpack .../0-pigz_2.4-1_amd64.deb ...
        Unpacking pigz (2.4-1) ...
        Selecting previously unselected package bridge-utils.
        Preparing to unpack .../1-bridge-utils_1.5-15ubuntu1_amd64.deb ...
        Unpacking bridge-utils (1.5-15ubuntu1) ...
        Selecting previously unselected package runc.
        Preparing to unpack .../2-runc_1.0.0~rc95-0ubuntu1~18.04.2_amd64.deb ...
        Unpacking runc (1.0.0~rc95-0ubuntu1~18.04.2) ...
        Selecting previously unselected package containerd.
        Preparing to unpack .../3-containerd_1.5.2-0ubuntu1~18.04.2_amd64.deb ...
        Unpacking containerd (1.5.2-0ubuntu1~18.04.2) ...
        Selecting previously unselected package docker.io.
        Preparing to unpack .../4-docker.io_20.10.7-0ubuntu1~18.04.1_amd64.deb ...
        Unpacking docker.io (20.10.7-0ubuntu1~18.04.1) ...
        Selecting previously unselected package ubuntu-fan.
        Preparing to unpack .../5-ubuntu-fan_0.12.10_all.deb ...
        Unpacking ubuntu-fan (0.12.10) ...
        Setting up runc (1.0.0~rc95-0ubuntu1~18.04.2) ...
        Setting up containerd (1.5.2-0ubuntu1~18.04.2) ...
        Created symlink /etc/systemd/system/multi-user.target.wants/containerd.service → /lib/systemd/system/containerd.service.
        Setting up bridge-utils (1.5-15ubuntu1) ...
        Setting up ubuntu-fan (0.12.10) ...
        Created symlink /etc/systemd/system/multi-user.target.wants/ubuntu-fan.service → /lib/systemd/system/ubuntu-fan.service.
        Setting up pigz (2.4-1) ...
        Setting up docker.io (20.10.7-0ubuntu1~18.04.1) ...
        Adding group `docker' (GID 113) ...
        Done.
        Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /lib/systemd/system/docker.service.
        Created symlink /etc/systemd/system/sockets.target.wants/docker.socket → /lib/systemd/system/docker.socket.
        Processing triggers for systemd (237-3ubuntu10.42) ...
        Processing triggers for man-db (2.8.3-2ubuntu0.1) ...
        Processing triggers for ureadahead (0.100.0-21) ...
[16:36:38] # Running command «docker -v» on 192.168.1.121
        wire@wire-client:~$ docker -v
        Docker version 20.10.7, build 20.10.7-0ubuntu1~18.04.1
[16:36:44] # Running command «sudo rm -rf /home/wire/wire*» on 192.168.1.121
        wire@wire-client:~$ sudo rm -rf /home/wire/wire*
[16:36:50] # Running command «ls -l /home/wire/» on 192.168.1.121
        wire@wire-client:~$ ls -l /home/wire/
        total 0
[16:36:56] # Running command «date» on 192.168.1.121
        wire@wire-client:~$ date
        Thu Aug 12 14:36:53 UTC 2021
[16:37:01] # Running command «uptime» on 192.168.1.121
        wire@wire-client:~$ uptime
         14:36:59 up 6 min,  1 user,  load average: 0.85, 0.71, 0.34
[16:37:11] # Running command «sudo apt update» on 192.168.1.121
        wire@wire-client:~$ sudo apt update
        Hit:1 http://fr.archive.ubuntu.com/ubuntu bionic InRelease
        Hit:2 http://fr.archive.ubuntu.com/ubuntu bionic-updates InRelease
        Hit:3 http://fr.archive.ubuntu.com/ubuntu bionic-backports InRelease
        Hit:4 http://fr.archive.ubuntu.com/ubuntu bionic-security InRelease
        Reading package lists... Done
        Building dependency tree
        Reading state information... Done
        81 packages can be upgraded. Run 'apt list --upgradable' to see them.
[16:37:17] # Running command «sudo dpkg --configure -a» on 192.168.1.121
        wire@wire-client:~$ sudo dpkg --configure -a
[16:37:22] # Running command «date» on 95.216.208.159
        wire@arthur-demo:~$ date
        Thu Aug 12 16:37:19 CEST 2021
[16:37:27] # Running command «uptime» on 95.216.208.159
        wire@arthur-demo:~$ uptime
         16:37:24 up 14 min,  0 users,  load average: 0.00, 0.00, 0.00
[16:37:50] # Running command «sudo apt update» on 95.216.208.159
        wire@arthur-demo:~$ sudo apt update
        Get:1 http://mirror.hetzner.de/ubuntu/packages bionic InRelease [242 kB]
        Get:2 https://mirror.hetzner.com/ubuntu/packages bionic InRelease [242 kB]
        Get:3 http://mirror.hetzner.de/ubuntu/packages bionic-updates InRelease [88.7 kB
        ]
        Get:4 http://mirror.hetzner.de/ubuntu/packages bionic-backports InRelease [74.6
        kB]
        Get:5 http://mirror.hetzner.de/ubuntu/packages bionic-security InRelease [88.7 k
        B]
        Get:6 https://mirror.hetzner.com/ubuntu/packages bionic-updates InRelease [88.7
        kB]
        Get:7 https://mirror.hetzner.com/ubuntu/packages bionic-backports InRelease [74.
        6 kB]
        Get:8 https://mirror.hetzner.com/ubuntu/security bionic-security InRelease [88.7
         kB]
        Get:9 http://mirror.hetzner.de/ubuntu/packages bionic/main i386 Packages [1,007
        kB]
        Get:10 http://mirror.hetzner.de/ubuntu/packages bionic/main amd64 Packages [1,01
        9 kB]
        Get:11 http://mirror.hetzner.de/ubuntu/packages bionic/main Translation-en [516
        kB]
        Get:12 http://mirror.hetzner.de/ubuntu/packages bionic/restricted i386 Packages
        [9,156 B]
        Get:13 http://mirror.hetzner.de/ubuntu/packages bionic/restricted amd64 Packages
         [9,184 B]
        Get:14 http://mirror.hetzner.de/ubuntu/packages bionic/restricted Translation-en
         [3,584 B]
        Get:15 http://mirror.hetzner.de/ubuntu/packages bionic/universe i386 Packages [8
        ,531 kB]
        Get:16 http://mirror.hetzner.de/ubuntu/packages bionic/universe amd64 Packages [
        8,570 kB]
        Get:17 http://mirror.hetzner.de/ubuntu/packages bionic/universe Translation-en [
        4,941 kB]
        Get:18 http://mirror.hetzner.de/ubuntu/packages bionic/multiverse i386 Packages
        [144 kB]
        Get:19 http://mirror.hetzner.de/ubuntu/packages bionic/multiverse amd64 Packages
         [151 kB]
        Get:20 http://mirror.hetzner.de/ubuntu/packages bionic/multiverse Translation-en
         [108 kB]
        Get:21 http://mirror.hetzner.de/ubuntu/packages bionic-updates/main amd64 Packag
        es [2,165 kB]
        Get:22 http://mirror.hetzner.de/ubuntu/packages bionic-updates/main i386 Package
        s [1,327 kB]
        Get:23 https://mirror.hetzner.com/ubuntu/packages bionic/main i386 Packages [1,0
        07 kB]
        Get:24 http://mirror.hetzner.de/ubuntu/packages bionic-updates/main Translation-
        en [427 kB]
        Get:25 http://mirror.hetzner.de/ubuntu/packages bionic-updates/restricted i386 P
        ackages [27.2 kB]
        Get:26 http://mirror.hetzner.de/ubuntu/packages bionic-updates/restricted amd64
        Packages [418 kB]
        Get:27 http://mirror.hetzner.de/ubuntu/packages bionic-updates/restricted Transl
        ation-en [56.8 kB]
        Get:28 http://mirror.hetzner.de/ubuntu/packages bionic-updates/universe i386 Pac
        kages [1,572 kB]
        Get:29 http://mirror.hetzner.de/ubuntu/packages bionic-updates/universe amd64 Pa
        ckages [1,744 kB]
        Get:30 http://mirror.hetzner.de/ubuntu/packages bionic-updates/universe Translat
        ion-en [373 kB]
        Get:31 http://mirror.hetzner.de/ubuntu/packages bionic-updates/multiverse i386 P
        ackages [13.0 kB]
        Get:32 http://mirror.hetzner.de/ubuntu/packages bionic-updates/multiverse amd64
        Packages [30.9 kB]
        Get:33 http://mirror.hetzner.de/ubuntu/packages bionic-updates/multiverse Transl
        ation-en [6,988 B]
        Get:34 http://mirror.hetzner.de/ubuntu/packages bionic-backports/main i386 Packa
        ges [10.0 kB]
        Get:35 http://mirror.hetzner.de/ubuntu/packages bionic-backports/main amd64 Pack
        ages [10.0 kB]
        Get:36 http://mirror.hetzner.de/ubuntu/packages bionic-backports/main Translatio
        n-en [4,764 B]
        Get:37 http://mirror.hetzner.de/ubuntu/packages bionic-backports/universe amd64
        Packages [10.3 kB]
        Get:38 http://mirror.hetzner.de/ubuntu/packages bionic-backports/universe i386 P
        ackages [10.3 kB]
        Get:39 http://mirror.hetzner.de/ubuntu/packages bionic-backports/universe Transl
        ation-en [4,588 B]
        Get:40 http://mirror.hetzner.de/ubuntu/packages bionic-security/main i386 Packag
        es [1,023 kB]
        Get:41 https://mirror.hetzner.com/ubuntu/packages bionic/main amd64 Packages [1,
        019 kB]
        Get:42 http://mirror.hetzner.de/ubuntu/packages bionic-security/main amd64 Packa
        ges [1,818 kB]
        Get:43 https://mirror.hetzner.com/ubuntu/packages bionic/main Translation-en [51
        6 kB]
        Get:44 http://mirror.hetzner.de/ubuntu/packages bionic-security/main Translation
        -en [335 kB]
        Get:45 http://mirror.hetzner.de/ubuntu/packages bionic-security/restricted i386
        Packages [20.6 kB]
        Get:46 http://mirror.hetzner.de/ubuntu/packages bionic-security/restricted amd64
         Packages [394 kB]
        Get:47 http://mirror.hetzner.de/ubuntu/packages bionic-security/restricted Trans
        lation-en [53.0 kB]
        Get:48 http://mirror.hetzner.de/ubuntu/packages bionic-security/universe i386 Pa
        ckages [984 kB]
        Get:49 https://mirror.hetzner.com/ubuntu/packages bionic/restricted amd64 Packag
        es [9,184 B]
        Get:50 https://mirror.hetzner.com/ubuntu/packages bionic/restricted i386 Package
        s [9,156 B]
        Get:51 https://mirror.hetzner.com/ubuntu/packages bionic/restricted Translation-
        en [3,584 B]
        Get:52 https://mirror.hetzner.com/ubuntu/packages bionic/universe amd64 Packages
         [8,570 kB]
        Get:53 http://mirror.hetzner.de/ubuntu/packages bionic-security/universe amd64 P
        ackages [1,133 kB]
        Get:54 http://mirror.hetzner.de/ubuntu/packages bionic-security/universe Transla
        tion-en [257 kB]
        Get:55 http://mirror.hetzner.de/ubuntu/packages bionic-security/multiverse amd64
         Packages [20.9 kB]
        Get:56 http://mirror.hetzner.de/ubuntu/packages bionic-security/multiverse i386
        Packages [6,480 B]
        Get:57 http://mirror.hetzner.de/ubuntu/packages bionic-security/multiverse Trans
        lation-en [4,732 B]
        Get:58 https://mirror.hetzner.com/ubuntu/packages bionic/universe i386 Packages
        [8,531 kB]
        Get:59 https://mirror.hetzner.com/ubuntu/packages bionic/universe Translation-en
         [4,941 kB]
        Get:60 https://mirror.hetzner.com/ubuntu/packages bionic/multiverse amd64 Packag
        es [151 kB]
        Get:61 https://mirror.hetzner.com/ubuntu/packages bionic/multiverse i386 Package
        s [144 kB]
        Get:62 https://mirror.hetzner.com/ubuntu/packages bionic/multiverse Translation-
        en [108 kB]
        Get:63 https://mirror.hetzner.com/ubuntu/packages bionic-updates/main i386 Packa
        ges [1,327 kB]
        Get:64 https://mirror.hetzner.com/ubuntu/packages bionic-updates/main amd64 Pack
        ages [2,165 kB]
        Get:65 https://mirror.hetzner.com/ubuntu/packages bionic-updates/main Translatio
        n-en [427 kB]
        Get:66 https://mirror.hetzner.com/ubuntu/packages bionic-updates/restricted amd6
        4 Packages [418 kB]
        Get:67 https://mirror.hetzner.com/ubuntu/packages bionic-updates/restricted i386
         Packages [27.2 kB]
        Get:68 https://mirror.hetzner.com/ubuntu/packages bionic-updates/restricted Tran
        slation-en [56.8 kB]
        Get:69 https://mirror.hetzner.com/ubuntu/packages bionic-updates/universe amd64
        Packages [1,744 kB]
        Get:70 https://mirror.hetzner.com/ubuntu/packages bionic-updates/universe i386 P
        ackages [1,572 kB]
        Get:71 https://mirror.hetzner.com/ubuntu/packages bionic-updates/universe Transl
        ation-en [373 kB]
        Get:72 https://mirror.hetzner.com/ubuntu/packages bionic-updates/multiverse amd6
        4 Packages [30.9 kB]
        Get:73 https://mirror.hetzner.com/ubuntu/packages bionic-updates/multiverse i386
         Packages [13.0 kB]
        Get:74 https://mirror.hetzner.com/ubuntu/packages bionic-updates/multiverse Tran
        slation-en [6,988 B]
        Get:75 https://mirror.hetzner.com/ubuntu/packages bionic-backports/main i386 Pac
        kages [10.0 kB]
        Get:76 https://mirror.hetzner.com/ubuntu/packages bionic-backports/main amd64 Pa
        ckages [10.0 kB]
        Get:77 https://mirror.hetzner.com/ubuntu/packages bionic-backports/main Translat
        ion-en [4,764 B]
        Get:78 https://mirror.hetzner.com/ubuntu/packages bionic-backports/universe amd6
        4 Packages [10.3 kB]
        Get:79 https://mirror.hetzner.com/ubuntu/packages bionic-backports/universe i386
         Packages [10.3 kB]
        Get:80 https://mirror.hetzner.com/ubuntu/packages bionic-backports/universe Tran
        slation-en [4,588 B]
        Get:81 https://mirror.hetzner.com/ubuntu/security bionic-security/main amd64 Pac
        kages [1,818 kB]
        Get:82 https://mirror.hetzner.com/ubuntu/security bionic-security/main i386 Pack
        ages [1,023 kB]
        Get:83 https://mirror.hetzner.com/ubuntu/security bionic-security/main Translati
        on-en [335 kB]
        Get:84 https://mirror.hetzner.com/ubuntu/security bionic-security/restricted amd
        64 Packages [394 kB]
        Get:85 https://mirror.hetzner.com/ubuntu/security bionic-security/restricted i38
        6 Packages [20.6 kB]
        Get:86 https://mirror.hetzner.com/ubuntu/security bionic-security/restricted Tra
        nslation-en [53.0 kB]
        Get:87 https://mirror.hetzner.com/ubuntu/security bionic-security/universe amd64
         Packages [1,133 kB]
        Get:88 https://mirror.hetzner.com/ubuntu/security bionic-security/universe i386
        Packages [984 kB]
        Get:89 https://mirror.hetzner.com/ubuntu/security bionic-security/universe Trans
        lation-en [257 kB]
        Get:90 https://mirror.hetzner.com/ubuntu/security bionic-security/multiverse amd
        64 Packages [20.9 kB]
        Get:91 https://mirror.hetzner.com/ubuntu/security bionic-security/multiverse i38
        6 Packages [6,480 B]
        Get:92 https://mirror.hetzner.com/ubuntu/security bionic-security/multiverse Tra
        nslation-en [4,732 B]
        Fetched 79.5 MB in 14s (5,847 kB/s)
        Reading package lists... Done
        Building dependency tree
        Reading state information... Done
        18 packages can be upgraded. Run 'apt list --upgradable' to see them.
[16:37:55] # Running command «sudo dpkg --configure -a» on 95.216.208.159
        wire@arthur-demo:~$ sudo dpkg --configure -a
[16:38:02] # Running command «sudo apt install docker.io» on 192.168.1.121
        wire@wire-client:~$ sudo apt install docker.io
        Reading package lists... Done
        Building dependency tree
        Reading state information... Done
        docker.io is already the newest version (20.10.7-0ubuntu1~18.04.1).
        0 upgraded, 0 newly installed, 0 to remove and 81 not upgraded.
[16:38:08] # Running command «docker -v» on 192.168.1.121
        wire@wire-client:~$ docker -v
        Docker version 20.10.7, build 20.10.7-0ubuntu1~18.04.1
[16:38:17] # Running command «git clone --branch master https://github.com/wireapp/wire-server-deploy.git» on 192.168.1.121
        wire@wire-client:~$ git clone --branch master https://github.com/wireapp/wire-server-deploy.git
        Cloning into 'wire-server-deploy'...
        remote: Enumerating objects: 18510, done.
        remote: Counting objects: 100% (343/343), done.
        remote: Compressing objects: 100% (217/217), done.
        remote: Total 18510 (delta 170), reused 239 (delta 120), pack-reused 18167
        Receiving objects: 100% (18510/18510), 2.20 MiB | 2.45 MiB/s, done.
        Resolving deltas: 100% (13826/13826), done.
[16:38:23] # Running command «ls -l» on 192.168.1.121
        wire@wire-client:~$ ls -l
        total 4
        drwxrwxr-x 12 wire wire 4096 Aug 12 14:38 wire-server-deploy
[16:38:29] # Running command «cd ~/wire-server-deploy» on 192.168.1.121
        wire@wire-client:~$ cd ~/wire-server-deploy
[16:38:35] # Running command «pwd» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ pwd
        /home/wire/wire-server-deploy
[16:38:41] # Running command «ls -l» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ ls -l
        total 108
        -rw-rw-r--  1 wire wire 16072 Aug 12 14:38 CHANGELOG.md
        -rw-rw-r--  1 wire wire  1531 Aug 12 14:38 CONTRIBUTING.md
        -rw-rw-r--  1 wire wire   252 Aug 12 14:38 Dockerfile
        -rw-rw-r--  1 wire wire 34520 Aug 12 14:38 LICENSE
        -rw-rw-r--  1 wire wire  5893 Aug 12 14:38 Makefile
        -rw-rw-r--  1 wire wire  2251 Aug 12 14:38 README.md
        drwxrwxr-x  9 wire wire  4096 Aug 12 14:38 ansible
        drwxrwxr-x  3 wire wire  4096 Aug 12 14:38 bin
        -rw-rw-r--  1 wire wire  2338 Aug 12 14:38 default.nix
        drwxrwxr-x  5 wire wire  4096 Aug 12 14:38 examples
        drwxrwxr-x  2 wire wire  4096 Aug 12 14:38 helm
        drwxrwxr-x  4 wire wire  4096 Aug 12 14:38 nix
        drwxrwxr-x  2 wire wire  4096 Aug 12 14:38 offline
        drwxrwxr-x  5 wire wire  4096 Aug 12 14:38 terraform
        drwxrwxr-x 15 wire wire  4096 Aug 12 14:38 values
[16:39:09] # Running command «git submodule update --init --recursive» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ git submodule update --init --recursive
        Submodule 'ansible/roles-external/ANXS.apt' (https://github.com/ANXS/apt.git) registered for path 'ansible/roles-external/ANXS.apt'
        Submodule 'ansible/roles-external/admin_users' (https://github.com/cchurch/ansible-role-admin-users.git) registered for path 'ansible/roles-external/admin_users'
        Submodule 'ansible/roles-external/andrewrothstein.unarchive-deps' (https://github.com/andrewrothstein/ansible-unarchive-deps) registered for path 'ansible/roles-external/andrewrothstein.unarchive-deps'
        Submodule 'ansible/roles-external/ansible-cassandra' (https://github.com/wireapp/ansible-cassandra.git) registered for path 'ansible/roles-external/ansible-cassandra'
        Submodule 'ansible/roles-external/ansible-minio' (https://github.com/wireapp/ansible-minio.git) registered for path 'ansible/roles-external/ansible-minio'
        Submodule 'ansible/roles-external/ansible-ntp-verify' (https://github.com/wireapp/ansible-ntp-verify.git) registered for path 'ansible/roles-external/ansible-ntp-verify'
        Submodule 'ansible/roles-external/ansible-restund' (https://github.com/wireapp/ansible-restund.git) registered for path 'ansible/roles-external/ansible-restund'
        Submodule 'ansible/roles-external/ansible-role-java' (https://github.com/geerlingguy/ansible-role-java.git) registered for path 'ansible/roles-external/ansible-role-java'
        Submodule 'ansible/roles-external/ansible-role-ntp' (https://github.com/geerlingguy/ansible-role-ntp.git) registered for path 'ansible/roles-external/ansible-role-ntp'
        Submodule 'ansible/roles-external/ansible-tinc' (https://github.com/wireapp/ansible-tinc.git) registered for path 'ansible/roles-external/ansible-tinc'
        Submodule 'ansible/roles-external/cloudalchemy.node-exporter' (https://github.com/cloudalchemy/ansible-node-exporter) registered for path 'ansible/roles-external/cloudalchemy.node-exporter'
        Submodule 'ansible/roles-external/elasticsearch' (https://github.com/elastic/ansible-elasticsearch.git) registered for path 'ansible/roles-external/elasticsearch'
        Submodule 'ansible/roles-external/hostname' (https://github.com/ANXS/hostname.git) registered for path 'ansible/roles-external/hostname'
        Submodule 'ansible/roles-external/kubespray' (https://github.com/kubernetes-sigs/kubespray.git) registered for path 'ansible/roles-external/kubespray'
        Submodule 'ansible/roles-external/logrotate' (https://github.com/nickhammond/ansible-logrotate.git) registered for path 'ansible/roles-external/logrotate'
        Submodule 'ansible/roles-external/sft' (https://github.com/wireapp/ansible-sft.git) registered for path 'ansible/roles-external/sft'
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/ANXS.apt'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/admin_users'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/andrewrothstein.unarchive-deps'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/ansible-cassandra'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/ansible-minio'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/ansible-ntp-verify'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/ansible-restund'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/ansible-role-java'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/ansible-role-ntp'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/ansible-tinc'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/cloudalchemy.node-exporter'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/elasticsearch'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/hostname'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/kubespray'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/logrotate'...
        Cloning into '/home/wire/wire-server-deploy/ansible/roles-external/sft'...
        Submodule path 'ansible/roles-external/ANXS.apt': checked out 'f602ba7e88abfbb3af6679a8ca47207dc3e9d9c4'
        Submodule path 'ansible/roles-external/admin_users': checked out 'd5bcef7e925ee1acf4e42359f0a95ed788eea58f'
        Submodule path 'ansible/roles-external/andrewrothstein.unarchive-deps': checked out '4485543262cfe04170d1ec02c8ccb95c44a7a222'
        Submodule path 'ansible/roles-external/ansible-cassandra': checked out '8a0f029f533856e8270d7fd74d75c099a677b2e3'
        Submodule path 'ansible/roles-external/ansible-minio': checked out '22ab28f75c007a0c48dc47db574773773ef19d22'
        Submodule path 'ansible/roles-external/ansible-ntp-verify': checked out '4c3d0c67d32d2d74444f4db45b2a4d2efdc7d590'
        Submodule path 'ansible/roles-external/ansible-restund': checked out '9807313a7c72ffa40e74f69d239404fd87db65ab'
        Submodule path 'ansible/roles-external/ansible-role-java': checked out '13b427055702d9e91558cad7dcccab7db91e5663'
        Submodule path 'ansible/roles-external/ansible-role-ntp': checked out 'af1ec62385c899a3e3f24407d8417adcdc9eea60'
        Submodule path 'ansible/roles-external/ansible-tinc': checked out '42951a951f6381e387174178bf3bff228b6a5dc5'
        Submodule path 'ansible/roles-external/cloudalchemy.node-exporter': checked out '8dc13ae077e3da1a71c268b114cd4fb8103ced80'
        Submodule path 'ansible/roles-external/elasticsearch': checked out '389a3ff45f8f51de95313ca0354cedcdc92b16f4'
        Submodule path 'ansible/roles-external/hostname': checked out 'da6f329b2984e84d2248d4251e0c679c53dfbb30'
        Submodule path 'ansible/roles-external/kubespray': checked out 'c7658c0256bfeb50913ac73f638a760680e4dd6d'
        Submodule path 'ansible/roles-external/logrotate': checked out '91d570f68c44261d2051a99a2b3c7d736306bf0d'
        Submodule path 'ansible/roles-external/sft': checked out '126fde847dfc9deffeef8ba133c541c16628a63a'
[16:39:14] # Running command «mkdir -p wire-server» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ mkdir -p wire-server
[16:39:20] # Running command «cd wire-server» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ cd wire-server
[16:39:26] # Running command «pwd» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ pwd
        /home/wire/wire-server-deploy/wire-server
[16:39:32] # Running command «curl -sSL https://raw.githubusercontent.com/wireapp/wire-server-deploy/master/values/wire-server/demo-secrets.example.yaml > secrets.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ curl -sSL https://raw.githubusercontent.com/wireapp/wire-server-deploy/master/values/wire-server/demo-secrets.example.yaml > secrets.yaml
[16:39:38] # Running command «curl -sSL https://raw.githubusercontent.com/wireapp/wire-server-deploy/master/values/wire-server/demo-values.example.yaml > values.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ curl -sSL https://raw.githubusercontent.com/wireapp/wire-server-deploy/master/values/wire-server/demo-values.example.yaml > values.yaml
[16:39:44] # Running command «openssl rand -base64 64 | env LC_CTYPE=C tr -dc a-zA-Z0-9 | head -c 42 > restund.txt» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ openssl rand -base64 64 | env LC_CTYPE=C tr -dc a-zA-Z0-9 | head -c 42 > restund.txt
[16:41:53] # Running command «sudo docker run --rm quay.io/wire/alpine-intermediate /dist/zauth -m gen-keypair -i 1 > zauth.txt» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ sudo docker run --rm quay.io/wire/alpine-intermediate /dist/zauth -m gen-keypair -i 1 > zauth.txt
        Unable to find image 'quay.io/wire/alpine-intermediate:latest' locally
        latest: Pulling from wire/alpine-intermediate
        188c0c94c7c5: Pulling fs layer
        edebdc4a6437: Pulling fs layer
        d9b6d5749552: Pulling fs layer
        0dd342b35df2: Pulling fs layer
        ea7c73d2e35b: Pulling fs layer
        0dd342b35df2: Waiting
        ea7c73d2e35b: Waiting
        edebdc4a6437: Verifying Checksum
        edebdc4a6437: Download complete
        188c0c94c7c5: Verifying Checksum
        188c0c94c7c5: Download complete
        ea7c73d2e35b: Download complete
        188c0c94c7c5: Pull complete
        edebdc4a6437: Pull complete
        d9b6d5749552: Verifying Checksum
        d9b6d5749552: Download complete
        d9b6d5749552: Pull complete
        0dd342b35df2: Verifying Checksum
        0dd342b35df2: Download complete
        0dd342b35df2: Pull complete
        ea7c73d2e35b: Pull complete
        Digest: sha256:bfb7dfd21e389ec699527f3cdad32d158ecab12577404c4578001af7c899d044
        Status: Downloaded newer image for quay.io/wire/alpine-intermediate:latest
[16:41:59] # Running command «ls -l» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ ls -l
        total 20
        -rw-rw-r-- 1 wire wire   42 Aug 12 14:39 restund.txt
        -rw-rw-r-- 1 wire wire 1949 Aug 12 14:39 secrets.yaml
        -rw-rw-r-- 1 wire wire 7642 Aug 12 14:39 values.yaml
        -rw-rw-r-- 1 wire wire  150 Aug 12 14:41 zauth.txt
[16:42:07] # Running command «curl -sSL https://raw.githubusercontent.com/wireapp/wire-server-deploy/master/values/wire-server/prod-values.example.yaml > prod-values.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ curl -sSL https://raw.githubusercontent.com/wireapp/wire-server-deploy/master/values/wire-server/prod-values.example.yaml > prod-values.yaml
[16:42:13] # Running command «grep 'spar:' prod-values.yaml -A 24 > spar.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ grep 'spar:' prod-values.yaml -A 24 > spar.yaml
[16:42:19] # Running command «sed -i 's/cassandra-external/cassandra-ephemeral/' spar.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ sed -i 's/cassandra-external/cassandra-ephemeral/' spar.yaml
[16:42:25] # Running command «ls -l» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ ls -l
        total 40
        -rw-rw-r-- 1 wire wire 12606 Aug 12 14:42 prod-values.yaml
        -rw-rw-r-- 1 wire wire    42 Aug 12 14:39 restund.txt
        -rw-rw-r-- 1 wire wire  1949 Aug 12 14:39 secrets.yaml
        -rw-rw-r-- 1 wire wire   744 Aug 12 14:42 spar.yaml
        -rw-rw-r-- 1 wire wire  7642 Aug 12 14:39 values.yaml
        -rw-rw-r-- 1 wire wire   150 Aug 12 14:41 zauth.txt
[16:42:31] # Running command «cat restund.txt && echo» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cat restund.txt && echo
        RtBha7Kl5qm0LuVAA7ROhzPPSm3Oi7QyUkHLMyysxX
[16:42:36] # Running command «cat zauth.txt» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cat zauth.txt
        public: lpzATMWlBYzy2-rJEL7RaPBTu5tUlzwQ3-iUzTqW9KY=
        secret: kSoabclYFP1TjAnfGRsmmfrjPnhByY38-VVXdrLu9W-WnMBMxaUFjPLb6skQvtFo8FO7m1SXPBDf6JTNOpb0pg==
[16:42:42] # Running command «sed -i 's/secret:$/secret: RtBha7Kl5qm0LuVAA7ROhzPPSm3Oi7QyUkHLMyysxX/' secrets.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ sed -i 's/secret:$/secret: RtBha7Kl5qm0LuVAA7ROhzPPSm3Oi7QyUkHLMyysxX/' secrets.yaml
[16:42:48] # Running command «sed -i 's/publicKeys: "<public key>"/publicKeys: "lpzATMWlBYzy2-rJEL7RaPBTu5tUlzwQ3-iUzTqW9KY="/' secrets.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ sed -i 's/publicKeys: "<public key>"/publicKeys: "lpzATMWlBYzy2-rJEL7RaPBTu5tUlzwQ3-iUzTqW9KY="/' secrets.yaml
[16:42:54] # Running command «sed -i 's/privateKeys: "<private key>"/privateKeys: "kSoabclYFP1TjAnfGRsmmfrjPnhByY38-VVXdrLu9W-WnMBMxaUFjPLb6skQvtFo8FO7m1SXPBDf6JTNOpb0pg=="/' secrets.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ sed -i 's/privateKeys: "<private key>"/privateKeys: "kSoabclYFP1TjAnfGRsmmfrjPnhByY38-VVXdrLu9W-WnMBMxaUFjPLb6skQvtFo8FO7m1SXPBDf6JTNOpb0pg=="/' secrets.yaml
[16:42:59] # Running command «cat secrets.yaml | grep 'RtBha7Kl5qm0LuVAA7ROhzPPSm3Oi7QyUkHLMyysxX'» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cat secrets.yaml | grep 'RtBha7Kl5qm0LuVAA7ROhzPPSm3Oi7QyUkHLMyysxX'
              secret: RtBha7Kl5qm0LuVAA7ROhzPPSm3Oi7QyUkHLMyysxX
[16:43:05] # Running command «cat secrets.yaml | grep 'lpzATMWlBYzy2-rJEL7RaPBTu5tUlzwQ3-iUzTqW9KY='» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cat secrets.yaml | grep 'lpzATMWlBYzy2-rJEL7RaPBTu5tUlzwQ3-iUzTqW9KY='
              publicKeys: "lpzATMWlBYzy2-rJEL7RaPBTu5tUlzwQ3-iUzTqW9KY="
              publicKeys: "lpzATMWlBYzy2-rJEL7RaPBTu5tUlzwQ3-iUzTqW9KY="
[16:43:11] # Running command «cat secrets.yaml | grep 'kSoabclYFP1TjAnfGRsmmfrjPnhByY38-VVXdrLu9W-WnMBMxaUFjPLb6skQvtFo8FO7m1SXPBDf6JTNOpb0pg=='» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cat secrets.yaml | grep 'kSoabclYFP1TjAnfGRsmmfrjPnhByY38-VVXdrLu9W-WnMBMxaUFjPLb6skQvtFo8FO7m1SXPBDf6JTNOpb0pg=='
              privateKeys: "kSoabclYFP1TjAnfGRsmmfrjPnhByY38-VVXdrLu9W-WnMBMxaUFjPLb6skQvtFo8FO7m1SXPBDf6JTNOpb0pg=="
[16:43:17] # Running command «cat values.yaml | grep spar» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cat values.yaml | grep spar
          spar: false # enable if you want/need Single-Sign-On (SSO)
[16:43:23] # Running command «sed -i 's/spar: false/spar: true/' values.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ sed -i 's/spar: false/spar: true/' values.yaml
[16:43:29] # Running command «cat spar.yaml >> values.yaml» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cat spar.yaml >> values.yaml
[16:43:35] # Running command «cat values.yaml | grep spar» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cat values.yaml | grep spar
          spar: true # enable if you want/need Single-Sign-On (SSO)
        spar:
[16:43:41] # Running command «cd ~/wire-server-deploy» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy/wire-server$ cd ~/wire-server-deploy
[16:43:47] # Running command «pwd» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ pwd
        /home/wire/wire-server-deploy
[16:43:52] # Running command «ls -l» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ ls -l
        total 112
        -rw-rw-r--  1 wire wire 16072 Aug 12 14:38 CHANGELOG.md
        -rw-rw-r--  1 wire wire  1531 Aug 12 14:38 CONTRIBUTING.md
        -rw-rw-r--  1 wire wire   252 Aug 12 14:38 Dockerfile
        -rw-rw-r--  1 wire wire 34520 Aug 12 14:38 LICENSE
        -rw-rw-r--  1 wire wire  5893 Aug 12 14:38 Makefile
        -rw-rw-r--  1 wire wire  2251 Aug 12 14:38 README.md
        drwxrwxr-x  9 wire wire  4096 Aug 12 14:38 ansible
        drwxrwxr-x  3 wire wire  4096 Aug 12 14:38 bin
        -rw-rw-r--  1 wire wire  2338 Aug 12 14:38 default.nix
        drwxrwxr-x  5 wire wire  4096 Aug 12 14:38 examples
        drwxrwxr-x  2 wire wire  4096 Aug 12 14:38 helm
        drwxrwxr-x  4 wire wire  4096 Aug 12 14:38 nix
        drwxrwxr-x  2 wire wire  4096 Aug 12 14:38 offline
        drwxrwxr-x  5 wire wire  4096 Aug 12 14:38 terraform
        drwxrwxr-x 15 wire wire  4096 Aug 12 14:38 values
        drwxrwxr-x  2 wire wire  4096 Aug 12 14:43 wire-server
[16:43:58] # Running command «WSD_CONTAINER=quay.io/wire/wire-server-deploy:cdc1c84c1a10a4f5f1b77b51ee5655d0da7f9518» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ WSD_CONTAINER=quay.io/wire/wire-server-deploy:cdc1c84c1a10a4f5f1b77b51ee5655d0da7f9518
[16:47:26] # Running command «sudo docker run -it --network=host -v ${SSH_AUTH_SOCK:-nonexistent}:/ssh-agent -v $HOME/.ssh:/root/.ssh -v $PWD:/wire-server-deploy -e SSH_AUTH_SOCK=/ssh-agent $WSD_CONTAINER bash» on 192.168.1.121
        wire@wire-client:~/wire-server-deploy$ sudo docker run -it --network=host -v ${SSH_AUTH_SOCK:-nonexistent}:/ssh-agent -v $HOME/.ssh:/root/.ssh -v $PWD:/wire-server-deploy -e SSH_AUTH_SOCK=/ssh-agent $WSD_CONTAINER bash
        Unable to find image 'quay.io/wire/wire-server-deploy:cdc1c84c1a10a4f5f1b77b51ee5655d0da7f9518' locally
        cdc1c84c1a10a4f5f1b77b51ee5655d0da7f9518: Pulling from wire/wire-server-deploy
        083086456ea5: Pull complete
        ae57e4902e57: Pull complete
        Digest: sha256:a18a5fae78d5ffb25e95e43ed899d840f5032890b76bdc4fb89a5669c1a60549
        Status: Downloaded newer image for quay.io/wire/wire-server-deploy:cdc1c84c1a10a4f5f1b77b51ee5655d0da7f9518
[16:47:32] # Running command «ansible --version» on 192.168.1.121
        bash-4.4# ansible --version
        ansible 2.9.12
          config file = /wire-server-deploy/ansible/ansible.cfg
          configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
          ansible python module location = /nix/store/407c5v2x920kri79w0sb9gb1g82q28mg-python3.8-ansible-2.9.12/lib/python3.8/site-packages/ansible
          executable location = /nix/store/407c5v2x920kri79w0sb9gb1g82q28mg-python3.8-ansible-2.9.12/bin/ansible
          python version = 3.8.8 (default, Feb 19 2021, 11:04:50) [GCC 10.2.0]
[16:47:38] # Running command «cd ansible» on 192.168.1.121
        bash-4.4# cd ansible
[16:47:43] # Running command «pwd» on 192.168.1.121
        bash-4.4# pwd
        /wire-server-deploy/ansible
[16:47:49] # Running command «cp inventory/demo/hosts.example.ini inventory/demo/hosts.ini» on 192.168.1.121
        bash-4.4# cp inventory/demo/hosts.example.ini inventory/demo/hosts.ini
[16:47:55] # Running command «ls -l inventory/demo/hosts.ini» on 192.168.1.121
        bash-4.4# ls -l inventory/demo/hosts.ini
        -rw-r--r-- 1 root root 1066 Aug 12 14:47 inventory/demo/hosts.ini
[16:48:01] # Running command «sed -i 's/X.X.X.X/95.216.208.159/g' inventory/demo/hosts.ini» on 192.168.1.121
        bash-4.4# sed -i 's/X.X.X.X/95.216.208.159/g' inventory/demo/hosts.ini
[16:48:07] # Running command «cat inventory/demo/hosts.ini | grep ansible_host» on 192.168.1.121
        bash-4.4# cat inventory/demo/hosts.ini | grep ansible_host
        # * 'ansible_host' is the IP to ssh into
        kubenode01    ansible_host=95.216.208.159 etcd_member_name=etcd1
[16:48:12] # Running command «ssh-keygen -f ~/.ssh/id_rsa -t rsa -P ''» on 192.168.1.121
        bash-4.4# ssh-keygen -f ~/.ssh/id_rsa -t rsa -P ''
        Generating public/private rsa key pair.
        Your identification has been saved in /root/.ssh/id_rsa
        Your public key has been saved in /root/.ssh/id_rsa.pub
        The key fingerprint is:
        SHA256:odap8nbCCw2wp3LfK+CyVssgETVZkynh9im8ap2CwKA root@wire-client
        The key's randomart image is:
        +---[RSA 3072]----+
        | .++oo           |
        |..o.o.           |
        | .+.    .        |
        |oo + . o o       |
        |+.+ = o S        |
        |Eo.* + .         |
        |=.O.=.o          |
        |oB.*.=+ .        |
        |=o. .o==         |
        +----[SHA256]-----+
[16:48:23] # Running command «ssh-copy-id wire@95.216.208.159» on 192.168.1.121
        bash-4.4# ssh-copy-id wire@95.216.208.159
        /bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"
        The authenticity of host '95.216.208.159 (95.216.208.159)' can't be established.
        ECDSA key fingerprint is SHA256:5wt1veWstQtNWXBHSoQrTglPYvxk+ABxT5FEn1hrZ9g.
        Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
        /bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
        expr: warning: '^ERROR: ': using '^' as the first character
        of a basic regular expression is not portable; it is ignored
        /bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
        wire@95.216.208.159's password:
        
        Number of key(s) added: 1
        
        Now try logging into the machine, with:   "ssh 'wire@95.216.208.159'"
        and check to make sure that only the key(s) you wanted were added.
        
[16:48:28] # Running command «cat /etc/hostname» on 95.216.208.159
        wire@arthur-demo:~$ cat /etc/hostname
        arthur-demo
[16:48:34] # Running command «sudo tail -n 2 /etc/sudoers» on 95.216.208.159
        wire@arthur-demo:~$ sudo tail -n 2 /etc/sudoers
        
        #includedir /etc/sudoers.d
[16:48:39] # Running command «echo 'wire ALL=(ALL) NOPASSWD:ALL' | sudo tee -a /etc/sudoers» on 95.216.208.159
        wire@arthur-demo:~$ echo 'wire ALL=(ALL) NOPASSWD:ALL' | sudo tee -a /etc/sudoer
        s
        wire ALL=(ALL) NOPASSWD:ALL
[16:48:43] # Running command «sudo tail -n 2 /etc/sudoers» on 95.216.208.159
        wire@arthur-demo:~$ sudo tail -n 2 /etc/sudoers
        #includedir /etc/sudoers.d
        wire ALL=(ALL) NOPASSWD:ALL
[16:48:49] # Running command «cat inventory/demo/hosts.ini | grep ansible_user» on 192.168.1.121
        bash-4.4# cat inventory/demo/hosts.ini | grep ansible_user
        # ansible_user = ...
[16:48:55] # Running command «sed -i 's/# ansible_user = .../ansible_user = wire/g' inventory/demo/hosts.ini» on 192.168.1.121
        bash-4.4# sed -i 's/# ansible_user = .../ansible_user = wire/g' inventory/demo/hosts.ini
[16:49:01] # Running command «cat inventory/demo/hosts.ini | grep ansible_user» on 192.168.1.121
        bash-4.4# cat inventory/demo/hosts.ini | grep ansible_user
        ansible_user = wire
[16:57:45] # Running command «ansible-playbook -i inventory/demo/hosts.ini kubernetes.yml -vv» on 192.168.1.121
        TASK [kubernetes-apps/network_plugin/kube-ovn : Kube-OVN | Start Resources] ****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/network_plugin/kube-ovn/tasks/main.yml:2
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'kube-ovn-crd', 'file': 'cni-kube-ovn-crd.yml'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": false, "item": {"a
        nsible_loop_var": "item", "changed": false, "item": {"file": "cni-kube-ovn-crd.yml", "name": "kube-ovn-crd"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'ovn', 'file': 'cni-ovn.yml'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var":
        "item", "changed": false, "item": {"file": "cni-ovn.yml", "name": "ovn"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'kube-ovn', 'file': 'cni-kube-ovn.yml'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_l
        oop_var": "item", "changed": false, "item": {"file": "cni-kube-ovn.yml", "name": "kube-ovn"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/network_plugin/weave : Weave | Start Resources] **********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/network_plugin/weave/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/network_plugin/weave : Weave | Wait for Weave to become available] ***************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/network_plugin/weave/tasks/main.yml:13
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/network_plugin/kube-router : kube-router | Start Resources] **********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/network_plugin/kube-router/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/network_plugin/kube-router : kube-router | Wait for kube-router pods to be ready] ************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/network_plugin/kube-router/tasks/main.yml:14
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/network_plugin/ovn4nfv : ovn4nfv-k8s | Start Resources] **************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/network_plugin/ovn4nfv/tasks/main.yml:2
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'ovn-daemonset', 'file': 'ovn-daemonset.yml'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": false, "item": {"ans
        ible_loop_var": "item", "changed": false, "item": {"file": "ovn-daemonset.yml", "name": "ovn-daemonset"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'ovn4nfv-k8s-plugin', 'file': 'ovn4nfv-k8s-plugin.yml'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": false, "it
        em": {"ansible_loop_var": "item", "changed": false, "item": {"file": "ovn4nfv-k8s-plugin.yml", "name": "ovn4nfv-k8s-plugin"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/network_plugin/multus : Multus | Start resources] ********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/network_plugin/multus/tasks/main.yml:2
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'multus-crd', 'file': 'multus-crd.yml', 'type': 'customresourcedefinition'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "
        changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "multus-crd.yml", "name": "multus-crd", "type": "customresourcedefinition"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was Fa
        lse"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'multus-serviceaccount', 'file': 'multus-serviceaccount.yml', 'type': 'serviceaccount'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var
        ": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "multus-serviceaccount.yml", "name": "multus-serviceaccount", "type": "serviceaccount"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "C
        onditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'multus-clusterrole', 'file': 'multus-clusterrole.yml', 'type': 'clusterrole'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item"
        , "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "multus-clusterrole.yml", "name": "multus-clusterrole", "type": "clusterrole"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result
        was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'multus-clusterrolebinding', 'file': 'multus-clusterrolebinding.yml', 'type': 'clusterrolebinding'}, 'ansible_loop_var': 'item'})  => {"ansi
        ble_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "multus-clusterrolebinding.yml", "name": "multus-clusterrolebinding", "type": "clusterrolebinding"}, "skip_reason": "Conditional result was False", "skipped":
        true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'multus-daemonset', 'file': 'multus-daemonset.yml', 'type': 'daemonset'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "cha
        nged": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "multus-daemonset.yml", "name": "multus-daemonset", "type": "daemonset"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [policy_controller/calico : Set cert dir] *********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/policy_controller/calico/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [policy_controller/calico : Create calico-kube-controllers manifests] *****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/policy_controller/calico/tasks/main.yml:11
        skipping: [kubenode01] => (item={'name': 'calico-kube-controllers', 'file': 'calico-kube-controllers.yml', 'type': 'deployment'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-controllers.yml", "name": "calico-kube-controllers", "type":
        "deployment"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'calico-kube-controllers', 'file': 'calico-kube-sa.yml', 'type': 'sa'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-sa.yml", "name": "calico-kube-controllers", "type": "sa"}, "skip_reason": "Con
        ditional result was False"}
        skipping: [kubenode01] => (item={'name': 'calico-kube-controllers', 'file': 'calico-kube-cr.yml', 'type': 'clusterrole'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-cr.yml", "name": "calico-kube-controllers", "type": "clusterrole"}, "
        skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'calico-kube-controllers', 'file': 'calico-kube-crb.yml', 'type': 'clusterrolebinding'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-crb.yml", "name": "calico-kube-controllers", "type": "cluster
        rolebinding"}, "skip_reason": "Conditional result was False"}
        
        TASK [policy_controller/calico : Start of Calico kube controllers] *************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/policy_controller/calico/tasks/main.yml:25
        skipping: [kubenode01] => (item=calico-kube-controllers.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-controllers.yml", "name": "calico-kube-controllers", "type": "deployment"},
         "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=calico-kube-sa.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-sa.yml", "name": "calico-kube-controllers", "type": "sa"}, "skip_reason": "Condition
        al result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=calico-kube-cr.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-cr.yml", "name": "calico-kube-controllers", "type": "clusterrole"}, "skip_reason": "
        Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=calico-kube-crb.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-crb.yml", "name": "calico-kube-controllers", "type": "clusterrolebinding"}, "skip_r
        eason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [policy_controller/calico : Set cert dir] *********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/policy_controller/calico/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [policy_controller/calico : Create calico-kube-controllers manifests] *****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/policy_controller/calico/tasks/main.yml:11
        skipping: [kubenode01] => (item={'name': 'calico-kube-controllers', 'file': 'calico-kube-controllers.yml', 'type': 'deployment'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-controllers.yml", "name": "calico-kube-controllers", "type":
        "deployment"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'calico-kube-controllers', 'file': 'calico-kube-sa.yml', 'type': 'sa'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-sa.yml", "name": "calico-kube-controllers", "type": "sa"}, "skip_reason": "Con
        ditional result was False"}
        skipping: [kubenode01] => (item={'name': 'calico-kube-controllers', 'file': 'calico-kube-cr.yml', 'type': 'clusterrole'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-cr.yml", "name": "calico-kube-controllers", "type": "clusterrole"}, "
        skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'calico-kube-controllers', 'file': 'calico-kube-crb.yml', 'type': 'clusterrolebinding'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-crb.yml", "name": "calico-kube-controllers", "type": "cluster
        rolebinding"}, "skip_reason": "Conditional result was False"}
        
        TASK [policy_controller/calico : Start of Calico kube controllers] *************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/policy_controller/calico/tasks/main.yml:25
        skipping: [kubenode01] => (item=calico-kube-controllers.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-controllers.yml", "name": "calico-kube-controllers", "type": "deployment"},
         "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=calico-kube-sa.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-sa.yml", "name": "calico-kube-controllers", "type": "sa"}, "skip_reason": "Condition
        al result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=calico-kube-cr.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-cr.yml", "name": "calico-kube-controllers", "type": "clusterrole"}, "skip_reason": "
        Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=calico-kube-crb.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "calico-kube-crb.yml", "name": "calico-kube-controllers", "type": "clusterrolebinding"}, "skip_r
        eason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ingress_nginx : NGINX Ingress Controller | Create addon dir] **************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ingress_nginx/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ingress_nginx : NGINX Ingress Controller | Templates list] ****************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ingress_nginx/tasks/main.yml:13
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ingress_nginx : NGINX Ingress Controller | Append extra templates to NGINX Ingress Templates list for PodSecurityPolicy] **************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ingress_nginx/tasks/main.yml:29
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ingress_nginx : NGINX Ingress Controller | Create manifests] **************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ingress_nginx/tasks/main.yml:34
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ingress_nginx : NGINX Ingress Controller | Apply manifests] ***************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ingress_nginx/tasks/main.yml:43
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ambassador : Ambassador | Create addon dir] *******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ambassador/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ambassador : Ambassador | Templates list] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ambassador/tasks/main.yml:13
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ambassador : Ambassador | Create manifests] *******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ambassador/tasks/main.yml:25
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ambassador : Ambassador | Apply manifests] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ambassador/tasks/main.yml:34
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ambassador : Ambassador | AmbassadorInstallation template] ****************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ambassador/tasks/main.yml:48
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ambassador : Ambassador | Create installation manifests] ******************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ambassador/tasks/main.yml:53
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/ambassador : Ambassador | Apply AmbassadorInstallation] *******************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/ambassador/tasks/main.yml:62
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Remove legacy addon dir and manifests] ******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Remove legacy namespace] ********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:12
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Create addon dir] ***************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:21
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Templates list] *****************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:31
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Create manifests] ***************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:50
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Apply manifests] ****************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:59
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Wait for Webhook pods become ready] *********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:70
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Create ClusterIssuer manifest] **************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:75
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/cert_manager : Cert Manager | Apply ClusterIssuer manifest] ***************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/cert_manager/tasks/main.yml:83
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/alb_ingress_controller : ALB Ingress Controller | Create addon dir] *******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/alb_ingress_controller/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/alb_ingress_controller : ALB Ingress Controller | Create manifests] *******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/alb_ingress_controller/tasks/main.yml:11
        skipping: [kubenode01] => (item={'name': 'alb-ingress-clusterrole', 'file': 'alb-ingress-clusterrole.yml', 'type': 'clusterrole'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-clusterrole.yml", "name": "alb-ingress-clusterrole", "type":
         "clusterrole"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'alb-ingress-clusterrolebinding', 'file': 'alb-ingress-clusterrolebinding.yml', 'type': 'clusterrolebinding'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-clusterrolebinding.yml", "name": "alb-i
        ngress-clusterrolebinding", "type": "clusterrolebinding"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'alb-ingress-ns', 'file': 'alb-ingress-ns.yml', 'type': 'ns'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-ns.yml", "name": "alb-ingress-ns", "type": "ns"}, "skip_reason": "Conditional result wa
        s False"}
        skipping: [kubenode01] => (item={'name': 'alb-ingress-sa', 'file': 'alb-ingress-sa.yml', 'type': 'sa'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-sa.yml", "name": "alb-ingress-sa", "type": "sa"}, "skip_reason": "Conditional result wa
        s False"}
        skipping: [kubenode01] => (item={'name': 'alb-ingress-deploy', 'file': 'alb-ingress-deploy.yml', 'type': 'deploy'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-deploy.yml", "name": "alb-ingress-deploy", "type": "deploy"}, "skip_reason"
        : "Conditional result was False"}
        
        TASK [kubernetes-apps/ingress_controller/alb_ingress_controller : ALB Ingress Controller | Apply manifests] ********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ingress_controller/alb_ingress_controller/tasks/main.yml:25
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'alb-ingress-clusterrole', 'file': 'alb-ingress-clusterrole.yml', 'type': 'clusterrole'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_va
        r": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-clusterrole.yml", "name": "alb-ingress-clusterrole", "type": "clusterrole"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason":
        "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'alb-ingress-clusterrolebinding', 'file': 'alb-ingress-clusterrolebinding.yml', 'type': 'clusterrolebinding'}, 'ansible_loop_var': 'item'})
         => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-clusterrolebinding.yml", "name": "alb-ingress-clusterrolebinding", "type": "clusterrolebinding"}, "skip_reason": "Conditional result was
         False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'alb-ingress-ns', 'file': 'alb-ingress-ns.yml', 'type': 'ns'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-ns.yml", "name": "alb-ingress-ns", "type": "ns"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'alb-ingress-sa', 'file': 'alb-ingress-sa.yml', 'type': 'sa'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-sa.yml", "name": "alb-ingress-sa", "type": "sa"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'alb-ingress-deploy', 'file': 'alb-ingress-deploy.yml', 'type': 'deploy'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "ch
        anged": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "alb-ingress-deploy.yml", "name": "alb-ingress-deploy", "type": "deploy"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"
        }
        
        TASK [kubernetes-apps/external_provisioner/local_volume_provisioner : Local Volume Provisioner | Ensure base dir is created on all hosts] **************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_volume_provisioner/tasks/main.yml:3
        skipping: [kubenode01] => (item=['kubenode01', 'local-storage'])  => {"ansible_loop_var": "delegate_host_base_dir", "changed": false, "delegate_host_base_dir": ["kubenode01", "local-storage"], "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_volume_provisioner : Local Volume Provisioner | Create addon dir] *************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_volume_provisioner/tasks/main.yml:9
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_volume_provisioner : Local Volume Provisioner | Templates list] ***************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_volume_provisioner/tasks/main.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_volume_provisioner : Local Volume Provisioner | Insert extra templates to Local Volume Provisioner templates list for PodSecurityPolicy] **************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_volume_provisioner/tasks/main.yml:32
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_volume_provisioner : Local Volume Provisioner | Create manifests] *************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_volume_provisioner/tasks/main.yml:39
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_volume_provisioner : Local Volume Provisioner | Apply manifests] **************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_volume_provisioner/tasks/main.yml:47
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/cephfs_provisioner : CephFS Provisioner | Remove legacy addon dir and manifests] ****************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/cephfs_provisioner/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/cephfs_provisioner : CephFS Provisioner | Remove legacy namespace] ******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/cephfs_provisioner/tasks/main.yml:12
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/cephfs_provisioner : CephFS Provisioner | Remove legacy storageclass] ***************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/cephfs_provisioner/tasks/main.yml:21
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/cephfs_provisioner : CephFS Provisioner | Create addon dir] *************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/cephfs_provisioner/tasks/main.yml:30
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/cephfs_provisioner : CephFS Provisioner | Templates list] ***************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/cephfs_provisioner/tasks/main.yml:40
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/cephfs_provisioner : CephFS Provisioner | Append extra templates to CephFS Provisioner Templates list for PodSecurityPolicy] ********************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/cephfs_provisioner/tasks/main.yml:55
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/cephfs_provisioner : CephFS Provisioner | Create manifests] *************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/cephfs_provisioner/tasks/main.yml:62
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/cephfs_provisioner : CephFS Provisioner | Apply manifests] **************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/cephfs_provisioner/tasks/main.yml:70
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/rbd_provisioner : RBD Provisioner | Remove legacy addon dir and manifests] **********************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/rbd_provisioner/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/rbd_provisioner : RBD Provisioner | Remove legacy namespace] ************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/rbd_provisioner/tasks/main.yml:12
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/rbd_provisioner : RBD Provisioner | Remove legacy storageclass] *********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/rbd_provisioner/tasks/main.yml:21
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/rbd_provisioner : RBD Provisioner | Create addon dir] *******************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/rbd_provisioner/tasks/main.yml:30
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/rbd_provisioner : RBD Provisioner | Templates list] *********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/rbd_provisioner/tasks/main.yml:40
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/rbd_provisioner : RBD Provisioner | Append extra templates to RBD Provisioner Templates list for PodSecurityPolicy] *****************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/rbd_provisioner/tasks/main.yml:55
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/rbd_provisioner : RBD Provisioner | Create manifests] *******************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/rbd_provisioner/tasks/main.yml:62
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/rbd_provisioner : RBD Provisioner | Apply manifests] ********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/rbd_provisioner/tasks/main.yml:70
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_path_provisioner : Local Path Provisioner | Create addon dir] *****************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_path_provisioner/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_path_provisioner : Local Path Provisioner | Create claim root dir] ************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_path_provisioner/tasks/main.yml:12
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_path_provisioner : Local Path Provisioner | Render Template] ******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_path_provisioner/tasks/main.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_path_provisioner : Local Path Provisioner | Insert extra templates to Local Path Provisioner templates list for PodSecurityPolicy] ********************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_path_provisioner/tasks/main.yml:32
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_path_provisioner : Local Path Provisioner | Create manifests] *****************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_path_provisioner/tasks/main.yml:39
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/external_provisioner/local_path_provisioner : Local Path Provisioner | Apply manifests] ******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/external_provisioner/local_path_provisioner/tasks/main.yml:47
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        META: ran handlers
        META: ran handlers
        
        PLAY [kube-master] *************************************************************************************************************************************************************************************************************************************************************
        META: ran handlers
        
        TASK [prep_download | Set a few facts] *****************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Set image info command for containerd and crio] **********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:8
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Set image info command for containerd and crio on localhost] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:14
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | On localhost, check if passwordless root is possible] ****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:20
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | On localhost, check if user has access to docker without using sudo] *************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:35
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Parse the outputs of the previous commands] **************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:50
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Check that local user is in group or can become root] ****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:60
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Register docker images info] *****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:71
        skipping: [kubenode01] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
        
        TASK [prep_download | Create staging directory on remote node] *****************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:80
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Create local cache for files and images on control node] *************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:90
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [container-engine/crictl : install crictĺ] ********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/container-engine/crictl/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [download | Get kubeadm binary and list of required images] ***************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/main.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [download | Download files / images] **************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/main.yml:26
        skipping: [kubenode01] => (item={'key': 'netcheck_server', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/l23network/k8s-netchecker-server', 'tag': 'v1.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item
        ": {"key": "netcheck_server", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/l23network/k8s-netchecker-server", "sha256": "", "tag": "v1.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'netcheck_agent', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/l23network/k8s-netchecker-agent', 'tag': 'v1.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item":
         {"key": "netcheck_agent", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/l23network/k8s-netchecker-agent", "sha256": "", "tag": "v1.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'etcd', 'value': {'container': True, 'file': False, 'enabled': True, 'version': 'v3.4.13', 'dest': '/tmp/releases/etcd-v3.4.13-linux-amd64.tar.gz', 'repo': 'quay.io/coreos/etcd', 'tag': 'v3.4.13', 'sha256': '', 'url': 'https://githu
        b.com/coreos/etcd/releases/download/v3.4.13/etcd-v3.4.13-linux-amd64.tar.gz', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['etcd']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "etcd", "value": {"container": true, "dest": "/tmp/r
        eleases/etcd-v3.4.13-linux-amd64.tar.gz", "enabled": true, "file": false, "groups": ["etcd"], "mode": "0755", "owner": "root", "repo": "quay.io/coreos/etcd", "sha256": "", "tag": "v3.4.13", "unarchive": false, "url": "https://github.com/coreos/etcd/releases/download/v3.4.
        13/etcd-v3.4.13-linux-amd64.tar.gz", "version": "v3.4.13"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cni', 'value': {'enabled': True, 'file': True, 'version': 'v0.9.0', 'dest': '/tmp/releases/cni-plugins-linux-amd64-v0.9.0.tgz', 'sha256': '58a58d389895ba9f9bbd3ef330f186c0bb7484136d0bfb9b50152eed55d9ec24', 'url': 'https://github.co
        m/containernetworking/plugins/releases/download/v0.9.0/cni-plugins-linux-amd64-v0.9.0.tgz', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "cni", "value": {"dest": "/tmp/
        releases/cni-plugins-linux-amd64-v0.9.0.tgz", "enabled": true, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "58a58d389895ba9f9bbd3ef330f186c0bb7484136d0bfb9b50152eed55d9ec24", "unarchive": false, "url": "https://github.com/containern
        etworking/plugins/releases/download/v0.9.0/cni-plugins-linux-amd64-v0.9.0.tgz", "version": "v0.9.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm', 'value': {'enabled': True, 'file': True, 'version': 'v1.19.7', 'dest': '/tmp/releases/kubeadm-v1.19.7-amd64', 'sha256': 'c63ef1842533cd7888c7452cab9f320dcf45fc1c173e9d40abb712d45992db24', 'url': 'https://storage.googleapi
        s.com/kubernetes-release/release/v1.19.7/bin/linux/amd64/kubeadm', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubeadm", "value": {"dest": "/tmp/releases/kubeadm-v1.1
        9.7-amd64", "enabled": true, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "c63ef1842533cd7888c7452cab9f320dcf45fc1c173e9d40abb712d45992db24", "unarchive": false, "url": "https://storage.googleapis.com/kubernetes-release/release/v1.19
        .7/bin/linux/amd64/kubeadm", "version": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubelet', 'value': {'enabled': True, 'file': True, 'version': 'v1.19.7', 'dest': '/tmp/releases/kubelet-v1.19.7-amd64', 'sha256': 'd8b296825f6dd7a17287b73cd6604d32210abbba86c88fb68c1b1c5016906c54', 'url': 'https://storage.googleapi
        s.com/kubernetes-release/release/v1.19.7/bin/linux/amd64/kubelet', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubelet", "value": {"dest": "/tmp/releases/kubelet-v1.1
        9.7-amd64", "enabled": true, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "d8b296825f6dd7a17287b73cd6604d32210abbba86c88fb68c1b1c5016906c54", "unarchive": false, "url": "https://storage.googleapis.com/kubernetes-release/release/v1.19
        .7/bin/linux/amd64/kubelet", "version": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubectl', 'value': {'enabled': True, 'file': True, 'version': 'v1.19.7', 'dest': '/tmp/releases/kubectl-v1.19.7-amd64', 'sha256': 'd46eb3bbe2575e5b6bedbc6d3519424b4f2f57929d7da1ef7e11c09068f37297', 'url': 'https://storage.googleapi
        s.com/kubernetes-release/release/v1.19.7/bin/linux/amd64/kubectl', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubectl", "value": {"dest": "/tmp/releases/kubectl-v1.1
        9.7-amd64", "enabled": true, "file": true, "groups": ["kube-master"], "mode": "0755", "owner": "root", "sha256": "d46eb3bbe2575e5b6bedbc6d3519424b4f2f57929d7da1ef7e11c09068f37297", "unarchive": false, "url": "https://storage.googleapis.com/kubernetes-release/release/v1.19
        .7/bin/linux/amd64/kubectl", "version": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'crictl', 'value': {'file': True, 'enabled': False, 'version': 'v1.19.0', 'dest': '/tmp/releases/crictl-v1.19.0-linux-amd64.tar.gz', 'sha256': '87d8ef70b61f2fe3d8b4a48f6f712fd798c6e293ed3723c1e4bbb5052098f0ae', 'url': 'https://githu
        b.com/kubernetes-sigs/cri-tools/releases/download/v1.19.0/crictl-v1.19.0-linux-amd64.tar.gz', 'unarchive': True, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "crictl", "value": {"dest": "/
        tmp/releases/crictl-v1.19.0-linux-amd64.tar.gz", "enabled": false, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "87d8ef70b61f2fe3d8b4a48f6f712fd798c6e293ed3723c1e4bbb5052098f0ae", "unarchive": true, "url": "https://github.com/kuberne
        tes-sigs/cri-tools/releases/download/v1.19.0/crictl-v1.19.0-linux-amd64.tar.gz", "version": "v1.19.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cilium', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/cilium/cilium', 'tag': 'v1.8.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "cilium", "valu
        e": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/cilium/cilium", "sha256": "", "tag": "v1.8.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cilium_init', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/cilium/cilium-init', 'tag': '2019-04-05', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "
        cilium_init", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/cilium/cilium-init", "sha256": "", "tag": "2019-04-05"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cilium_operator', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/cilium/operator', 'tag': 'v1.8.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "cil
        ium_operator", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/cilium/operator", "sha256": "", "tag": "v1.8.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'multus', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/nfvpe/multus', 'tag': 'v3.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "multus", "value
        ": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/nfvpe/multus", "sha256": "", "tag": "v3.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'flannel', 'value': {'enabled': True, 'container': True, 'repo': 'quay.io/coreos/flannel', 'tag': 'v0.13.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "flannel", "v
        alue": {"container": true, "enabled": true, "groups": ["k8s-cluster"], "repo": "quay.io/coreos/flannel", "sha256": "", "tag": "v0.13.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calicoctl', 'value': {'enabled': False, 'file': True, 'version': 'v3.16.6', 'dest': '/tmp/releases/calicoctl', 'sha256': '9b82230446d4749a1043dddd8d466d275a460e570a412e6ced003368ab9c72d8', 'url': 'https://github.com/projectcalico/c
        alicoctl/releases/download/v3.16.6/calicoctl-linux-amd64', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "calicoctl", "value": {"dest": "/tmp/releases/calicoctl", "enabl
        ed": false, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "9b82230446d4749a1043dddd8d466d275a460e570a412e6ced003368ab9c72d8", "unarchive": false, "url": "https://github.com/projectcalico/calicoctl/releases/download/v3.16.6/calicoctl-l
        inux-amd64", "version": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calico_node', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/calico/node', 'tag': 'v3.16.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "calico_nod
        e", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/calico/node", "sha256": "", "tag": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calico_cni', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/calico/cni', 'tag': 'v3.16.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "calico_cni",
         "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/calico/cni", "sha256": "", "tag": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calico_policy', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/calico/kube-controllers', 'tag': 'v3.16.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key
        ": "calico_policy", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/calico/kube-controllers", "sha256": "", "tag": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calico_typha', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/calico/typha', 'tag': 'v3.16.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "calico_t
        ypha", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/calico/typha", "sha256": "", "tag": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'weave_kube', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/weaveworks/weave-kube', 'tag': '2.7.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "w
        eave_kube", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/weaveworks/weave-kube", "sha256": "", "tag": "2.7.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'weave_npc', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/weaveworks/weave-npc', 'tag': '2.7.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "wea
        ve_npc", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/weaveworks/weave-npc", "sha256": "", "tag": "2.7.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'ovn4nfv', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/integratedcloudnative/ovn4nfv-k8s-plugin', 'tag': 'v1.1.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "
        item": {"key": "ovn4nfv", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/integratedcloudnative/ovn4nfv-k8s-plugin", "sha256": "", "tag": "v1.1.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kube_ovn', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/kubeovn/kube-ovn', 'tag': 'v1.5.2', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kube_ov
        n", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/kubeovn/kube-ovn", "sha256": "", "tag": "v1.5.2"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kube_router', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/cloudnativelabs/kube-router', 'tag': 'v1.1.1', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"
        key": "kube_router", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/cloudnativelabs/kube-router", "sha256": "", "tag": "v1.1.1"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'pod_infra', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/pause', 'tag': '3.3', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "pod_infra", "value":
         {"container": true, "enabled": true, "groups": ["k8s-cluster"], "repo": "k8s.gcr.io/pause", "sha256": "", "tag": "3.3"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'install_socat', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/xueshanf/install-socat', 'tag': 'latest', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key
        ": "install_socat", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/xueshanf/install-socat", "sha256": "", "tag": "latest"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'nginx', 'value': {'enabled': True, 'container': True, 'repo': 'docker.io/library/nginx', 'tag': 1.19, 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "nginx", "value": {"c
        ontainer": true, "enabled": true, "groups": ["kube-node"], "repo": "docker.io/library/nginx", "sha256": "", "tag": 1.19}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'haproxy', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/library/haproxy', 'tag': 2.3, 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "haproxy", "value
        ": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/library/haproxy", "sha256": "", "tag": 2.3}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'coredns', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/coredns', 'tag': '1.7.0', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "coredns", "value":
         {"container": true, "enabled": true, "groups": ["kube-master"], "repo": "k8s.gcr.io/coredns", "sha256": "", "tag": "1.7.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'nodelocaldns', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/dns/k8s-dns-node-cache', 'tag': '1.16.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key"
        : "nodelocaldns", "value": {"container": true, "enabled": true, "groups": ["k8s-cluster"], "repo": "k8s.gcr.io/dns/k8s-dns-node-cache", "sha256": "", "tag": "1.16.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'dnsautoscaler', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/cpa/cluster-proportional-autoscaler-amd64', 'tag': '1.8.3', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": fa
        lse, "item": {"key": "dnsautoscaler", "value": {"container": true, "enabled": true, "groups": ["kube-master"], "repo": "k8s.gcr.io/cpa/cluster-proportional-autoscaler-amd64", "sha256": "", "tag": "1.8.3"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'testbox', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/busybox', 'tag': 'latest', 'sha256': ''}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "testbox", "value": {"container": true, "ena
        bled": false, "repo": "k8s.gcr.io/busybox", "sha256": "", "tag": "latest"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'helm', 'value': {'enabled': False, 'file': True, 'version': 'v3.5.2', 'dest': '/tmp/releases/helm-v3.5.2/helm-v3.5.2-linux-amd64.tar.gz', 'sha256': '01b317c506f8b6ad60b11b1dc3f093276bb703281cb1ae01132752253ec706a2', 'url': 'https:/
        /get.helm.sh/helm-v3.5.2-linux-amd64.tar.gz', 'unarchive': True, 'owner': 'root', 'mode': '0755', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "helm", "value": {"dest": "/tmp/releases/helm-v3.5.2/helm-v3.5.2-linux-amd64.t
        ar.gz", "enabled": false, "file": true, "groups": ["kube-master"], "mode": "0755", "owner": "root", "sha256": "01b317c506f8b6ad60b11b1dc3f093276bb703281cb1ae01132752253ec706a2", "unarchive": true, "url": "https://get.helm.sh/helm-v3.5.2-linux-amd64.tar.gz", "version": "v3
        .5.2"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'registry', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/library/registry', 'tag': '2.7.1', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "registry",
         "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/library/registry", "sha256": "", "tag": "2.7.1"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'registry_proxy', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/kube-registry-proxy', 'tag': '0.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "re
        gistry_proxy", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "k8s.gcr.io/kube-registry-proxy", "sha256": "", "tag": "0.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'metrics_server', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/metrics-server/metrics-server', 'tag': 'v0.3.7', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "ite
        m": {"key": "metrics_server", "value": {"container": true, "enabled": false, "groups": ["kube-master"], "repo": "k8s.gcr.io/metrics-server/metrics-server", "sha256": "", "tag": "v0.3.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'addon_resizer', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/addon-resizer', 'tag': '1.8.11', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "addo
        n_resizer", "value": {"container": true, "enabled": false, "groups": ["kube-master"], "repo": "k8s.gcr.io/addon-resizer", "sha256": "", "tag": "1.8.11"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'local_volume_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/external_storage/local-volume-provisioner', 'tag': 'v2.3.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "chan
        ged": false, "item": {"key": "local_volume_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/external_storage/local-volume-provisioner", "sha256": "", "tag": "v2.3.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cephfs_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/external_storage/cephfs-provisioner', 'tag': 'v2.1.0-k8s1.11', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed"
        : false, "item": {"key": "cephfs_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/external_storage/cephfs-provisioner", "sha256": "", "tag": "v2.1.0-k8s1.11"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'rbd_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/external_storage/rbd-provisioner', 'tag': 'v2.1.1-k8s1.11', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"key": "rbd_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/external_storage/rbd-provisioner", "sha256": "", "tag": "v2.1.1-k8s1.11"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'local_path_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/rancher/local-path-provisioner', 'tag': 'v0.0.19', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"key": "local_path_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/rancher/local-path-provisioner", "sha256": "", "tag": "v0.0.19"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'ingress_nginx_controller', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/ingress-nginx/controller', 'tag': 'v0.41.2', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false,
        "item": {"key": "ingress_nginx_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "k8s.gcr.io/ingress-nginx/controller", "sha256": "", "tag": "v0.41.2"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'ingress_ambassador_controller', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/datawire/ambassador-operator', 'tag': 'v1.2.9', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fa
        lse, "item": {"key": "ingress_ambassador_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/datawire/ambassador-operator", "sha256": "", "tag": "v1.2.9"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'ingress_alb_controller', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/amazon/aws-alb-ingress-controller', 'tag': 'v1.1.9', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fa
        lse, "item": {"key": "ingress_alb_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/amazon/aws-alb-ingress-controller", "sha256": "", "tag": "v1.1.9"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cert_manager_controller', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/jetstack/cert-manager-controller', 'tag': 'v1.0.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"key": "cert_manager_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/jetstack/cert-manager-controller", "sha256": "", "tag": "v1.0.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cert_manager_cainjector', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/jetstack/cert-manager-cainjector', 'tag': 'v1.0.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"key": "cert_manager_cainjector", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/jetstack/cert-manager-cainjector", "sha256": "", "tag": "v1.0.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cert_manager_webhook', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/jetstack/cert-manager-webhook', 'tag': 'v1.0.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "it
        em": {"key": "cert_manager_webhook", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/jetstack/cert-manager-webhook", "sha256": "", "tag": "v1.0.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_attacher', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-attacher', 'tag': 'v2.2.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "csi_
        attacher", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-attacher", "sha256": "", "tag": "v2.2.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-provisioner', 'tag': 'v1.6.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key":
         "csi_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-provisioner", "sha256": "", "tag": "v1.6.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_snapshotter', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-snapshotter', 'tag': 'v2.1.1', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key":
         "csi_snapshotter", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-snapshotter", "sha256": "", "tag": "v2.1.1"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'snapshot_controller', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/snapshot-controller', 'tag': 'v2.0.1', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item":
         {"key": "snapshot_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/snapshot-controller", "sha256": "", "tag": "v2.0.1"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_resizer', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-resizer', 'tag': 'v0.5.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "csi_re
        sizer", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-resizer", "sha256": "", "tag": "v0.5.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_node_driver_registrar', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-node-driver-registrar', 'tag': 'v1.3.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fa
        lse, "item": {"key": "csi_node_driver_registrar", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-node-driver-registrar", "sha256": "", "tag": "v1.3.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cinder_csi_plugin', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/k8scloudprovider/cinder-csi-plugin', 'tag': 'v1.18.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false
        , "item": {"key": "cinder_csi_plugin", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/k8scloudprovider/cinder-csi-plugin", "sha256": "", "tag": "v1.18.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'aws_ebs_csi_plugin', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/amazon/aws-ebs-csi-driver', 'tag': 'v0.5.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item":
         {"key": "aws_ebs_csi_plugin", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/amazon/aws-ebs-csi-driver", "sha256": "", "tag": "v0.5.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'dashboard', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/kubernetesui/dashboard-amd64', 'tag': 'v2.1.0', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"k
        ey": "dashboard", "value": {"container": true, "enabled": false, "groups": ["kube-master"], "repo": "docker.io/kubernetesui/dashboard-amd64", "sha256": "", "tag": "v2.1.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'dashboard_metrics_scrapper', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/kubernetesui/metrics-scraper', 'tag': 'v1.0.6', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": f
        alse, "item": {"key": "dashboard_metrics_scrapper", "value": {"container": true, "enabled": false, "groups": ["kube-master"], "repo": "docker.io/kubernetesui/metrics-scraper", "sha256": "", "tag": "v1.0.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm_kube-apiserver', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/kube-apiserver', 'tag': 'v1.19.7', 'groups': 'k8s-cluster'}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubeadm_ku
        be-apiserver", "value": {"container": true, "enabled": true, "groups": "k8s-cluster", "repo": "k8s.gcr.io/kube-apiserver", "tag": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm_kube-controller-manager', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/kube-controller-manager', 'tag': 'v1.19.7', 'groups': 'k8s-cluster'}})  => {"ansible_loop_var": "item", "changed": false, "item": {
        "key": "kubeadm_kube-controller-manager", "value": {"container": true, "enabled": true, "groups": "k8s-cluster", "repo": "k8s.gcr.io/kube-controller-manager", "tag": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm_kube-scheduler', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/kube-scheduler', 'tag': 'v1.19.7', 'groups': 'k8s-cluster'}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubeadm_ku
        be-scheduler", "value": {"container": true, "enabled": true, "groups": "k8s-cluster", "repo": "k8s.gcr.io/kube-scheduler", "tag": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm_kube-proxy', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/kube-proxy', 'tag': 'v1.19.7', 'groups': 'k8s-cluster'}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubeadm_kube-proxy
        ", "value": {"container": true, "enabled": true, "groups": "k8s-cluster", "repo": "k8s.gcr.io/kube-proxy", "tag": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : Configure defaults] *********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/main.yaml:2
        ok: [kubenode01] => {
            "msg": "Check roles/kubespray-defaults/defaults/main.yml"
        }
        
        TASK [kubespray-defaults : Gather ansible_default_ipv4 from all hosts] *********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/fallback_ips.yml:6
        skipping: [kubenode01] => (item=kubenode01)  => {"ansible_loop_var": "delegate_host_to_gather_facts", "changed": false, "delegate_host_to_gather_facts": "kubenode01", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=kubenode01)  => {"ansible_loop_var": "delegate_host_to_gather_facts", "changed": false, "delegate_host_to_gather_facts": "kubenode01", "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : create fallback_ips_base] ***************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/fallback_ips.yml:15
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : set fallback_ips] ***********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/fallback_ips.yml:29
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : Set no_proxy to all assigned cluster IPs and hostnames] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/no_proxy.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : Populates no_proxy to all hosts] ********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/no_proxy.yml:32
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Wait for kube-apiserver] *****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/main.yml:2
        ok: [kubenode01] => {"attempts": 1, "cache_control": "no-cache, private", "changed": false, "connection": "close", "content_length": "2", "content_type": "text/plain; charset=utf-8", "cookies": {}, "cookies_string": "", "date": "Thu, 12 Aug 2021 14:56:45 GMT", "elapsed":
        0, "msg": "OK (2 bytes)", "redirected": false, "status": 200, "url": "https://127.0.0.1:6443/healthz", "x_content_type_options": "nosniff"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Register coredns deployment annotation `createdby`] **************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/cleanup_dns.yml:2
        fatal: [kubenode01]: FAILED! => {"changed": false, "cmd": "/usr/local/bin/kubectl get deploy -n kube-system coredns -o jsonpath='{ .spec.template.metadata.annotations.createdby }'", "delta": "0:00:00.126286", "end": "2021-08-12 16:56:46.205063", "msg": "non-zero return co
        de", "rc": 1, "start": "2021-08-12 16:56:46.078777", "stderr": "Error from server (NotFound): deployments.apps \"coredns\" not found", "stderr_lines": ["Error from server (NotFound): deployments.apps \"coredns\" not found"], "stdout": "", "stdout_lines": []}
        ...ignoring
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Delete kubeadm CoreDNS] ******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/cleanup_dns.yml:11
        ok: [kubenode01] => {"changed": false, "msg": "success: "}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Delete kubeadm Kube-DNS service] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/cleanup_dns.yml:23
        ok: [kubenode01] => {"changed": false, "msg": "success: "}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Lay Down CoreDNS Template] ***************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/coredns.yml:2
        changed: [kubenode01] => (item={'name': 'coredns', 'module': 'template', 'file': 'coredns-config.yml', 'type': 'configmap'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "82356ee656b0cfe778b498484e245d58b02a8c6f", "dest": "/etc/kubernetes/coredns-config.ym
        l", "gid": 0, "group": "root", "item": {"file": "coredns-config.yml", "module": "template", "name": "coredns", "type": "configmap"}, "md5sum": "8039ad1a3328161fbdf9b240d5fa4d54", "mode": "0600", "owner": "root", "size": 558, "src": "/home/wire/.ansible/tmp/ansible-tmp-162
        8780207.5721993-3214-101594001414510/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/coredns-config.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'coredns', 'module': 'copy', 'file': 'coredns-sa.yml', 'type': 'sa'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "d6d17ee78eb0d61e5525fb50797b17da9309d798", "dest": "/etc/kubernetes/coredns-sa.yml", "gid": 0, "grou
        p": "root", "item": {"file": "coredns-sa.yml", "module": "copy", "name": "coredns", "type": "sa"}, "md5sum": "8a718fbc98a6bde1af52757c742d01aa", "mode": "0600", "owner": "root", "size": 148, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780209.445194-3214-26168451400115
        4/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/coredns-sa.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'coredns', 'module': 'template', 'file': 'coredns-deployment.yml', 'type': 'deployment'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "4c8f6faa10a53d98eea5fba162f9d8e023778548", "dest": "/etc/kubernetes/coredns-depl
        oyment.yml", "gid": 0, "group": "root", "item": {"file": "coredns-deployment.yml", "module": "template", "name": "coredns", "type": "deployment"}, "md5sum": "ab70868691d0b57e0e7e3672ab57321b", "mode": "0600", "owner": "root", "size": 3067, "src": "/home/wire/.ansible/tmp/
        ansible-tmp-1628780211.2627697-3214-91898990473364/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/coredns-deployment.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'coredns', 'module': 'template', 'file': 'coredns-svc.yml', 'type': 'svc'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "7c307c7802bd01cf482ec1b4cc1b44a29f404a27", "dest": "/etc/kubernetes/coredns-svc.yml", "gid": 0
        , "group": "root", "item": {"file": "coredns-svc.yml", "module": "template", "name": "coredns", "type": "svc"}, "md5sum": "e0549dd30a48627b611c30686d975c68", "mode": "0600", "owner": "root", "size": 512, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780213.094574-3214-2
        67177771852494/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/coredns-svc.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'coredns', 'module': 'copy', 'file': 'coredns-clusterrole.yml', 'type': 'clusterrole'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "423ea49425b12e5470028a9813d9996523a656b0", "dest": "/etc/kubernetes/coredns-cluste
        rrole.yml", "gid": 0, "group": "root", "item": {"file": "coredns-clusterrole.yml", "module": "copy", "name": "coredns", "type": "clusterrole"}, "md5sum": "7d445083884884bc8c459ea69329fab5", "mode": "0600", "owner": "root", "size": 431, "src": "/home/wire/.ansible/tmp/ansi
        ble-tmp-1628780214.932044-3214-57005472596764/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/coredns-clusterrole.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'coredns', 'module': 'copy', 'file': 'coredns-clusterrolebinding.yml', 'type': 'clusterrolebinding'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "27b881209cb41225b20ab14bc9bdca6e45c45750", "dest": "/etc/kubernetes/
        coredns-clusterrolebinding.yml", "gid": 0, "group": "root", "item": {"file": "coredns-clusterrolebinding.yml", "module": "copy", "name": "coredns", "type": "clusterrolebinding"}, "md5sum": "751c8b9b4b4de0d14eae5d3f4fc1f208", "mode": "0600", "owner": "root", "size": 451, "
        src": "/home/wire/.ansible/tmp/ansible-tmp-1628780216.7333646-3214-162447771165667/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/coredns-clusterrolebinding.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode
        ' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'dns-autoscaler', 'module': 'copy', 'file': 'dns-autoscaler-sa.yml', 'type': 'sa'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "9d96dcf2256bb4968a45d09e9232666384e83f2e", "dest": "/etc/kubernetes/dns-autoscaler-sa.
        yml", "gid": 0, "group": "root", "item": {"file": "dns-autoscaler-sa.yml", "module": "copy", "name": "dns-autoscaler", "type": "sa"}, "md5sum": "a111f82d5400ea2f9af53e9d6e627b6c", "mode": "0600", "owner": "root", "size": 763, "src": "/home/wire/.ansible/tmp/ansible-tmp-16
        28780218.4831443-3214-42711154623161/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/dns-autoscaler-sa.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'dns-autoscaler', 'module': 'copy', 'file': 'dns-autoscaler-clusterrole.yml', 'type': 'clusterrole'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "f5047c80df26d815fbc5873fc47b9d7c31a0aa0f", "dest": "/etc/kubernetes/
        dns-autoscaler-clusterrole.yml", "gid": 0, "group": "root", "item": {"file": "dns-autoscaler-clusterrole.yml", "module": "copy", "name": "dns-autoscaler", "type": "clusterrole"}, "md5sum": "859012d2b25325835b044a62cc0226bc", "mode": "0600", "owner": "root", "size": 1150,
        "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780220.2104409-3214-218717179784374/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/dns-autoscaler-clusterrole.yml' created with default permissions '600'. The previous default was '666'. Specify 'mod
        e' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'dns-autoscaler', 'module': 'copy', 'file': 'dns-autoscaler-clusterrolebinding.yml', 'type': 'clusterrolebinding'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "5c5b302e4cd73c2ec5ceb5262b2bd608173faccc", "dest": "/e
        tc/kubernetes/dns-autoscaler-clusterrolebinding.yml", "gid": 0, "group": "root", "item": {"file": "dns-autoscaler-clusterrolebinding.yml", "module": "copy", "name": "dns-autoscaler", "type": "clusterrolebinding"}, "md5sum": "7f8769d1e1b5cd33313edea39550fb6a", "mode": "060
        0", "owner": "root", "size": 959, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780222.0366988-3214-85538403255174/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/dns-autoscaler-clusterrolebinding.yml' created with default permissions '600'. The
        previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'dns-autoscaler', 'module': 'template', 'file': 'dns-autoscaler.yml', 'type': 'deployment'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "28a0e6d3df25d8402b6dee317b2b48e94e0fd208", "dest": "/etc/kubernetes/dns-autos
        caler.yml", "gid": 0, "group": "root", "item": {"file": "dns-autoscaler.yml", "module": "template", "name": "dns-autoscaler", "type": "deployment"}, "md5sum": "ea998ad8a6a066e021258a5ffc2fa6af", "mode": "0600", "owner": "root", "size": 2542, "src": "/home/wire/.ansible/tm
        p/ansible-tmp-1628780223.8358757-3214-16041735255071/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/dns-autoscaler.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        [WARNING]: File '/etc/kubernetes/coredns-config.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/coredns-sa.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/coredns-deployment.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/coredns-svc.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/coredns-clusterrole.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/coredns-clusterrolebinding.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/dns-autoscaler-sa.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/dns-autoscaler-clusterrole.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/dns-autoscaler-clusterrolebinding.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/dns-autoscaler.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Lay Down Secondary CoreDNS Template] *****************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/coredns.yml:27
        skipping: [kubenode01] => (item={'name': 'coredns', 'src': 'coredns-deployment.yml', 'file': 'coredns-deployment-secondary.yml', 'type': 'deployment'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "coredns-deployment-secondary.yml", "name": "coredns
        ", "src": "coredns-deployment.yml", "type": "deployment"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'coredns', 'src': 'coredns-svc.yml', 'file': 'coredns-svc-secondary.yml', 'type': 'svc'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "coredns-svc-secondary.yml", "name": "coredns", "src": "coredns-svc.yml",
         "type": "svc"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'dns-autoscaler', 'src': 'dns-autoscaler.yml', 'file': 'coredns-autoscaler-secondary.yml', 'type': 'deployment'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "coredns-autoscaler-secondary.yml", "name": "dns-
        autoscaler", "src": "dns-autoscaler.yml", "type": "deployment"}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | set up necessary nodelocaldns parameters] ************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/nodelocaldns.yml:2
        ok: [kubenode01] => {"ansible_facts": {"primaryClusterIP": "10.233.0.3", "secondaryclusterIP": "10.233.0.4"}, "changed": false}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Lay Down nodelocaldns Template] **********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/nodelocaldns.yml:18
        changed: [kubenode01] => (item={'name': 'nodelocaldns', 'file': 'nodelocaldns-config.yml', 'type': 'configmap'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "7f596d25085a985b19f569ce893494e4c25a6fdd", "dest": "/etc/kubernetes/nodelocaldns-config.yml", "gi
        d": 0, "group": "root", "item": {"file": "nodelocaldns-config.yml", "name": "nodelocaldns", "type": "configmap"}, "md5sum": "e9fe4f4535a8d30ec7ffc40f8f3cf750", "mode": "0600", "owner": "root", "size": 1035, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780225.8679683-33
        00-278799555854809/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/nodelocaldns-config.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'nodelocaldns', 'file': 'nodelocaldns-sa.yml', 'type': 'sa'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "aa80f91dc256a7e0812b32e5dbeb5fe895e554e6", "dest": "/etc/kubernetes/nodelocaldns-sa.yml", "gid": 0, "group":
         "root", "item": {"file": "nodelocaldns-sa.yml", "name": "nodelocaldns", "type": "sa"}, "md5sum": "0c026246f6aa8648cd470b27feee7778", "mode": "0600", "owner": "root", "size": 149, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780227.7055478-3300-262588815161404/source",
         "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/nodelocaldns-sa.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        changed: [kubenode01] => (item={'name': 'nodelocaldns', 'file': 'nodelocaldns-daemonset.yml', 'type': 'daemonset'}) => {"ansible_loop_var": "item", "changed": true, "checksum": "3f14a02f5bdc6cbd547e995b89bd4517f8f8ee09", "dest": "/etc/kubernetes/nodelocaldns-daemonset.yml
        ", "gid": 0, "group": "root", "item": {"file": "nodelocaldns-daemonset.yml", "name": "nodelocaldns", "type": "daemonset"}, "md5sum": "3869e2461675e6101bfd18fcecea7b58", "mode": "0600", "owner": "root", "size": 2560, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780229.3
        94996-3300-239235895529002/source", "state": "file", "uid": 0, "warnings": ["File '/etc/kubernetes/nodelocaldns-daemonset.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        [WARNING]: File '/etc/kubernetes/nodelocaldns-config.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/nodelocaldns-sa.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        [WARNING]: File '/etc/kubernetes/nodelocaldns-daemonset.yml' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Start Resources] *************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/main.yml:39
        ok: [kubenode01] => (item=coredns-config.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "82356ee656b0cfe778b498484e245d58b02a8c6f", "dest": "/etc/kubernetes/coredns-config.yml", "diff
        ": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "coredns-config.yml.j2", "attributes": null, "backup": false, "checksum": "82356ee656b0cfe778b498484e245d58b02a8c6f", "content": null, "delimiter": null, "dest": "/etc/
        kubernetes/coredns-config.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": null, "src": "/home/wir
        e/.ansible/tmp/ansible-tmp-1628780207.5721993-3214-101594001414510/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "coredns-config.yml", "module": "template", "name": "coredns", "type": "configmap"}, "md5sum": "8039ad1a3328161fbdf9b240d5fa4d54", "mode
        ": "0600", "owner": "root", "size": 558, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780207.5721993-3214-101594001414510/source", "state": "file", "uid": 0}, "msg": "success: configmap/coredns created"}
        ok: [kubenode01] => (item=coredns-sa.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "d6d17ee78eb0d61e5525fb50797b17da9309d798", "dest": "/etc/kubernetes/coredns-sa.yml", "diff": [], "
        failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "coredns-sa.yml", "attributes": null, "backup": false, "checksum": "d6d17ee78eb0d61e5525fb50797b17da9309d798", "content": null, "delimiter": null, "dest": "/etc/kubernetes/core
        dns-sa.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": null, "src": "/home/wire/.ansible/tmp/ansi
        ble-tmp-1628780209.445194-3214-261684514001154/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "coredns-sa.yml", "module": "copy", "name": "coredns", "type": "sa"}, "md5sum": "8a718fbc98a6bde1af52757c742d01aa", "mode": "0600", "owner": "root", "size":
         148, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780209.445194-3214-261684514001154/source", "state": "file", "uid": 0}, "msg": "success: serviceaccount/coredns created"}
        ok: [kubenode01] => (item=coredns-deployment.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "4c8f6faa10a53d98eea5fba162f9d8e023778548", "dest": "/etc/kubernetes/coredns-deployment.yml
        ", "diff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "coredns-deployment.yml.j2", "attributes": null, "backup": false, "checksum": "4c8f6faa10a53d98eea5fba162f9d8e023778548", "content": null, "delimiter": null, "d
        est": "/etc/kubernetes/coredns-deployment.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": null, "
        src": "/home/wire/.ansible/tmp/ansible-tmp-1628780211.2627697-3214-91898990473364/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "coredns-deployment.yml", "module": "template", "name": "coredns", "type": "deployment"}, "md5sum": "ab70868691d0b57e0e7e
        3672ab57321b", "mode": "0600", "owner": "root", "size": 3067, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780211.2627697-3214-91898990473364/source", "state": "file", "uid": 0}, "msg": "success: deployment.apps/coredns created"}
        ok: [kubenode01] => (item=coredns-svc.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "7c307c7802bd01cf482ec1b4cc1b44a29f404a27", "dest": "/etc/kubernetes/coredns-svc.yml", "diff": [],
         "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "coredns-svc.yml.j2", "attributes": null, "backup": false, "checksum": "7c307c7802bd01cf482ec1b4cc1b44a29f404a27", "content": null, "delimiter": null, "dest": "/etc/kubernete
        s/coredns-svc.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": null, "src": "/home/wire/.ansible/t
        mp/ansible-tmp-1628780213.094574-3214-267177771852494/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "coredns-svc.yml", "module": "template", "name": "coredns", "type": "svc"}, "md5sum": "e0549dd30a48627b611c30686d975c68", "mode": "0600", "owner": "r
        oot", "size": 512, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780213.094574-3214-267177771852494/source", "state": "file", "uid": 0}, "msg": "success: service/coredns created"}
        ok: [kubenode01] => (item=coredns-clusterrole.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "423ea49425b12e5470028a9813d9996523a656b0", "dest": "/etc/kubernetes/coredns-clusterrole.y
        ml", "diff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "coredns-clusterrole.yml", "attributes": null, "backup": false, "checksum": "423ea49425b12e5470028a9813d9996523a656b0", "content": null, "delimiter": null, "d
        est": "/etc/kubernetes/coredns-clusterrole.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": null,
        "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780214.932044-3214-57005472596764/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "coredns-clusterrole.yml", "module": "copy", "name": "coredns", "type": "clusterrole"}, "md5sum": "7d445083884884bc8c459e
        a69329fab5", "mode": "0600", "owner": "root", "size": 431, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780214.932044-3214-57005472596764/source", "state": "file", "uid": 0}, "msg": "success: clusterrole.rbac.authorization.k8s.io/system:coredns created"}
        ok: [kubenode01] => (item=coredns-clusterrolebinding.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "27b881209cb41225b20ab14bc9bdca6e45c45750", "dest": "/etc/kubernetes/coredns-cluste
        rrolebinding.yml", "diff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "coredns-clusterrolebinding.yml", "attributes": null, "backup": false, "checksum": "27b881209cb41225b20ab14bc9bdca6e45c45750", "content": null,
        "delimiter": null, "dest": "/etc/kubernetes/coredns-clusterrolebinding.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "set
        ype": null, "seuser": null, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780216.7333646-3214-162447771165667/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "coredns-clusterrolebinding.yml", "module": "copy", "name": "coredns", "type": "clusterrole
        binding"}, "md5sum": "751c8b9b4b4de0d14eae5d3f4fc1f208", "mode": "0600", "owner": "root", "size": 451, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780216.7333646-3214-162447771165667/source", "state": "file", "uid": 0}, "msg": "success: clusterrolebinding.rbac.authori
        zation.k8s.io/system:coredns created"}
        ok: [kubenode01] => (item=dns-autoscaler-sa.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "9d96dcf2256bb4968a45d09e9232666384e83f2e", "dest": "/etc/kubernetes/dns-autoscaler-sa.yml",
         "diff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "dns-autoscaler-sa.yml", "attributes": null, "backup": false, "checksum": "9d96dcf2256bb4968a45d09e9232666384e83f2e", "content": null, "delimiter": null, "dest":
        "/etc/kubernetes/dns-autoscaler-sa.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": null, "src": "
        /home/wire/.ansible/tmp/ansible-tmp-1628780218.4831443-3214-42711154623161/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "dns-autoscaler-sa.yml", "module": "copy", "name": "dns-autoscaler", "type": "sa"}, "md5sum": "a111f82d5400ea2f9af53e9d6e627b6c"
        , "mode": "0600", "owner": "root", "size": 763, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780218.4831443-3214-42711154623161/source", "state": "file", "uid": 0}, "msg": "success: serviceaccount/dns-autoscaler created"}
        ok: [kubenode01] => (item=dns-autoscaler-clusterrole.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "f5047c80df26d815fbc5873fc47b9d7c31a0aa0f", "dest": "/etc/kubernetes/dns-autoscaler
        -clusterrole.yml", "diff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "dns-autoscaler-clusterrole.yml", "attributes": null, "backup": false, "checksum": "f5047c80df26d815fbc5873fc47b9d7c31a0aa0f", "content": null,
        "delimiter": null, "dest": "/etc/kubernetes/dns-autoscaler-clusterrole.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "set
        ype": null, "seuser": null, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780220.2104409-3214-218717179784374/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "dns-autoscaler-clusterrole.yml", "module": "copy", "name": "dns-autoscaler", "type": "clus
        terrole"}, "md5sum": "859012d2b25325835b044a62cc0226bc", "mode": "0600", "owner": "root", "size": 1150, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780220.2104409-3214-218717179784374/source", "state": "file", "uid": 0}, "msg": "success: clusterrole.rbac.authorization
        .k8s.io/system:dns-autoscaler created"}
        ok: [kubenode01] => (item=dns-autoscaler-clusterrolebinding.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "5c5b302e4cd73c2ec5ceb5262b2bd608173faccc", "dest": "/etc/kubernetes/dns-aut
        oscaler-clusterrolebinding.yml", "diff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "dns-autoscaler-clusterrolebinding.yml", "attributes": null, "backup": false, "checksum": "5c5b302e4cd73c2ec5ceb5262b2bd608173facc
        c", "content": null, "delimiter": null, "dest": "/etc/kubernetes/dns-autoscaler-clusterrolebinding.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel"
        : null, "serole": null, "setype": null, "seuser": null, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780222.0366988-3214-85538403255174/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "dns-autoscaler-clusterrolebinding.yml", "module": "copy", "name
        ": "dns-autoscaler", "type": "clusterrolebinding"}, "md5sum": "7f8769d1e1b5cd33313edea39550fb6a", "mode": "0600", "owner": "root", "size": 959, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780222.0366988-3214-85538403255174/source", "state": "file", "uid": 0}, "msg": "
        success: clusterrolebinding.rbac.authorization.k8s.io/system:dns-autoscaler created"}
        ok: [kubenode01] => (item=dns-autoscaler.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "28a0e6d3df25d8402b6dee317b2b48e94e0fd208", "dest": "/etc/kubernetes/dns-autoscaler.yml", "diff
        ": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "dns-autoscaler.yml.j2", "attributes": null, "backup": false, "checksum": "28a0e6d3df25d8402b6dee317b2b48e94e0fd208", "content": null, "delimiter": null, "dest": "/etc/
        kubernetes/dns-autoscaler.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": null, "src": "/home/wir
        e/.ansible/tmp/ansible-tmp-1628780223.8358757-3214-16041735255071/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "dns-autoscaler.yml", "module": "template", "name": "dns-autoscaler", "type": "deployment"}, "md5sum": "ea998ad8a6a066e021258a5ffc2fa6af"
        , "mode": "0600", "owner": "root", "size": 2542, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780223.8358757-3214-16041735255071/source", "state": "file", "uid": 0}, "msg": "success: deployment.apps/dns-autoscaler created"}
        skipping: [kubenode01] => (item=coredns-deployment-secondary.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "coredns-deployment-secondary.yml", "name": "coredns", "src": "coredns-deployment.y
        ml", "type": "deployment"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=coredns-svc-secondary.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "coredns-svc-secondary.yml", "name": "coredns", "src": "coredns-svc.yml", "type": "svc"},
        "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=coredns-autoscaler-secondary.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "coredns-autoscaler-secondary.yml", "name": "dns-autoscaler", "src": "dns-autoscale
        r.yml", "type": "deployment"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        ok: [kubenode01] => (item=nodelocaldns-config.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "7f596d25085a985b19f569ce893494e4c25a6fdd", "dest": "/etc/kubernetes/nodelocaldns-config.y
        ml", "diff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "nodelocaldns-config.yml.j2", "attributes": null, "backup": false, "checksum": "7f596d25085a985b19f569ce893494e4c25a6fdd", "content": null, "delimiter": null,
         "dest": "/etc/kubernetes/nodelocaldns-config.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": nul
        l, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780225.8679683-3300-278799555854809/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "nodelocaldns-config.yml", "name": "nodelocaldns", "type": "configmap"}, "md5sum": "e9fe4f4535a8d30ec7ffc40f8f3cf750
        ", "mode": "0600", "owner": "root", "size": 1035, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780225.8679683-3300-278799555854809/source", "state": "file", "uid": 0}, "msg": "success: configmap/nodelocaldns created"}
        ok: [kubenode01] => (item=nodelocaldns-sa.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "aa80f91dc256a7e0812b32e5dbeb5fe895e554e6", "dest": "/etc/kubernetes/nodelocaldns-sa.yml", "di
        ff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "nodelocaldns-sa.yml.j2", "attributes": null, "backup": false, "checksum": "aa80f91dc256a7e0812b32e5dbeb5fe895e554e6", "content": null, "delimiter": null, "dest": "/e
        tc/kubernetes/nodelocaldns-sa.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "seuser": null, "src": "/home
        /wire/.ansible/tmp/ansible-tmp-1628780227.7055478-3300-262588815161404/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "nodelocaldns-sa.yml", "name": "nodelocaldns", "type": "sa"}, "md5sum": "0c026246f6aa8648cd470b27feee7778", "mode": "0600", "owner":
         "root", "size": 149, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780227.7055478-3300-262588815161404/source", "state": "file", "uid": 0}, "msg": "success: serviceaccount/nodelocaldns created"}
        ok: [kubenode01] => (item=nodelocaldns-daemonset.yml) => {"ansible_loop_var": "item", "attempts": 1, "changed": false, "item": {"ansible_loop_var": "item", "changed": true, "checksum": "3f14a02f5bdc6cbd547e995b89bd4517f8f8ee09", "dest": "/etc/kubernetes/nodelocaldns-daemo
        nset.yml", "diff": [], "failed": false, "gid": 0, "group": "root", "invocation": {"module_args": {"_original_basename": "nodelocaldns-daemonset.yml.j2", "attributes": null, "backup": false, "checksum": "3f14a02f5bdc6cbd547e995b89bd4517f8f8ee09", "content": null, "delimite
        r": null, "dest": "/etc/kubernetes/nodelocaldns-daemonset.yml", "directory_mode": null, "follow": false, "force": true, "group": null, "local_follow": null, "mode": null, "owner": null, "regexp": null, "remote_src": null, "selevel": null, "serole": null, "setype": null, "
        seuser": null, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780229.394996-3300-239235895529002/source", "unsafe_writes": null, "validate": null}}, "item": {"file": "nodelocaldns-daemonset.yml", "name": "nodelocaldns", "type": "daemonset"}, "md5sum": "3869e2461675e6101b
        fd18fcecea7b58", "mode": "0600", "owner": "root", "size": 2560, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780229.394996-3300-239235895529002/source", "state": "file", "uid": 0}, "msg": "success: daemonset.apps/nodelocaldns created"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Netchecker Templates list] ***************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/netchecker.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Append extra templates to Netchecker Templates list for PodSecurityPolicy] ***************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/netchecker.yml:19
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Lay Down Netchecker Template] ************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/netchecker.yml:24
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Start Netchecker Resources] **************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/netchecker.yml:33
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Lay down dashboard template] *************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/dashboard.yml:2
        skipping: [kubenode01] => (item={'file': 'dashboard.yml', 'type': 'deploy', 'name': 'kubernetes-dashboard'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "dashboard.yml", "name": "kubernetes-dashboard", "type": "deploy"}, "skip_reason": "Conditional
         result was False"}
        
        TASK [kubernetes-apps/ansible : Kubernetes Apps | Start dashboard] *************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/ansible/tasks/dashboard.yml:11
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'file': 'dashboard.yml', 'type': 'deploy', 'name': 'kubernetes-dashboard'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed":
         false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "dashboard.yml", "name": "kubernetes-dashboard", "type": "deploy"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/helm : Helm | Download helm] *****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/helm/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/helm : Copy helm binary from download dir] ***************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/helm/tasks/main.yml:7
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/helm : Check if bash_completion.d folder exists] *********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/helm/tasks/main.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/helm : Get helm completion] ******************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/helm/tasks/main.yml:22
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/helm : Install helm completion] **************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/helm/tasks/main.yml:29
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/registry : Registry | Create addon dir] ******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/registry/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/registry : Registry | Templates list] ********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/registry/tasks/main.yml:11
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/registry : Registry | Append extra templates to Registry Templates list for PodSecurityPolicy] ***********************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/registry/tasks/main.yml:28
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/registry : Registry | Create manifests] ******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/registry/tasks/main.yml:35
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/registry : Registry | Apply manifests] *******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/registry/tasks/main.yml:43
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/registry : Registry | Create PVC manifests] **************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/registry/tasks/main.yml:54
        skipping: [kubenode01] => (item={'name': 'registry-pvc', 'file': 'registry-pvc.yml', 'type': 'pvc'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "registry-pvc.yml", "name": "registry-pvc", "type": "pvc"}, "skip_reason": "Conditional result was Fals
        e"}
        
        TASK [kubernetes-apps/registry : Registry | Apply PVC manifests] ***************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/registry/tasks/main.yml:66
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'registry-pvc', 'file': 'registry-pvc.yml', 'type': 'pvc'}, 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": false,
        "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "registry-pvc.yml", "name": "registry-pvc", "type": "pvc"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metrics_server : Check all masters are node or not] ******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metrics_server/tasks/main.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metrics_server : Metrics Server | Delete addon dir] ******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metrics_server/tasks/main.yml:7
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metrics_server : Metrics Server | Create addon dir] ******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metrics_server/tasks/main.yml:16
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metrics_server : Metrics Server | Templates list] ********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metrics_server/tasks/main.yml:26
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metrics_server : Metrics Server | Create manifests] ******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metrics_server/tasks/main.yml:39
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metrics_server : Metrics Server | Apply manifests] *******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metrics_server/tasks/main.yml:48
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/csi_crd : CSI CRD | Generate Manifests] *******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/csi_crd/tasks/main.yml:2
        skipping: [kubenode01] => (item={'name': 'volumesnapshotclasses', 'file': 'volumesnapshotclasses.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "volumesnapshotclasses.yml", "name": "volumesnapshotclasses"}, "skip_reason": "Conditional result wa
        s False"}
        skipping: [kubenode01] => (item={'name': 'volumesnapshotcontents', 'file': 'volumesnapshotcontents.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "volumesnapshotcontents.yml", "name": "volumesnapshotcontents"}, "skip_reason": "Conditional resul
        t was False"}
        skipping: [kubenode01] => (item={'name': 'volumesnapshots', 'file': 'volumesnapshots.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "volumesnapshots.yml", "name": "volumesnapshots"}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/csi_crd : CSI CRD | Apply Manifests] **********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/csi_crd/tasks/main.yml:14
        skipping: [kubenode01] => (item=volumesnapshotclasses.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "volumesnapshotclasses.yml", "name": "volumesnapshotclasses"}, "skip_reason": "Conditional
         result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=volumesnapshotcontents.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "volumesnapshotcontents.yml", "name": "volumesnapshotcontents"}, "skip_reason": "Conditio
        nal result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=volumesnapshots.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "volumesnapshots.yml", "name": "volumesnapshots"}, "skip_reason": "Conditional result was False"
        , "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/cinder : include_tasks] ***********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/cinder/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/cinder : Cinder CSI Driver | Write cacert file] ***********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/cinder/tasks/main.yml:5
        skipping: [kubenode01] => (item=kubenode01)  => {"ansible_loop_var": "delegate_host_to_write_cacert", "changed": false, "delegate_host_to_write_cacert": "kubenode01", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/cinder : Cinder CSI Driver | Write Cinder cloud-config] ***************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/cinder/tasks/main.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/cinder : Cinder CSI Driver | Get base64 cloud-config] *****************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/cinder/tasks/main.yml:26
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/cinder : Cinder CSI Driver | Generate Manifests] **********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/cinder/tasks/main.yml:33
        skipping: [kubenode01] => (item={'name': 'cinder-csi-driver', 'file': 'cinder-csi-driver.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-driver.yml", "name": "cinder-csi-driver"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'cinder-csi-cloud-config-secret', 'file': 'cinder-csi-cloud-config-secret.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-cloud-config-secret.yml", "name": "cinder-csi-cloud-config-secret"}, "
        skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'cinder-csi-controllerplugin', 'file': 'cinder-csi-controllerplugin-rbac.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-controllerplugin-rbac.yml", "name": "cinder-csi-controllerplugin"}, "sk
        ip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'cinder-csi-controllerplugin', 'file': 'cinder-csi-controllerplugin.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-controllerplugin.yml", "name": "cinder-csi-controllerplugin"}, "skip_reason"
        : "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'cinder-csi-nodeplugin', 'file': 'cinder-csi-nodeplugin-rbac.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-nodeplugin-rbac.yml", "name": "cinder-csi-nodeplugin"}, "skip_reason": "Conditional
         result was False"}
        skipping: [kubenode01] => (item={'name': 'cinder-csi-nodeplugin', 'file': 'cinder-csi-nodeplugin.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-nodeplugin.yml", "name": "cinder-csi-nodeplugin"}, "skip_reason": "Conditional result wa
        s False"}
        skipping: [kubenode01] => (item={'name': 'cinder-csi-poddisruptionbudget', 'file': 'cinder-csi-poddisruptionbudget.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-poddisruptionbudget.yml", "name": "cinder-csi-poddisruptionbudget"}, "
        skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/cinder : Cinder CSI Driver | Apply Manifests] *************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/cinder/tasks/main.yml:49
        skipping: [kubenode01] => (item=cinder-csi-driver.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-driver.yml", "name": "cinder-csi-driver"}, "skip_reason": "Conditional result was
        False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=cinder-csi-cloud-config-secret.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-cloud-config-secret.yml", "name": "cinder-csi-cloud-config-secret"},
        "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=cinder-csi-controllerplugin-rbac.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-controllerplugin-rbac.yml", "name": "cinder-csi-controllerplugin"},
         "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=cinder-csi-controllerplugin.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-controllerplugin.yml", "name": "cinder-csi-controllerplugin"}, "skip_rea
        son": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=cinder-csi-nodeplugin-rbac.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-nodeplugin-rbac.yml", "name": "cinder-csi-nodeplugin"}, "skip_reason": "C
        onditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=cinder-csi-nodeplugin.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-nodeplugin.yml", "name": "cinder-csi-nodeplugin"}, "skip_reason": "Conditional
         result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=cinder-csi-poddisruptionbudget.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "cinder-csi-poddisruptionbudget.yml", "name": "cinder-csi-poddisruptionbudget"},
        "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/aws_ebs : AWS CSI Driver | Generate Manifests] ************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/aws_ebs/tasks/main.yml:2
        skipping: [kubenode01] => (item={'name': 'aws-ebs-csi-driver', 'file': 'aws-ebs-csi-driver.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "aws-ebs-csi-driver.yml", "name": "aws-ebs-csi-driver"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'aws-ebs-csi-controllerservice', 'file': 'aws-ebs-csi-controllerservice-rbac.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "aws-ebs-csi-controllerservice-rbac.yml", "name": "aws-ebs-csi-controllerservic
        e"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'aws-ebs-csi-controllerservice', 'file': 'aws-ebs-csi-controllerservice.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "aws-ebs-csi-controllerservice.yml", "name": "aws-ebs-csi-controllerservice"}, "skip
        _reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'aws-ebs-csi-nodeservice', 'file': 'aws-ebs-csi-nodeservice.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "aws-ebs-csi-nodeservice.yml", "name": "aws-ebs-csi-nodeservice"}, "skip_reason": "Conditional r
        esult was False"}
        
        TASK [kubernetes-apps/csi_driver/aws_ebs : AWS CSI Driver | Apply Manifests] ***************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/aws_ebs/tasks/main.yml:15
        skipping: [kubenode01] => (item=aws-ebs-csi-driver.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "aws-ebs-csi-driver.yml", "name": "aws-ebs-csi-driver"}, "skip_reason": "Conditional result w
        as False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=aws-ebs-csi-controllerservice-rbac.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "aws-ebs-csi-controllerservice-rbac.yml", "name": "aws-ebs-csi-controllerserv
        ice"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=aws-ebs-csi-controllerservice.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "aws-ebs-csi-controllerservice.yml", "name": "aws-ebs-csi-controllerservice"}, "sk
        ip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=aws-ebs-csi-nodeservice.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "aws-ebs-csi-nodeservice.yml", "name": "aws-ebs-csi-nodeservice"}, "skip_reason": "Condi
        tional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/azuredisk : include_tasks] ********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/azuredisk/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/azuredisk : Azure CSI Driver | Write Azure CSI cloud-config] **********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/azuredisk/tasks/main.yml:5
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/azuredisk : Azure CSI Driver | Get base64 cloud-config] ***************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/azuredisk/tasks/main.yml:14
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/azuredisk : Azure CSI Driver | Generate Manifests] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/azuredisk/tasks/main.yml:21
        skipping: [kubenode01] => (item={'name': 'azure-csi-azuredisk-driver', 'file': 'azure-csi-azuredisk-driver.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-azuredisk-driver.yml", "name": "azure-csi-azuredisk-driver"}, "skip_reason": "C
        onditional result was False"}
        skipping: [kubenode01] => (item={'name': 'azure-csi-cloud-config-secret', 'file': 'azure-csi-cloud-config-secret.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-cloud-config-secret.yml", "name": "azure-csi-cloud-config-secret"}, "skip
        _reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'azure-csi-azuredisk-controller', 'file': 'azure-csi-azuredisk-controller-rbac.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-azuredisk-controller-rbac.yml", "name": "azure-csi-azuredisk-contr
        oller"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'azure-csi-azuredisk-controller', 'file': 'azure-csi-azuredisk-controller.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-azuredisk-controller.yml", "name": "azure-csi-azuredisk-controller"}, "
        skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'azure-csi-azuredisk-node', 'file': 'azure-csi-azuredisk-node.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-azuredisk-node.yml", "name": "azure-csi-azuredisk-node"}, "skip_reason": "Condition
        al result was False"}
        skipping: [kubenode01] => (item={'name': 'azure-csi-node-info-crd.yml.j2', 'file': 'azure-csi-node-info-crd.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-node-info-crd.yml", "name": "azure-csi-node-info-crd.yml.j2"}, "skip_reason":
        "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/azuredisk : Azure CSI Driver | Apply Manifests] ***********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/azuredisk/tasks/main.yml:36
        skipping: [kubenode01] => (item=azure-csi-azuredisk-driver.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-azuredisk-driver.yml", "name": "azure-csi-azuredisk-driver"}, "skip_reason
        ": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=azure-csi-cloud-config-secret.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-cloud-config-secret.yml", "name": "azure-csi-cloud-config-secret"}, "sk
        ip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=azure-csi-azuredisk-controller-rbac.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-azuredisk-controller-rbac.yml", "name": "azure-csi-azuredisk-cont
        roller"}, "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=azure-csi-azuredisk-controller.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-azuredisk-controller.yml", "name": "azure-csi-azuredisk-controller"},
        "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=azure-csi-azuredisk-node.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-azuredisk-node.yml", "name": "azure-csi-azuredisk-node"}, "skip_reason": "Co
        nditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=azure-csi-node-info-crd.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "azure-csi-node-info-crd.yml", "name": "azure-csi-node-info-crd.yml.j2"}, "skip_reason":
         "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/gcp_pd : GCP PD CSI Driver | Check if cloud-sa.json exists] ***********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/gcp_pd/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/gcp_pd : GCP PD CSI Driver | Copy GCP credentials file] ***************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/gcp_pd/tasks/main.yml:8
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/gcp_pd : GCP PD CSI Driver | Get base64 cloud-sa.json] ****************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/gcp_pd/tasks/main.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/gcp_pd : GCP PD CSI Driver | Generate Manifests] **********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/gcp_pd/tasks/main.yml:24
        skipping: [kubenode01] => (item={'name': 'gcp-pd-csi-cred-secret', 'file': 'gcp-pd-csi-cred-secret.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "gcp-pd-csi-cred-secret.yml", "name": "gcp-pd-csi-cred-secret"}, "skip_reason": "Conditional resul
        t was False"}
        skipping: [kubenode01] => (item={'name': 'gcp-pd-csi-setup', 'file': 'gcp-pd-csi-setup.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "gcp-pd-csi-setup.yml", "name": "gcp-pd-csi-setup"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'gcp-pd-csi-controller', 'file': 'gcp-pd-csi-controller.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "gcp-pd-csi-controller.yml", "name": "gcp-pd-csi-controller"}, "skip_reason": "Conditional result wa
        s False"}
        skipping: [kubenode01] => (item={'name': 'gcp-pd-csi-node', 'file': 'gcp-pd-csi-node.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "gcp-pd-csi-node.yml", "name": "gcp-pd-csi-node"}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/gcp_pd : GCP PD CSI Driver | Apply Manifests] *************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/gcp_pd/tasks/main.yml:37
        skipping: [kubenode01] => (item=gcp-pd-csi-cred-secret.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "gcp-pd-csi-cred-secret.yml", "name": "gcp-pd-csi-cred-secret"}, "skip_reason": "Conditio
        nal result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=gcp-pd-csi-setup.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "gcp-pd-csi-setup.yml", "name": "gcp-pd-csi-setup"}, "skip_reason": "Conditional result was Fal
        se", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=gcp-pd-csi-controller.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "gcp-pd-csi-controller.yml", "name": "gcp-pd-csi-controller"}, "skip_reason": "Conditional
         result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=gcp-pd-csi-node.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "gcp-pd-csi-node.yml", "name": "gcp-pd-csi-node"}, "skip_reason": "Conditional result was False"
        , "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/vsphere : include_tasks] **********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/vsphere/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/vsphere : vSphere CSI Driver | Generate CSI cloud-config] *************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/vsphere/tasks/main.yml:5
        skipping: [kubenode01] => (item=vsphere-csi-cloud-config)  => {"ansible_loop_var": "item", "changed": false, "item": "vsphere-csi-cloud-config", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/vsphere : vSphere CSI Driver | Generate Manifests] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/vsphere/tasks/main.yml:15
        skipping: [kubenode01] => (item=vsphere-csi-controller-rbac.yml)  => {"ansible_loop_var": "item", "changed": false, "item": "vsphere-csi-controller-rbac.yml", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=vsphere-csi-controller-ss.yml)  => {"ansible_loop_var": "item", "changed": false, "item": "vsphere-csi-controller-ss.yml", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=vsphere-csi-node.yml)  => {"ansible_loop_var": "item", "changed": false, "item": "vsphere-csi-node.yml", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/csi_driver/vsphere : vSphere CSI Driver | Generate a CSI secret manifest] ********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/vsphere/tasks/main.yml:27
        skipping: [kubenode01] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
        
        TASK [kubernetes-apps/csi_driver/vsphere : vSphere CSI Driver | Apply a CSI secret manifest] ***********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/vsphere/tasks/main.yml:34
        skipping: [kubenode01] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
        
        TASK [kubernetes-apps/csi_driver/vsphere : vSphere CSI Driver | Apply Manifests] ***********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/csi_driver/vsphere/tasks/main.yml:42
        skipping: [kubenode01] => (item=vsphere-csi-controller-rbac.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": "vsphere-csi-controller-rbac.yml", "skip_reason": "Conditional result was False", "skipped":
        true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=vsphere-csi-controller-ss.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": "vsphere-csi-controller-ss.yml", "skip_reason": "Conditional result was False", "skipped": true
        }, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=vsphere-csi-node.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": "vsphere-csi-node.yml", "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason":
        "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/openstack : Kubernetes Persistent Volumes | Lay down OpenStack Cinder Storage Class template] *****************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/openstack/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/openstack : Kubernetes Persistent Volumes | Add OpenStack Cinder Storage Class] *******************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/openstack/tasks/main.yml:10
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/cinder-csi : Kubernetes Persistent Volumes | Copy Cinder CSI Storage Class template] **************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/cinder-csi/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/cinder-csi : Kubernetes Persistent Volumes | Add Cinder CSI Storage Class] ************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/cinder-csi/tasks/main.yml:10
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/aws-ebs-csi : Kubernetes Persistent Volumes | Copy AWS EBS CSI Storage Class template] ************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/aws-ebs-csi/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/aws-ebs-csi : Kubernetes Persistent Volumes | Add AWS EBS CSI Storage Class] **********************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/aws-ebs-csi/tasks/main.yml:10
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/azuredisk-csi : Kubernetes Persistent Volumes | Copy Azure CSI Storage Class template] ************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/azuredisk-csi/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/azuredisk-csi : Kubernetes Persistent Volumes | Add Azure CSI Storage Class] **********************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/azuredisk-csi/tasks/main.yml:10
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/gcp-pd-csi : Kubernetes Persistent Volumes | Copy GCP PD CSI Storage Class template] **************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/gcp-pd-csi/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/persistent_volumes/gcp-pd-csi : Kubernetes Persistent Volumes | Add GCP PD CSI Storage Class] ************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/persistent_volumes/gcp-pd-csi/tasks/main.yml:10
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/snapshots/snapshot-controller : Snapshot Controller | Generate Manifests] ********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/snapshots/snapshot-controller/tasks/main.yml:2
        skipping: [kubenode01] => (item={'name': 'rbac-snapshot-controller', 'file': 'rbac-snapshot-controller.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "rbac-snapshot-controller.yml", "name": "rbac-snapshot-controller"}, "skip_reason": "Condition
        al result was False"}
        skipping: [kubenode01] => (item={'name': 'snapshot-controller', 'file': 'snapshot-controller.yml'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "snapshot-controller.yml", "name": "snapshot-controller"}, "skip_reason": "Conditional result was False"
        }
        
        TASK [kubernetes-apps/snapshots/snapshot-controller : Snapshot Controller | Apply Manifests] ***********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/snapshots/snapshot-controller/tasks/main.yml:13
        skipping: [kubenode01] => (item=rbac-snapshot-controller.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "rbac-snapshot-controller.yml", "name": "rbac-snapshot-controller"}, "skip_reason": "Co
        nditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=snapshot-controller.yml)  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "snapshot-controller.yml", "name": "snapshot-controller"}, "skip_reason": "Conditional resul
        t was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/snapshots/cinder-csi : Kubernetes Snapshots | Copy Cinder CSI Snapshot Class template] *******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/snapshots/cinder-csi/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/snapshots/cinder-csi : Kubernetes Snapshots | Add Cinder CSI Snapshot Class] *****************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/snapshots/cinder-csi/tasks/main.yml:10
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_runtimes/kata_containers : Kata Containers | Create addon dir] *********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_runtimes/kata_containers/tasks/main.yaml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_runtimes/kata_containers : Kata Containers | Templates list] ***********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_runtimes/kata_containers/tasks/main.yaml:11
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_runtimes/kata_containers : Kata Containers | Create manifests] *********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_runtimes/kata_containers/tasks/main.yaml:16
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_runtimes/kata_containers : Kata Containers | Apply manifests] **********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_runtimes/kata_containers/tasks/main.yaml:25
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_runtimes/crun : crun | Copy runtime class manifest] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_runtimes/crun/tasks/main.yaml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_runtimes/crun : crun | Apply manifests] ********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_runtimes/crun/tasks/main.yaml:11
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_engine_accelerator/nvidia_gpu : Container Engine Acceleration Nvidia GPU| gather os specific variables] ****************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/tasks/main.yml:3
        skipping: [kubenode01] => (item=/wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/vars/ubuntu-18.yml)  => {"ansible_loop_var": "item", "changed": false, "item": "/wire-server-deploy/ansible/roles-external/ku
        bespray/roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/vars/ubuntu-18.yml", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_engine_accelerator/nvidia_gpu : Container Engine Acceleration Nvidia GPU | Set fact of download url Tesla] *************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/tasks/main.yml:14
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_engine_accelerator/nvidia_gpu : Container Engine Acceleration Nvidia GPU | Set fact of download url GTX] ***************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/tasks/main.yml:19
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_engine_accelerator/nvidia_gpu : Container Engine Acceleration Nvidia GPU | Create addon dir] ***************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/tasks/main.yml:24
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_engine_accelerator/nvidia_gpu : Container Engine Acceleration Nvidia GPU | Create manifests for nvidia accelerators] ***************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/tasks/main.yml:32
        skipping: [kubenode01] => (item={'name': 'nvidia-driver-install-daemonset', 'file': 'nvidia-driver-install-daemonset.yml', 'type': 'daemonset'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "nvidia-driver-install-daemonset.yml", "name": "nvidia-driv
        er-install-daemonset", "type": "daemonset"}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'k8s-device-plugin-nvidia-daemonset', 'file': 'k8s-device-plugin-nvidia-daemonset.yml', 'type': 'daemonset'})  => {"ansible_loop_var": "item", "changed": false, "item": {"file": "k8s-device-plugin-nvidia-daemonset.yml", "name": "k8
        s-device-plugin-nvidia-daemonset", "type": "daemonset"}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/container_engine_accelerator/nvidia_gpu : Container Engine Acceleration Nvidia GPU | Apply manifests for nvidia accelerators] ****************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/tasks/main.yml:43
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'nvidia-driver-install-daemonset', 'file': 'nvidia-driver-install-daemonset.yml', 'type': 'daemonset'}, 'ansible_loop_var': 'item'})  => {"a
        nsible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "nvidia-driver-install-daemonset.yml", "name": "nvidia-driver-install-daemonset", "type": "daemonset"}, "skip_reason": "Conditional result was False", "skip
        ped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': {'name': 'k8s-device-plugin-nvidia-daemonset', 'file': 'k8s-device-plugin-nvidia-daemonset.yml', 'type': 'daemonset'}, 'ansible_loop_var': 'item'})
        => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false, "item": {"file": "k8s-device-plugin-nvidia-daemonset.yml", "name": "k8s-device-plugin-nvidia-daemonset", "type": "daemonset"}, "skip_reason": "Conditional result was F
        alse", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_private_key] ***********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_region_id] *************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:10
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_tenancy_id] ************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_user_id] ***************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:24
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_user_fingerprint] ******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:31
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_compartment_id] ********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:38
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_vnc_id] ****************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:44
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_subnet1_id] ************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:50
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_subnet2_id] ************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:56
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Credentials Check | oci_security_list_management] **********************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/credentials-check.yml:63
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Generate Cloud Provider Configuration] *********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/main.yml:6
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Slurp Configuration] ***************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/main.yml:13
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Encode Configuration] **************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/main.yml:18
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Generate Manifests] ****************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/main.yml:24
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/cloud_controller/oci : OCI Cloud Controller | Apply Manifests] *******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/cloud_controller/oci/tasks/main.yml:31
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Check cluster settings for MetalLB] ******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Check cluster settings for MetalLB] ******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:8
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Check BGP peers for MetalLB] *************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:14
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Check AppArmor status] *******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:20
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Set apparmor_enabled] ********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:28
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Lay Down MetalLB] ************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:35
        skipping: [kubenode01] => (item=metallb.yml)  => {"ansible_loop_var": "item", "changed": false, "item": "metallb.yml", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=metallb-config.yml)  => {"ansible_loop_var": "item", "changed": false, "item": "metallb-config.yml", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Install and configure MetalLB] ***********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:43
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': 'metallb.yml', 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed": false,
         "item": "metallb.yml", "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'changed': False, 'skipped': True, 'skip_reason': 'Conditional result was False', 'item': 'metallb-config.yml', 'ansible_loop_var': 'item'})  => {"ansible_loop_var": "item", "changed": false, "item": {"ansible_loop_var": "item", "changed":
         false, "item": "metallb-config.yml", "skip_reason": "Conditional result was False", "skipped": true}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Check existing secret of MetalLB] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:54
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Create random bytes for MetalLB] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:62
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes-apps/metallb : Kubernetes Apps | Install secret of MetalLB if not existing] ***********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes-apps/metallb/tasks/main.yml:69
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        META: ran handlers
        META: ran handlers
        
        PLAY [k8s-cluster] *************************************************************************************************************************************************************************************************************************************************************
        META: ran handlers
        
        TASK [prep_download | Set a few facts] *****************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Set image info command for containerd and crio] **********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:8
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Set image info command for containerd and crio on localhost] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:14
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | On localhost, check if passwordless root is possible] ****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:20
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | On localhost, check if user has access to docker without using sudo] *************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:35
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Parse the outputs of the previous commands] **************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:50
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Check that local user is in group or can become root] ****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:60
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Register docker images info] *****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:71
        skipping: [kubenode01] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
        
        TASK [prep_download | Create staging directory on remote node] *****************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:80
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [prep_download | Create local cache for files and images on control node] *************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/prep_download.yml:90
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [container-engine/crictl : install crictĺ] ********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/container-engine/crictl/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [download | Get kubeadm binary and list of required images] ***************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/main.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [download | Download files / images] **************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/download/tasks/main.yml:26
        skipping: [kubenode01] => (item={'key': 'netcheck_server', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/l23network/k8s-netchecker-server', 'tag': 'v1.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item
        ": {"key": "netcheck_server", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/l23network/k8s-netchecker-server", "sha256": "", "tag": "v1.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'netcheck_agent', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/l23network/k8s-netchecker-agent', 'tag': 'v1.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item":
         {"key": "netcheck_agent", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/l23network/k8s-netchecker-agent", "sha256": "", "tag": "v1.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'etcd', 'value': {'container': True, 'file': False, 'enabled': True, 'version': 'v3.4.13', 'dest': '/tmp/releases/etcd-v3.4.13-linux-amd64.tar.gz', 'repo': 'quay.io/coreos/etcd', 'tag': 'v3.4.13', 'sha256': '', 'url': 'https://githu
        b.com/coreos/etcd/releases/download/v3.4.13/etcd-v3.4.13-linux-amd64.tar.gz', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['etcd']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "etcd", "value": {"container": true, "dest": "/tmp/r
        eleases/etcd-v3.4.13-linux-amd64.tar.gz", "enabled": true, "file": false, "groups": ["etcd"], "mode": "0755", "owner": "root", "repo": "quay.io/coreos/etcd", "sha256": "", "tag": "v3.4.13", "unarchive": false, "url": "https://github.com/coreos/etcd/releases/download/v3.4.
        13/etcd-v3.4.13-linux-amd64.tar.gz", "version": "v3.4.13"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cni', 'value': {'enabled': True, 'file': True, 'version': 'v0.9.0', 'dest': '/tmp/releases/cni-plugins-linux-amd64-v0.9.0.tgz', 'sha256': '58a58d389895ba9f9bbd3ef330f186c0bb7484136d0bfb9b50152eed55d9ec24', 'url': 'https://github.co
        m/containernetworking/plugins/releases/download/v0.9.0/cni-plugins-linux-amd64-v0.9.0.tgz', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "cni", "value": {"dest": "/tmp/
        releases/cni-plugins-linux-amd64-v0.9.0.tgz", "enabled": true, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "58a58d389895ba9f9bbd3ef330f186c0bb7484136d0bfb9b50152eed55d9ec24", "unarchive": false, "url": "https://github.com/containern
        etworking/plugins/releases/download/v0.9.0/cni-plugins-linux-amd64-v0.9.0.tgz", "version": "v0.9.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm', 'value': {'enabled': True, 'file': True, 'version': 'v1.19.7', 'dest': '/tmp/releases/kubeadm-v1.19.7-amd64', 'sha256': 'c63ef1842533cd7888c7452cab9f320dcf45fc1c173e9d40abb712d45992db24', 'url': 'https://storage.googleapi
        s.com/kubernetes-release/release/v1.19.7/bin/linux/amd64/kubeadm', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubeadm", "value": {"dest": "/tmp/releases/kubeadm-v1.1
        9.7-amd64", "enabled": true, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "c63ef1842533cd7888c7452cab9f320dcf45fc1c173e9d40abb712d45992db24", "unarchive": false, "url": "https://storage.googleapis.com/kubernetes-release/release/v1.19
        .7/bin/linux/amd64/kubeadm", "version": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubelet', 'value': {'enabled': True, 'file': True, 'version': 'v1.19.7', 'dest': '/tmp/releases/kubelet-v1.19.7-amd64', 'sha256': 'd8b296825f6dd7a17287b73cd6604d32210abbba86c88fb68c1b1c5016906c54', 'url': 'https://storage.googleapi
        s.com/kubernetes-release/release/v1.19.7/bin/linux/amd64/kubelet', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubelet", "value": {"dest": "/tmp/releases/kubelet-v1.1
        9.7-amd64", "enabled": true, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "d8b296825f6dd7a17287b73cd6604d32210abbba86c88fb68c1b1c5016906c54", "unarchive": false, "url": "https://storage.googleapis.com/kubernetes-release/release/v1.19
        .7/bin/linux/amd64/kubelet", "version": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubectl', 'value': {'enabled': True, 'file': True, 'version': 'v1.19.7', 'dest': '/tmp/releases/kubectl-v1.19.7-amd64', 'sha256': 'd46eb3bbe2575e5b6bedbc6d3519424b4f2f57929d7da1ef7e11c09068f37297', 'url': 'https://storage.googleapi
        s.com/kubernetes-release/release/v1.19.7/bin/linux/amd64/kubectl', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubectl", "value": {"dest": "/tmp/releases/kubectl-v1.1
        9.7-amd64", "enabled": true, "file": true, "groups": ["kube-master"], "mode": "0755", "owner": "root", "sha256": "d46eb3bbe2575e5b6bedbc6d3519424b4f2f57929d7da1ef7e11c09068f37297", "unarchive": false, "url": "https://storage.googleapis.com/kubernetes-release/release/v1.19
        .7/bin/linux/amd64/kubectl", "version": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'crictl', 'value': {'file': True, 'enabled': False, 'version': 'v1.19.0', 'dest': '/tmp/releases/crictl-v1.19.0-linux-amd64.tar.gz', 'sha256': '87d8ef70b61f2fe3d8b4a48f6f712fd798c6e293ed3723c1e4bbb5052098f0ae', 'url': 'https://githu
        b.com/kubernetes-sigs/cri-tools/releases/download/v1.19.0/crictl-v1.19.0-linux-amd64.tar.gz', 'unarchive': True, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "crictl", "value": {"dest": "/
        tmp/releases/crictl-v1.19.0-linux-amd64.tar.gz", "enabled": false, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "87d8ef70b61f2fe3d8b4a48f6f712fd798c6e293ed3723c1e4bbb5052098f0ae", "unarchive": true, "url": "https://github.com/kuberne
        tes-sigs/cri-tools/releases/download/v1.19.0/crictl-v1.19.0-linux-amd64.tar.gz", "version": "v1.19.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cilium', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/cilium/cilium', 'tag': 'v1.8.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "cilium", "valu
        e": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/cilium/cilium", "sha256": "", "tag": "v1.8.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cilium_init', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/cilium/cilium-init', 'tag': '2019-04-05', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "
        cilium_init", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/cilium/cilium-init", "sha256": "", "tag": "2019-04-05"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cilium_operator', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/cilium/operator', 'tag': 'v1.8.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "cil
        ium_operator", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/cilium/operator", "sha256": "", "tag": "v1.8.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'multus', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/nfvpe/multus', 'tag': 'v3.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "multus", "value
        ": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/nfvpe/multus", "sha256": "", "tag": "v3.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'flannel', 'value': {'enabled': True, 'container': True, 'repo': 'quay.io/coreos/flannel', 'tag': 'v0.13.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "flannel", "v
        alue": {"container": true, "enabled": true, "groups": ["k8s-cluster"], "repo": "quay.io/coreos/flannel", "sha256": "", "tag": "v0.13.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calicoctl', 'value': {'enabled': False, 'file': True, 'version': 'v3.16.6', 'dest': '/tmp/releases/calicoctl', 'sha256': '9b82230446d4749a1043dddd8d466d275a460e570a412e6ced003368ab9c72d8', 'url': 'https://github.com/projectcalico/c
        alicoctl/releases/download/v3.16.6/calicoctl-linux-amd64', 'unarchive': False, 'owner': 'root', 'mode': '0755', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "calicoctl", "value": {"dest": "/tmp/releases/calicoctl", "enabl
        ed": false, "file": true, "groups": ["k8s-cluster"], "mode": "0755", "owner": "root", "sha256": "9b82230446d4749a1043dddd8d466d275a460e570a412e6ced003368ab9c72d8", "unarchive": false, "url": "https://github.com/projectcalico/calicoctl/releases/download/v3.16.6/calicoctl-l
        inux-amd64", "version": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calico_node', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/calico/node', 'tag': 'v3.16.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "calico_nod
        e", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/calico/node", "sha256": "", "tag": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calico_cni', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/calico/cni', 'tag': 'v3.16.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "calico_cni",
         "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/calico/cni", "sha256": "", "tag": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calico_policy', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/calico/kube-controllers', 'tag': 'v3.16.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key
        ": "calico_policy", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/calico/kube-controllers", "sha256": "", "tag": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'calico_typha', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/calico/typha', 'tag': 'v3.16.6', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "calico_t
        ypha", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "quay.io/calico/typha", "sha256": "", "tag": "v3.16.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'weave_kube', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/weaveworks/weave-kube', 'tag': '2.7.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "w
        eave_kube", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/weaveworks/weave-kube", "sha256": "", "tag": "2.7.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'weave_npc', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/weaveworks/weave-npc', 'tag': '2.7.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "wea
        ve_npc", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/weaveworks/weave-npc", "sha256": "", "tag": "2.7.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'ovn4nfv', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/integratedcloudnative/ovn4nfv-k8s-plugin', 'tag': 'v1.1.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "
        item": {"key": "ovn4nfv", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/integratedcloudnative/ovn4nfv-k8s-plugin", "sha256": "", "tag": "v1.1.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kube_ovn', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/kubeovn/kube-ovn', 'tag': 'v1.5.2', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kube_ov
        n", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/kubeovn/kube-ovn", "sha256": "", "tag": "v1.5.2"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kube_router', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/cloudnativelabs/kube-router', 'tag': 'v1.1.1', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"
        key": "kube_router", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/cloudnativelabs/kube-router", "sha256": "", "tag": "v1.1.1"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'pod_infra', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/pause', 'tag': '3.3', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "pod_infra", "value":
         {"container": true, "enabled": true, "groups": ["k8s-cluster"], "repo": "k8s.gcr.io/pause", "sha256": "", "tag": "3.3"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'install_socat', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/xueshanf/install-socat', 'tag': 'latest', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key
        ": "install_socat", "value": {"container": true, "enabled": false, "groups": ["k8s-cluster"], "repo": "docker.io/xueshanf/install-socat", "sha256": "", "tag": "latest"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'nginx', 'value': {'enabled': True, 'container': True, 'repo': 'docker.io/library/nginx', 'tag': 1.19, 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "nginx", "value": {"c
        ontainer": true, "enabled": true, "groups": ["kube-node"], "repo": "docker.io/library/nginx", "sha256": "", "tag": 1.19}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'haproxy', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/library/haproxy', 'tag': 2.3, 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "haproxy", "value
        ": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/library/haproxy", "sha256": "", "tag": 2.3}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'coredns', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/coredns', 'tag': '1.7.0', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "coredns", "value":
         {"container": true, "enabled": true, "groups": ["kube-master"], "repo": "k8s.gcr.io/coredns", "sha256": "", "tag": "1.7.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'nodelocaldns', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/dns/k8s-dns-node-cache', 'tag': '1.16.0', 'sha256': '', 'groups': ['k8s-cluster']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key"
        : "nodelocaldns", "value": {"container": true, "enabled": true, "groups": ["k8s-cluster"], "repo": "k8s.gcr.io/dns/k8s-dns-node-cache", "sha256": "", "tag": "1.16.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'dnsautoscaler', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/cpa/cluster-proportional-autoscaler-amd64', 'tag': '1.8.3', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": fa
        lse, "item": {"key": "dnsautoscaler", "value": {"container": true, "enabled": true, "groups": ["kube-master"], "repo": "k8s.gcr.io/cpa/cluster-proportional-autoscaler-amd64", "sha256": "", "tag": "1.8.3"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'testbox', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/busybox', 'tag': 'latest', 'sha256': ''}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "testbox", "value": {"container": true, "ena
        bled": false, "repo": "k8s.gcr.io/busybox", "sha256": "", "tag": "latest"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'helm', 'value': {'enabled': False, 'file': True, 'version': 'v3.5.2', 'dest': '/tmp/releases/helm-v3.5.2/helm-v3.5.2-linux-amd64.tar.gz', 'sha256': '01b317c506f8b6ad60b11b1dc3f093276bb703281cb1ae01132752253ec706a2', 'url': 'https:/
        /get.helm.sh/helm-v3.5.2-linux-amd64.tar.gz', 'unarchive': True, 'owner': 'root', 'mode': '0755', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "helm", "value": {"dest": "/tmp/releases/helm-v3.5.2/helm-v3.5.2-linux-amd64.t
        ar.gz", "enabled": false, "file": true, "groups": ["kube-master"], "mode": "0755", "owner": "root", "sha256": "01b317c506f8b6ad60b11b1dc3f093276bb703281cb1ae01132752253ec706a2", "unarchive": true, "url": "https://get.helm.sh/helm-v3.5.2-linux-amd64.tar.gz", "version": "v3
        .5.2"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'registry', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/library/registry', 'tag': '2.7.1', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "registry",
         "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/library/registry", "sha256": "", "tag": "2.7.1"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'registry_proxy', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/kube-registry-proxy', 'tag': '0.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "re
        gistry_proxy", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "k8s.gcr.io/kube-registry-proxy", "sha256": "", "tag": "0.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'metrics_server', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/metrics-server/metrics-server', 'tag': 'v0.3.7', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "ite
        m": {"key": "metrics_server", "value": {"container": true, "enabled": false, "groups": ["kube-master"], "repo": "k8s.gcr.io/metrics-server/metrics-server", "sha256": "", "tag": "v0.3.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'addon_resizer', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/addon-resizer', 'tag': '1.8.11', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "addo
        n_resizer", "value": {"container": true, "enabled": false, "groups": ["kube-master"], "repo": "k8s.gcr.io/addon-resizer", "sha256": "", "tag": "1.8.11"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'local_volume_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/external_storage/local-volume-provisioner', 'tag': 'v2.3.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "chan
        ged": false, "item": {"key": "local_volume_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/external_storage/local-volume-provisioner", "sha256": "", "tag": "v2.3.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cephfs_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/external_storage/cephfs-provisioner', 'tag': 'v2.1.0-k8s1.11', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed"
        : false, "item": {"key": "cephfs_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/external_storage/cephfs-provisioner", "sha256": "", "tag": "v2.1.0-k8s1.11"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'rbd_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/external_storage/rbd-provisioner', 'tag': 'v2.1.1-k8s1.11', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"key": "rbd_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/external_storage/rbd-provisioner", "sha256": "", "tag": "v2.1.1-k8s1.11"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'local_path_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/rancher/local-path-provisioner', 'tag': 'v0.0.19', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"key": "local_path_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/rancher/local-path-provisioner", "sha256": "", "tag": "v0.0.19"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'ingress_nginx_controller', 'value': {'enabled': False, 'container': True, 'repo': 'k8s.gcr.io/ingress-nginx/controller', 'tag': 'v0.41.2', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false,
        "item": {"key": "ingress_nginx_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "k8s.gcr.io/ingress-nginx/controller", "sha256": "", "tag": "v0.41.2"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'ingress_ambassador_controller', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/datawire/ambassador-operator', 'tag': 'v1.2.9', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fa
        lse, "item": {"key": "ingress_ambassador_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/datawire/ambassador-operator", "sha256": "", "tag": "v1.2.9"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'ingress_alb_controller', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/amazon/aws-alb-ingress-controller', 'tag': 'v1.1.9', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fa
        lse, "item": {"key": "ingress_alb_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/amazon/aws-alb-ingress-controller", "sha256": "", "tag": "v1.1.9"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cert_manager_controller', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/jetstack/cert-manager-controller', 'tag': 'v1.0.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"key": "cert_manager_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/jetstack/cert-manager-controller", "sha256": "", "tag": "v1.0.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cert_manager_cainjector', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/jetstack/cert-manager-cainjector', 'tag': 'v1.0.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fals
        e, "item": {"key": "cert_manager_cainjector", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/jetstack/cert-manager-cainjector", "sha256": "", "tag": "v1.0.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cert_manager_webhook', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/jetstack/cert-manager-webhook', 'tag': 'v1.0.4', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "it
        em": {"key": "cert_manager_webhook", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/jetstack/cert-manager-webhook", "sha256": "", "tag": "v1.0.4"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_attacher', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-attacher', 'tag': 'v2.2.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "csi_
        attacher", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-attacher", "sha256": "", "tag": "v2.2.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_provisioner', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-provisioner', 'tag': 'v1.6.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key":
         "csi_provisioner", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-provisioner", "sha256": "", "tag": "v1.6.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_snapshotter', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-snapshotter', 'tag': 'v2.1.1', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key":
         "csi_snapshotter", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-snapshotter", "sha256": "", "tag": "v2.1.1"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'snapshot_controller', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/snapshot-controller', 'tag': 'v2.0.1', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item":
         {"key": "snapshot_controller", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/snapshot-controller", "sha256": "", "tag": "v2.0.1"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_resizer', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-resizer', 'tag': 'v0.5.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "csi_re
        sizer", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-resizer", "sha256": "", "tag": "v0.5.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'csi_node_driver_registrar', 'value': {'enabled': False, 'container': True, 'repo': 'quay.io/k8scsi/csi-node-driver-registrar', 'tag': 'v1.3.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": fa
        lse, "item": {"key": "csi_node_driver_registrar", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "quay.io/k8scsi/csi-node-driver-registrar", "sha256": "", "tag": "v1.3.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'cinder_csi_plugin', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/k8scloudprovider/cinder-csi-plugin', 'tag': 'v1.18.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false
        , "item": {"key": "cinder_csi_plugin", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/k8scloudprovider/cinder-csi-plugin", "sha256": "", "tag": "v1.18.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'aws_ebs_csi_plugin', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/amazon/aws-ebs-csi-driver', 'tag': 'v0.5.0', 'sha256': '', 'groups': ['kube-node']}})  => {"ansible_loop_var": "item", "changed": false, "item":
         {"key": "aws_ebs_csi_plugin", "value": {"container": true, "enabled": false, "groups": ["kube-node"], "repo": "docker.io/amazon/aws-ebs-csi-driver", "sha256": "", "tag": "v0.5.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'dashboard', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/kubernetesui/dashboard-amd64', 'tag': 'v2.1.0', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"k
        ey": "dashboard", "value": {"container": true, "enabled": false, "groups": ["kube-master"], "repo": "docker.io/kubernetesui/dashboard-amd64", "sha256": "", "tag": "v2.1.0"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'dashboard_metrics_scrapper', 'value': {'enabled': False, 'container': True, 'repo': 'docker.io/kubernetesui/metrics-scraper', 'tag': 'v1.0.6', 'sha256': '', 'groups': ['kube-master']}})  => {"ansible_loop_var": "item", "changed": f
        alse, "item": {"key": "dashboard_metrics_scrapper", "value": {"container": true, "enabled": false, "groups": ["kube-master"], "repo": "docker.io/kubernetesui/metrics-scraper", "sha256": "", "tag": "v1.0.6"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm_kube-apiserver', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/kube-apiserver', 'tag': 'v1.19.7', 'groups': 'k8s-cluster'}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubeadm_ku
        be-apiserver", "value": {"container": true, "enabled": true, "groups": "k8s-cluster", "repo": "k8s.gcr.io/kube-apiserver", "tag": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm_kube-controller-manager', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/kube-controller-manager', 'tag': 'v1.19.7', 'groups': 'k8s-cluster'}})  => {"ansible_loop_var": "item", "changed": false, "item": {
        "key": "kubeadm_kube-controller-manager", "value": {"container": true, "enabled": true, "groups": "k8s-cluster", "repo": "k8s.gcr.io/kube-controller-manager", "tag": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm_kube-scheduler', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/kube-scheduler', 'tag': 'v1.19.7', 'groups': 'k8s-cluster'}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubeadm_ku
        be-scheduler", "value": {"container": true, "enabled": true, "groups": "k8s-cluster", "repo": "k8s.gcr.io/kube-scheduler", "tag": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': 'kubeadm_kube-proxy', 'value': {'enabled': True, 'container': True, 'repo': 'k8s.gcr.io/kube-proxy', 'tag': 'v1.19.7', 'groups': 'k8s-cluster'}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "kubeadm_kube-proxy
        ", "value": {"container": true, "enabled": true, "groups": "k8s-cluster", "repo": "k8s.gcr.io/kube-proxy", "tag": "v1.19.7"}}, "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : Configure defaults] *********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/main.yaml:2
        ok: [kubenode01] => {
            "msg": "Check roles/kubespray-defaults/defaults/main.yml"
        }
        
        TASK [kubespray-defaults : Gather ansible_default_ipv4 from all hosts] *********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/fallback_ips.yml:6
        skipping: [kubenode01] => (item=kubenode01)  => {"ansible_loop_var": "delegate_host_to_gather_facts", "changed": false, "delegate_host_to_gather_facts": "kubenode01", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=kubenode01)  => {"ansible_loop_var": "delegate_host_to_gather_facts", "changed": false, "delegate_host_to_gather_facts": "kubenode01", "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : create fallback_ips_base] ***************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/fallback_ips.yml:15
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : set fallback_ips] ***********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/fallback_ips.yml:29
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : Set no_proxy to all assigned cluster IPs and hostnames] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/no_proxy.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubespray-defaults : Populates no_proxy to all hosts] ********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubespray-defaults/tasks/no_proxy.yml:32
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [adduser : User | Create User Group] **************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/adduser/tasks/main.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [adduser : User | Create User] ********************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/adduser/tasks/main.yml:7
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Remove swapfile from /etc/fstab] *****************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0010-swapoff.yml:2
        skipping: [kubenode01] => (item=swap)  => {"ansible_loop_var": "item", "changed": false, "item": "swap", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=none)  => {"ansible_loop_var": "item", "changed": false, "item": "none", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check swap] **************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0010-swapoff.yml:12
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Disable swap] ************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0010-swapoff.yml:16
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if either kube-master or kube-node group is empty] ******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:2
        skipping: [kubenode01] => (item=kube-master)  => {"ansible_loop_var": "item", "changed": false, "item": "kube-master", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=kube-node)  => {"ansible_loop_var": "item", "changed": false, "item": "kube-node", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if etcd group is empty in external etcd mode] ***********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:11
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if non systemd OS type] *********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:20
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if unknown OS] ******************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:25
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if unknown network plugin] ******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:31
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if incompatible network plugin and cloudprovider] *******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:39
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if unsupported version of Kubernetes] *******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:47
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if known booleans are set as strings (Use JSON format on CLI: -e "{'key': true }")] *********************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:54
        skipping: [kubenode01] => (item={'name': 'download_run_once', 'value': False})  => {"ansible_loop_var": "item", "changed": false, "item": {"name": "download_run_once", "value": false}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'deploy_netchecker', 'value': False})  => {"ansible_loop_var": "item", "changed": false, "item": {"name": "deploy_netchecker", "value": false}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'download_always_pull', 'value': False})  => {"ansible_loop_var": "item", "changed": false, "item": {"name": "download_always_pull", "value": false}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'helm_enabled', 'value': False})  => {"ansible_loop_var": "item", "changed": false, "item": {"name": "helm_enabled", "value": false}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'openstack_lbaas_enabled', 'value': False})  => {"ansible_loop_var": "item", "changed": false, "item": {"name": "openstack_lbaas_enabled", "value": false}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if even number of etcd hosts] ***************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:67
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if memory is too small for masters] *********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:74
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if memory is too small for nodes] ***********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:81
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Guarantee that enough network address space is available for all pods] ***************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:93
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if ip var does not match local ips] *********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:103
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if access_ip is not pingable] ***************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:111
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if RBAC is not enabled when dashboard is enabled] *******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:118
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if RBAC is not enabled when OCI cloud controller is enabled] ********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:125
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if RBAC and anonymous-auth are not enabled when insecure port is disabled] ******************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:132
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if kernel version is too low] ***************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:139
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if bad hostname] ****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:146
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check cloud_provider value] **********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:152
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Ensure minimum calico version] *******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:163
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Get current calico cluster version] **************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:171
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Check that current calico version is enough for upgrade] *****************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:184
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Check that cluster_id is set if calico_rr enabled] ***********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:196
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Check that calico_rr nodes are in k8s-cluster group] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:207
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Check that kube_service_addresses is a network range] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:216
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Check that kube_pods_subnet is a network range] **************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:223
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Check that kube_pods_subnet does not collide with kube_service_addresses] ************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:230
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if unknown dns mode] ************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:237
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if unknown kube proxy mode] *****************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:244
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if vault is chose] **************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:251
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if unknown cert_management] *****************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:258
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if unknown resolvconf_mode] *****************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:264
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if etcd deployment type is not host or docker] **********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:271
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if etcd deployment type is not host when container_manager != docker] ***********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:279
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if download_localhost is enabled but download_run_once is not] ******************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:288
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if kata_containers_enabled is enabled when container_manager is docker] *********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:294
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stop if download_localhost is enabled for Flatcar Container Linux] *******************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml:300
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Force binaries directory for Flatcar Container Linux by Kinvolk] *********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check if booted with ostree] *********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:9
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : set is_fedora_coreos] ****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:14
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : set is_fedora_coreos] ****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:23
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check resolvconf] ********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:27
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check systemd-resolved] **************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:34
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : set dns facts] ***********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:42
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check if kubelet is configured] ******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:59
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check if early DNS configuration stage] **********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:65
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : target resolv.conf files] ************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:70
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : target temporary resolvconf cloud init file (Flatcar Container Linux by Kinvolk / Fedora CoreOS)] ************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:79
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check if /etc/dhclient.conf exists] **************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:84
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : target dhclient conf file for /etc/dhclient.conf] ************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:89
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check if /etc/dhcp/dhclient.conf exists] *********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:94
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : target dhclient conf file for /etc/dhcp/dhclient.conf] *******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:99
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : target dhclient hook file for Red Hat family] ****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:104
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : target dhclient hook file for Debian family] *****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:109
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : generate search domains to resolvconf] ***********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:114
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : pick coredns cluster IP or default resolver] *****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:125
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : generate nameservers to resolvconf] **************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:140
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : gather os specific variables] ********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:147
        skipping: [kubenode01] => (item=/wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/vars/../vars/ubuntu.yml)  => {"ansible_loop_var": "item", "changed": false, "item": "/wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/prei
        nstall/vars/../vars/ubuntu.yml", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : set etcd vars if using kubeadm mode] *************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:161
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check /usr readonly] *****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:170
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : set alternate flexvolume path] *******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0040-set_facts.yml:175
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Create kubernetes directories] *******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0050-create_directories.yml:2
        skipping: [kubenode01] => (item=/etc/kubernetes)  => {"ansible_loop_var": "item", "changed": false, "item": "/etc/kubernetes", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=/etc/kubernetes/ssl)  => {"ansible_loop_var": "item", "changed": false, "item": "/etc/kubernetes/ssl", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=/etc/kubernetes/manifests)  => {"ansible_loop_var": "item", "changed": false, "item": "/etc/kubernetes/manifests", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=/usr/local/bin/kubernetes-scripts)  => {"ansible_loop_var": "item", "changed": false, "item": "/usr/local/bin/kubernetes-scripts", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=/usr/libexec/kubernetes/kubelet-plugins/volume/exec)  => {"ansible_loop_var": "item", "changed": false, "item": "/usr/libexec/kubernetes/kubelet-plugins/volume/exec", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Create other directories] ************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0050-create_directories.yml:26
        skipping: [kubenode01] => (item=/usr/local/bin)  => {"ansible_loop_var": "item", "changed": false, "item": "/usr/local/bin", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Check if kubernetes kubeadm compat cert dir exists] **********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0050-create_directories.yml:46
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Create kubernetes kubeadm compat cert dir (kubernetes/kubeadm issue 1498)] ***********************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0050-create_directories.yml:54
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Create cni directories] **************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0050-create_directories.yml:64
        skipping: [kubenode01] => (item=/etc/cni/net.d)  => {"ansible_loop_var": "item", "changed": false, "item": "/etc/cni/net.d", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=/opt/cni/bin)  => {"ansible_loop_var": "item", "changed": false, "item": "/opt/cni/bin", "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=/var/lib/calico)  => {"ansible_loop_var": "item", "changed": false, "item": "/var/lib/calico", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Create local volume provisioner directories] *****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0050-create_directories.yml:87
        skipping: [kubenode01] => (item=local-storage)  => {"ansible_loop_var": "item", "changed": false, "item": "local-storage", "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : create temporary resolveconf cloud init file] ****************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0060-resolvconf.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Add domain/search/nameservers/options to resolv.conf] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0060-resolvconf.yml:6
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Remove search/domain/nameserver options before block] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0060-resolvconf.yml:23
        skipping: [kubenode01] => (item=['/etc/resolv.conf', 'search '])  => {"ansible_loop_var": "item", "changed": false, "item": ["/etc/resolv.conf", "search "], "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=['/etc/resolv.conf', 'nameserver '])  => {"ansible_loop_var": "item", "changed": false, "item": ["/etc/resolv.conf", "nameserver "], "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=['/etc/resolv.conf', 'domain '])  => {"ansible_loop_var": "item", "changed": false, "item": ["/etc/resolv.conf", "domain "], "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=['/etc/resolv.conf', 'options '])  => {"ansible_loop_var": "item", "changed": false, "item": ["/etc/resolv.conf", "options "], "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Remove search/domain/nameserver options after block] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0060-resolvconf.yml:34
        skipping: [kubenode01] => (item=['/etc/resolv.conf', 'search '])  => {"ansible_loop_var": "item", "changed": false, "item": ["/etc/resolv.conf", "search "], "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=['/etc/resolv.conf', 'nameserver '])  => {"ansible_loop_var": "item", "changed": false, "item": ["/etc/resolv.conf", "nameserver "], "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=['/etc/resolv.conf', 'domain '])  => {"ansible_loop_var": "item", "changed": false, "item": ["/etc/resolv.conf", "domain "], "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item=['/etc/resolv.conf', 'options '])  => {"ansible_loop_var": "item", "changed": false, "item": ["/etc/resolv.conf", "options "], "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : get temporary resolveconf cloud init file content] ***********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0060-resolvconf.yml:47
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : persist resolvconf cloud init file] **************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0060-resolvconf.yml:52
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Write resolved.conf] *****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0061-systemd-resolved.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : NetworkManager | Add nameservers to NM configuration] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0062-networkmanager.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : NetworkManager | Add DNS search to NM configuration] *********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0062-networkmanager.yml:12
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : NetworkManager | Add DNS options to NM configuration] ********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0062-networkmanager.yml:22
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Update package management cache (zypper) - SUSE] *************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0070-system-packages.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Update package management cache (APT)] ***********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0070-system-packages.yml:12
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Remove legacy docker repo file] ******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0070-system-packages.yml:20
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Install python3-dnf for latest RedHat versions] **************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0070-system-packages.yml:28
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Install epel-release on RedHat/CentOS] ***********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0070-system-packages.yml:42
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Update common_required_pkgs with ipvsadm when kube_proxy_mode is ipvs] ***************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0070-system-packages.yml:53
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Install packages requirements] *******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0070-system-packages.yml:58
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Install ipvsadm for ClearLinux] ******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0070-system-packages.yml:70
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Confirm selinux deployed] ************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0080-system-configurations.yml:3
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Set selinux policy] ******************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0080-system-configurations.yml:11
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Disable IPv6 DNS lookup] *************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0080-system-configurations.yml:23
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Stat sysctl file configuration] ******************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0080-system-configurations.yml:36
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Change sysctl file path to link source if linked] ************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0080-system-configurations.yml:43
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Make sure sysctl file path folder exists] ********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0080-system-configurations.yml:52
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Enable ip forwarding] ****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0080-system-configurations.yml:57
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Ensure kube-bench parameters are set] ************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0080-system-configurations.yml:65
        skipping: [kubenode01] => (item={'name': 'vm.overcommit_memory', 'value': 1})  => {"ansible_loop_var": "item", "changed": false, "item": {"name": "vm.overcommit_memory", "value": 1}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'kernel.panic', 'value': 10})  => {"ansible_loop_var": "item", "changed": false, "item": {"name": "kernel.panic", "value": 10}, "skip_reason": "Conditional result was False"}
        skipping: [kubenode01] => (item={'name': 'kernel.panic_on_oops', 'value': 1})  => {"ansible_loop_var": "item", "changed": false, "item": {"name": "kernel.panic_on_oops", "value": 1}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Hosts | create list from inventory] **************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0090-etchosts.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Hosts | populate inventory into hosts file] ******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0090-etchosts.yml:16
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Hosts | populate kubernetes loadbalancer address into hosts file] ********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0090-etchosts.yml:27
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Hosts | Retrieve hosts file content] *************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0090-etchosts.yml:39
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Hosts | Extract existing entries for localhost from hosts file] **********************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0090-etchosts.yml:44
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Hosts | Update target hosts file entries dict with required entries] *****************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0090-etchosts.yml:54
        skipping: [kubenode01] => (item={'key': '127.0.0.1', 'value': {'expected': ['localhost', 'localhost.localdomain']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "127.0.0.1", "value": {"expected": ["localhost", "localhost.localdomain"]}}, "skip_reaso
        n": "Conditional result was False"}
        skipping: [kubenode01] => (item={'key': '::1', 'value': {'expected': ['localhost6', 'localhost6.localdomain'], 'unexpected': ['localhost', 'localhost.localdomain']}})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "::1", "value": {"expected": ["localho
        st6", "localhost6.localdomain"], "unexpected": ["localhost", "localhost.localdomain"]}}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Hosts | Update (if necessary) hosts file] ********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0090-etchosts.yml:61
        skipping: [kubenode01] => (item={'key': '127.0.0.1', 'value': ['localhost', 'localhost.localdomain']})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "127.0.0.1", "value": ["localhost", "localhost.localdomain"]}, "skip_reason": "Conditional result was
        False"}
        skipping: [kubenode01] => (item={'key': '::1', 'value': ['ip6-localhost', 'ip6-loopback', 'localhost6', 'localhost6.localdomain']})  => {"ansible_loop_var": "item", "changed": false, "item": {"key": "::1", "value": ["ip6-localhost", "ip6-loopback", "localhost6", "localhos
        t6.localdomain"]}, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Update facts] ************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0090-etchosts.yml:72
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Configure dhclient to supersede search/domain/nameservers] ***************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0100-dhclient-hooks.yml:2
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Configure dhclient hooks for resolv.conf (non-RH)] ***********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0100-dhclient-hooks.yml:17
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Configure dhclient hooks for resolv.conf (RH-only)] **********************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0100-dhclient-hooks.yml:26
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Remove kubespray specific config from dhclient config] *******************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0110-dhclient-hooks-undo.yml:6
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : Remove kubespray specific dhclient hook] *********************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0110-dhclient-hooks-undo.yml:15
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        META: ran handlers
        
        TASK [kubernetes/preinstall : Check if we are running inside a Azure VM] *******************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/main.yml:92
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : install growpart] ********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0120-growpart-azure-centos-7.yml:5
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check if growpart needs to be run] ***************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0120-growpart-azure-centos-7.yml:10
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : check fs type] ***********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0120-growpart-azure-centos-7.yml:18
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : run growpart] ************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0120-growpart-azure-centos-7.yml:23
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        
        TASK [kubernetes/preinstall : run xfs_growfs] **********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/kubespray/roles/kubernetes/preinstall/tasks/0120-growpart-azure-centos-7.yml:29
        skipping: [kubenode01] => {"changed": false, "skip_reason": "Conditional result was False"}
        META: ran handlers
        META: ran handlers
        
        PLAY [k8s-cluster] *************************************************************************************************************************************************************************************************************************************************************
        META: ran handlers
        
        TASK [Annotate nodes] **********************************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/kubernetes.yml:12
        META: ran handlers
        META: ran handlers
        
        PLAY [k8s-cluster] *************************************************************************************************************************************************************************************************************************************************************
        META: ran handlers
        
        TASK [nickhammond.logrotate | Install logrotate] *******************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/logrotate/tasks/main.yml:2
        ok: [kubenode01] => {"cache_update_time": 1628779844, "cache_updated": false, "changed": false}
        
        TASK [nickhammond.logrotate | Setup logrotate.d scripts] ***********************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles-external/logrotate/tasks/main.yml:8
        changed: [kubenode01] => (item={'name': 'podlogs', 'path': '/var/lib/docker/containers/*/*.log', 'options': ['daily', 'missingok', 'rotate 2', 'maxage 1', 'copytruncate', 'nocreate', 'nocompress']}) => {"ansible_loop_var": "item", "changed": true, "checksum": "cbb2a32ef27
        e84ded753a3d749c86e0aed963f33", "dest": "/etc/logrotate.d/podlogs", "gid": 0, "group": "root", "item": {"name": "podlogs", "options": ["daily", "missingok", "rotate 2", "maxage 1", "copytruncate", "nocreate", "nocompress"], "path": "/var/lib/docker/containers/*/*.log"}, "
        md5sum": "f76ae2a3a8a211eb0c74ca3657422bfe", "mode": "0600", "owner": "root", "size": 143, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780255.3643317-3825-120899758345527/source", "state": "file", "uid": 0, "warnings": ["File '/etc/logrotate.d/podlogs' created with de
        fault permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning."]}
        [WARNING]: File '/etc/logrotate.d/podlogs' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        META: ran handlers
        META: ran handlers
        
        PLAY [Bringing kubeconfig in place] ********************************************************************************************************************************************************************************************************************************************
        META: ran handlers
        
        TASK [Checking if 'kubeconfig' file already exists] ****************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/kubernetes.yml:24
        ok: [kubenode01] => {"changed": false, "stat": {"exists": false}}
        
        TASK [Renaming kubeconfig file provided by Kubespray] **************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/kubernetes.yml:30
        [WARNING]: File '/wire-server-deploy/ansible/inventory/demo/../kubeconfig.dec' created with default permissions '600'. The previous default was '666'. Specify 'mode' to avoid this warning.
        changed: [kubenode01] => {"changed": true, "checksum": "f38b7da1364fc912af635440bba0527bfaca40e9", "dest": "/wire-server-deploy/ansible/inventory/demo/../kubeconfig.dec", "gid": 0, "group": "root", "md5sum": "8aee42835777974c3417c34d4bd3d369", "mode": "0600", "owner": "ro
        ot", "size": 5638, "src": "/root/.ansible/tmp/ansible-tmp-1628780257.3840256-3840-215959176747575/source", "state": "file", "uid": 0}
        
        TASK [debug] *******************************************************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/kubernetes.yml:34
        ok: [kubenode01] => {
            "msg": "TODO: Encrypt /wire-server-deploy/ansible/inventory/demo/../kubeconfig.dec with sops"
        }
        META: ran handlers
        META: ran handlers
        
        PLAY [etcd] ********************************************************************************************************************************************************************************************************************************************************************
        META: ran handlers
        
        TASK [etcd-helpers : Add etcd helper scripts] **********************************************************************************************************************************************************************************************************************************
        task path: /wire-server-deploy/ansible/roles/etcd-helpers/tasks/main.yml:3
        changed: [kubenode01] => (item=etcd-health.sh) => {"ansible_loop_var": "item", "changed": true, "checksum": "9626e733cbc0c5ab3f512aba5031291a45c8ad43", "dest": "/usr/local/bin/etcd-health.sh", "gid": 0, "group": "root", "item": "etcd-health.sh", "md5sum": "c48c87b8343500c
        b9bd4af088e6420ee", "mode": "0755", "owner": "root", "size": 236, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780258.0582855-3862-277285358928683/source", "state": "file", "uid": 0}
        changed: [kubenode01] => (item=etcdctl3.sh) => {"ansible_loop_var": "item", "changed": true, "checksum": "cd5c88dfe6cd230dfdd01cd673280a2b5a3b66d0", "dest": "/usr/local/bin/etcdctl3.sh", "gid": 0, "group": "root", "item": "etcdctl3.sh", "md5sum": "20ee7b89f5c3a3d02a55ae1e
        dba09d61", "mode": "0755", "owner": "root", "size": 249, "src": "/home/wire/.ansible/tmp/ansible-tmp-1628780260.060692-3862-274747914849236/source", "state": "file", "uid": 0}
        META: ran handlers
        META: ran handlers
        
        PLAY RECAP *********************************************************************************************************************************************************************************************************************************************************************
        kubenode01                 : ok=532  changed=123  unreachable=0    failed=0    skipped=1017 rescued=0    ignored=1
        localhost                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
        
[16:57:50] # Running command «find . -name 'admin.conf'» on 192.168.1.121
        bash-4.4# find . -name 'admin.conf'
        ./inventory/demo/artifacts/admin.conf
[16:57:56] # Running command «mkdir -p ~/.kube/» on 192.168.1.121
        bash-4.4# mkdir -p ~/.kube/
[16:58:02] # Running command «cp ./inventory/demo/artifacts/admin.conf ~/.kube/config» on 192.168.1.121
        bash-4.4# cp ./inventory/demo/artifacts/admin.conf ~/.kube/config
[16:58:08] # Running command «KUBECONFIG=~/.kube/config» on 192.168.1.121
        bash-4.4# KUBECONFIG=~/.kube/config
[16:58:14] # Running command «which kubectl» on 192.168.1.121
        bash-4.4# which kubectl
        /bin/kubectl
[16:58:19] # Running command «kubectl version» on 192.168.1.121
        bash-4.4# kubectl version
        Client Version: version.Info{Major:"1", Minor:"19", GitVersion:"v1.19.7", GitCommit:"1dd5338295409edcfff11505e7bb246f0d325d15", GitTreeState:"clean", BuildDate:"2021-01-13T13:23:52Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"linux/amd64"}
        Server Version: version.Info{Major:"1", Minor:"19", GitVersion:"v1.19.7", GitCommit:"1dd5338295409edcfff11505e7bb246f0d325d15", GitTreeState:"clean", BuildDate:"2021-01-13T13:15:20Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"linux/amd64"}
[16:58:35] # Running command «kubectl get pods -A » on 192.168.1.121
        bash-4.4# kubectl get pods -A
        NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE
        kube-system   coredns-7677f9bb54-kv2pk             1/1     Running   0          80s
        kube-system   coredns-7677f9bb54-pp6sc             0/1     Pending   0          73s
        kube-system   dns-autoscaler-5b7b5c9b6f-mcvnc      1/1     Running   0          75s
        kube-system   kube-apiserver-kubenode01            1/1     Running   0          3m9s
        kube-system   kube-controller-manager-kubenode01   1/1     Running   0          3m9s
        kube-system   kube-flannel-z8lgq                   1/1     Running   0          119s
        kube-system   kube-proxy-4sc5k                     1/1     Running   0          2m3s
        kube-system   kube-scheduler-kubenode01            1/1     Running   1          3m9s
        kube-system   nodelocaldns-z5465                   1/1     Running   0          72s
[16:58:41] # Running command «free -m && uptime» on 192.168.1.121
        bash-4.4# free -m && uptime
                      total        used        free      shared  buff/cache   available
        Mem:           2928         267         550           0        2111        2513
        Swap:          3943           0        3943
         14:58:38 up 28 min,  load average: 0.66, 0.77, 0.72
[16:58:47] # Running command «free -m && uptime» on 95.216.208.159
        wire@arthur-demo:~$ free -m && uptime
                      total        used        free      shared  buff/cache   available
        Mem:          15661         783       12044           1        2833       14576
        Swap:             0           0           0
         16:58:44 up 35 min,  0 users,  load average: 0.33, 0.47, 0.28
[16:58:53] # Running command «helm version» on 192.168.1.121
        bash-4.4# helm version
        version.BuildInfo{Version:"v3.5.2", GitCommit:"", GitTreeState:"", GoVersion:"go1.16"}
[16:59:00] # Running command «helm repo add wire https://s3-eu-west-1.amazonaws.com/public.wire.com/charts» on 192.168.1.121
        bash-4.4# helm repo add wire https://s3-eu-west-1.amazonaws.com/public.wire.com/charts
        "wire" has been added to your repositories
[16:59:06] # Running command «helm search repo wire/» on 192.168.1.121
        bash-4.4# helm search repo wire/
        NAME                            CHART VERSION   APP VERSION     DESCRIPTION
        wire/account-pages              0.130.0                         A Helm chart for the Wire account pages in Kube...
        wire/aws-ingress                2.111.0                         A Helm chart for ingresses (AWS specific) on Ku...
        wire/aws-storage                0.130.0                         AWS storage classes
        wire/backoffice                 2.111.0                         Backoffice tool
        wire/brig                       0.130.0                         Brig (part of Wire Server) - User management
        wire/calling-test               2.111.0         1.0.14          Network testing tool for audio/video/signalling...
        wire/cannon                     0.130.0                         A Helm chart for cannon in Kubernetes
        wire/cargohold                  0.130.0                         Cargohold (part of Wire Server) - Asset storage
        wire/cassandra-ephemeral        0.130.0                         Wrapper chart for incubator/cassandra with cust...
        wire/cassandra-external         2.111.0                         Refer to cassandra IPs located outside kubernet...
        wire/cassandra-migrations       0.130.0                         cassandra database schema migration for gundeck...
        wire/databases-ephemeral        2.111.0                         A Helm chart in-memory, ephemeral databases for...
        wire/demo-smtp                  2.111.0         1.0             A demo helm chart to send emails. Not productio...
        wire/elasticsearch-curator      2.111.0                         Wrapper chart for stable/elasticsearch-curator
        wire/elasticsearch-ephemeral    2.111.0                         Dummy ephemeral elasticsearch
        wire/elasticsearch-external     2.111.0                         Refer to elasticsearch IPs located outside kube...
        wire/elasticsearch-index        0.130.0                         Elasticsearch index for brig
        wire/fake-aws                   2.111.0                         A Helm chart for fake-aws services (replacing r...
        wire/fake-aws-dynamodb          0.130.0                         Dummy ephemeral DynamoDB service
        wire/fake-aws-s3                2.111.0                         Wrapper chart for stable/minio
        wire/fake-aws-ses               0.130.0                         Dummy ephemeral SES service (based on localstack)
        wire/fake-aws-sns               0.130.0                         Dummy ephemeral SNS service (based on localstack)
        wire/fake-aws-sqs               2.111.0                         Dummy ephemeral SQS service
        wire/fluent-bit                 2.111.0                         Wrapper chart for stable/fluent-bit
        wire/galley                     0.130.0                         Galley (part of Wire Server) - Conversations
        wire/gundeck                    0.130.0                         Gundeck (part of Wire Server) - Push Notificati...
        wire/kibana                     2.111.0                         Wrapper chart for stable/kibana
        wire/legalhold                  0.130.0                         A Helm chart for legalhold
        wire/metallb                    0.130.0                         A Helm chart for metallb on Kubernetes
        wire/minio-external             2.111.0                         Refer to minio IPs located outside kubernetes b...
        wire/nginx-ingress-controller   2.111.0                         A Helm chart for an ingress controller (using n...
        wire/nginx-ingress-services     2.111.0                         A Helm chart for ingresses and services on Kube...
        wire/nginx-lb-ingress           0.1.3                           A Helm chart for ingresses (using nginx) on Kub...
        wire/nginz                      0.130.0                         A Helm chart for nginz in Kubernetes
        wire/proxy                      0.130.0                         Proxy (part of Wire Server) - 3rd party proxy s...
        wire/reaper                     2.111.0         0.1.0           A helm charts to restart cannons if redis-ephem...
        wire/redis-ephemeral            2.111.0                         Wrapper chart for stable/redis
        wire/sftd                       2.111.0         1.0.88          SFTD is a component for engaging in conference ...
        wire/spar                       0.130.0                         Spar (part of Wire Server) - SSO Service
        wire/team-settings              0.130.0                         A Helm chart for the Wire team-settings in Kube...
        wire/webapp                     0.130.0                         A Helm chart for the Wire webapp in Kubernetes
        wire/wire-server                2.111.0                         A Helm chart for wire-server https://github.com...
        wire/wire-server-metrics        2.111.0         1.0             Adds monitoring for the kubernetes cluster and ...
[16:59:12] # Running command «kubectl get pods -A» on 192.168.1.121
        bash-4.4# kubectl get pods -A
        NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE
        kube-system   coredns-7677f9bb54-kv2pk             1/1     Running   0          116s
        kube-system   coredns-7677f9bb54-pp6sc             0/1     Pending   0          109s
        kube-system   dns-autoscaler-5b7b5c9b6f-mcvnc      1/1     Running   0          111s
        kube-system   kube-apiserver-kubenode01            1/1     Running   0          3m45s
        kube-system   kube-controller-manager-kubenode01   1/1     Running   0          3m45s
        kube-system   kube-flannel-z8lgq                   1/1     Running   0          2m35s
        kube-system   kube-proxy-4sc5k                     1/1     Running   0          2m39s
        kube-system   kube-scheduler-kubenode01            1/1     Running   1          3m45s
        kube-system   nodelocaldns-z5465                   1/1     Running   0          108s
[17:01:59] # Running command «helm upgrade --install databases-ephemeral wire/databases-ephemeral --wait --debug» on 192.168.1.121
        bash-4.4# helm upgrade --install databases-ephemeral wire/databases-ephemeral --wait --debug
        history.go:56: [debug] getting history for release databases-ephemeral
        Release "databases-ephemeral" does not exist. Installing it now.
        install.go:173: [debug] Original chart version: ""
        install.go:190: [debug] CHART PATH: /root/.cache/helm/repository/databases-ephemeral-2.111.0.tgz
        
        client.go:122: [debug] creating 10 resource(s)
        wait.go:53: [debug] beginning wait for 10 resources with timeout of 5m0s
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/elasticsearch-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        wait.go:353: [debug] StatefulSet is not ready: default/cassandra-ephemeral. 0 out of 1 expected pods are ready
        NAME: databases-ephemeral
        LAST DEPLOYED: Thu Aug 12 14:59:28 2021
        NAMESPACE: default
        STATUS: deployed
        REVISION: 1
        TEST SUITE: None
        USER-SUPPLIED VALUES:
        {}
        
        COMPUTED VALUES:
        cassandra-ephemeral:
          cassandra-ephemeral:
            affinity: {}
            argsOverrides: []
            backup:
              annotations:
                iam.amazonaws.com/role: cain
              destination: s3://bucket/cassandra
              enabled: false
              env:
              - name: AWS_REGION
                value: us-east-1
              extraArgs: []
              image:
                repository: maorfr/cain
                tag: 0.6.0
              resources:
                limits:
                  cpu: 1
                  memory: 1Gi
                requests:
                  cpu: 1
                  memory: 1Gi
              schedule:
              - cron: 0 7 * * *
                keyspace: keyspace1
              - cron: 30 7 * * *
                keyspace: keyspace2
            commandOverrides: []
            config:
              cluster_domain: cluster.local
              cluster_name: cassandra
              cluster_size: 1
              dc_name: DC1
              endpoint_snitch: SimpleSnitch
              heap_new_size: 1024M
              max_heap_size: 2048M
              num_tokens: 256
              ports:
                cql: 9042
                thrift: 9160
              rack_name: RAC1
              seed_size: 1
              start_rpc: false
            configOverrides: {}
            env: {}
            exporter:
              enabled: false
              image:
                repo: criteord/cassandra_exporter
                tag: 2.0.2
              jvmOpts: ""
              port: 5556
              resources: {}
              servicemonitor: true
            global: {}
            hostNetwork: false
            image:
              pullPolicy: IfNotPresent
              repo: cassandra
              tag: 3.11.3
            livenessProbe:
              failureThreshold: 3
              initialDelaySeconds: 90
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 5
            persistence:
              accessMode: ReadWriteOnce
              enabled: false
              size: 10Gi
            podAnnotations: {}
            podDisruptionBudget: {}
            podLabels: {}
            podManagementPolicy: OrderedReady
            podSettings:
              terminationGracePeriodSeconds: 30
            rbac:
              create: true
            readinessProbe:
              address: ${POD_IP}
              failureThreshold: 3
              initialDelaySeconds: 90
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 5
            resources:
              limits:
                cpu: "4"
                memory: 4.0Gi
              requests:
                cpu: "1"
                memory: 2.0Gi
            securityContext:
              enabled: false
              fsGroup: 999
              runAsUser: 999
            service:
              type: ClusterIP
            serviceAccount:
              create: true
            tolerations: []
            updateStrategy:
              type: RollingUpdate
          global: {}
        elasticsearch-ephemeral:
          global: {}
          image:
            repository: elasticsearch
            tag: 6.7.1
          resources:
            limits:
              cpu: 2000m
              memory: 4Gi
            requests:
              cpu: 250m
              memory: 500Mi
          service:
            httpPort: 9200
            transportPort: 9300
        redis-ephemeral:
          global: {}
          redis-ephemeral:
            cluster:
              enabled: false
              slaveCount: 2
            clusterDomain: cluster.local
            configmap: |-
              # Enable AOF https://redis.io/topics/persistence#append-only-file
              appendonly yes
              # Disable RDB persistence, AOF persistence already enabled.
              save ""
            containerSecurityContext:
              enabled: true
              runAsUser: 1001
            global:
              redis: {}
            image:
              pullPolicy: IfNotPresent
              registry: docker.io
              repository: bitnami/redis
              tag: 6.0.9-debian-10-r0
            master:
              affinity: {}
              command: /run.sh
              configmap: null
              customLivenessProbe: {}
              customReadinessProbe: {}
              disableCommands:
              - FLUSHDB
              - FLUSHALL
              extraEnvVars: []
              extraEnvVarsCM: []
              extraEnvVarsSecret: []
              extraFlags: []
              livenessProbe:
                enabled: true
                failureThreshold: 5
                initialDelaySeconds: 5
                periodSeconds: 5
                successThreshold: 1
                timeoutSeconds: 5
              persistence:
                accessModes:
                - ReadWriteOnce
                enabled: false
                matchExpressions: {}
                matchLabels: {}
                path: /data
                size: 8Gi
                subPath: ""
              podAnnotations: {}
              podLabels: {}
              preExecCmds: ""
              priorityClassName: ""
              readinessProbe:
                enabled: true
                failureThreshold: 5
                initialDelaySeconds: 5
                periodSeconds: 5
                successThreshold: 1
                timeoutSeconds: 1
              resources:
                limits:
                  cpu: 1000m
                  memory: 1024Mi
                requests:
                  cpu: 500m
                  memory: 512Mi
              service:
                annotations: {}
                labels: {}
                port: 6379
                type: ClusterIP
              shareProcessNamespace: false
              statefulset:
                labels: {}
                updateStrategy: RollingUpdate
            metrics:
              enabled: false
              image:
                pullPolicy: IfNotPresent
                registry: docker.io
                repository: bitnami/redis-exporter
                tag: 1.12.1-debian-10-r11
              podAnnotations:
                prometheus.io/port: "9121"
                prometheus.io/scrape: "true"
              prometheusRule:
                additionalLabels: {}
                enabled: false
                namespace: ""
                rules: []
              service:
                annotations: {}
                labels: {}
                type: ClusterIP
              serviceMonitor:
                enabled: false
                selector:
                  prometheus: kube-prometheus
            networkPolicy:
              enabled: false
              ingressNSMatchLabels: {}
              ingressNSPodMatchLabels: {}
            password: ""
            persistence: {}
            podDisruptionBudget:
              enabled: false
              minAvailable: 1
            podSecurityPolicy:
              create: false
            rbac:
              create: false
              role:
                rules: []
            redisPort: 6379
            securityContext:
              enabled: true
              fsGroup: 1001
            sentinel:
              customLivenessProbe: {}
              customReadinessProbe: {}
              downAfterMilliseconds: 60000
              enabled: false
              failoverTimeout: 18000
              image:
                pullPolicy: IfNotPresent
                registry: docker.io
                repository: bitnami/redis-sentinel
                tag: 6.0.8-debian-10-r55
              initialCheckTimeout: 5
              livenessProbe:
                enabled: true
                failureThreshold: 5
                initialDelaySeconds: 5
                periodSeconds: 5
                successThreshold: 1
                timeoutSeconds: 5
              masterSet: mymaster
              parallelSyncs: 1
              port: 26379
              quorum: 2
              readinessProbe:
                enabled: true
                failureThreshold: 5
                initialDelaySeconds: 5
                periodSeconds: 5
                successThreshold: 1
                timeoutSeconds: 1
              service:
                annotations: {}
                labels: {}
                redisPort: 6379
                sentinelPort: 26379
                type: ClusterIP
              staticID: false
              usePassword: true
            serviceAccount:
              create: false
            slave:
              affinity: {}
              command: /run.sh
              customLivenessProbe: {}
              customReadinessProbe: {}
              disableCommands:
              - FLUSHDB
              - FLUSHALL
              extraEnvVars: []
              extraEnvVarsCM: []
              extraEnvVarsSecret: []
              extraFlags: []
              livenessProbe:
                enabled: true
                failureThreshold: 5
                initialDelaySeconds: 30
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 5
              persistence:
                accessModes:
                - ReadWriteOnce
                enabled: true
                matchExpressions: {}
                matchLabels: {}
                path: /data
                size: 8Gi
                subPath: ""
              podAnnotations: {}
              podLabels: {}
              port: 6379
              preExecCmds: ""
              readinessProbe:
                enabled: true
                failureThreshold: 5
                initialDelaySeconds: 5
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 10
              service:
                annotations: {}
                labels: {}
                port: 6379
                type: ClusterIP
              shareProcessNamespace: false
              spreadConstraints: {}
              statefulset:
                labels: {}
                updateStrategy: RollingUpdate
            sysctlImage:
              command: []
              enabled: false
              mountHostSys: false
              pullPolicy: Always
              registry: docker.io
              repository: bitnami/minideb
              resources: {}
              tag: buster
            tls:
              authClients: true
              enabled: false
            usePassword: false
            usePasswordFile: false
            volumePermissions:
              enabled: false
              image:
                pullPolicy: Always
                registry: docker.io
                repository: bitnami/minideb
                tag: buster
              resources: {}
              securityContext:
                runAsUser: 0
        
        HOOKS:
        MANIFEST:
        ---
        # Source: databases-ephemeral/charts/redis-ephemeral/charts/redis-ephemeral/templates/configmap-scripts.yaml
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: redis-ephemeral-scripts
          namespace: "default"
          labels:
            app: redis-ephemeral
            chart: redis-ephemeral-11.3.4
            heritage: Helm
            release: databases-ephemeral
        data:
          start-master.sh: |
            #!/bin/bash
            useradd redis
            chown -R redis /data
            if [[ -n $REDIS_PASSWORD_FILE ]]; then
              password_aux=`cat ${REDIS_PASSWORD_FILE}`
              export REDIS_PASSWORD=$password_aux
            fi
            if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
              cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
            fi
            if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
              cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
            fi
            ARGS=("--port" "${REDIS_PORT}")
            ARGS+=("--protected-mode" "no")
            ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
            ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
            exec /run.sh "${ARGS[@]}"
        ---
        # Source: databases-ephemeral/charts/redis-ephemeral/charts/redis-ephemeral/templates/configmap.yaml
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: redis-ephemeral
          namespace: "default"
          labels:
            app: redis-ephemeral
            chart: redis-ephemeral-11.3.4
            heritage: Helm
            release: databases-ephemeral
        data:
          redis.conf: |-
            # User-supplied configuration:
            # Enable AOF https://redis.io/topics/persistence#append-only-file
            appendonly yes
            # Disable RDB persistence, AOF persistence already enabled.
            save ""
          master.conf: |-
            dir /data
            rename-command FLUSHDB ""
            rename-command FLUSHALL ""
          replica.conf: |-
            dir /data
            slave-read-only yes
            rename-command FLUSHDB ""
            rename-command FLUSHALL ""
        ---
        # Source: databases-ephemeral/charts/redis-ephemeral/charts/redis-ephemeral/templates/health-configmap.yaml
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: redis-ephemeral-health
          namespace: "default"
          labels:
            app: redis-ephemeral
            chart: redis-ephemeral-11.3.4
            heritage: Helm
            release: databases-ephemeral
        data:
          ping_readiness_local.sh: |-
            #!/bin/bash
            response=$(
              timeout -s 3 $1 \
              redis-cli \
                -h localhost \
                -p $REDIS_PORT \
                ping
            )
            if [ "$response" != "PONG" ]; then
              echo "$response"
              exit 1
            fi
          ping_liveness_local.sh: |-
            #!/bin/bash
            response=$(
              timeout -s 3 $1 \
              redis-cli \
                -h localhost \
                -p $REDIS_PORT \
                ping
            )
            if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
              echo "$response"
              exit 1
            fi
          ping_readiness_master.sh: |-
            #!/bin/bash
             response=$(
              timeout -s 3 $1 \
              redis-cli \
                -h $REDIS_MASTER_HOST \
                -p $REDIS_MASTER_PORT_NUMBER \
                ping
            )
            if [ "$response" != "PONG" ]; then
              echo "$response"
              exit 1
            fi
          ping_liveness_master.sh: |-
            #!/bin/bash
            response=$(
              timeout -s 3 $1 \
              redis-cli \
                -h $REDIS_MASTER_HOST \
                -p $REDIS_MASTER_PORT_NUMBER \
                ping
            )
            if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
              echo "$response"
              exit 1
            fi
          ping_readiness_local_and_master.sh: |-
            script_dir="$(dirname "$0")"
            exit_status=0
            "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
            "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
            exit $exit_status
          ping_liveness_local_and_master.sh: |-
            script_dir="$(dirname "$0")"
            exit_status=0
            "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
            "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
            exit $exit_status
        ---
        # Source: databases-ephemeral/charts/cassandra-ephemeral/charts/cassandra-ephemeral/templates/service.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: cassandra-ephemeral
          labels:
            app: cassandra-ephemeral
            chart: cassandra-ephemeral-0.13.3
            release: databases-ephemeral
            heritage: Helm
        spec:
          clusterIP: None
          type: ClusterIP
          ports:
          - name: intra
            port: 7000
            targetPort: 7000
          - name: tls
            port: 7001
            targetPort: 7001
          - name: jmx
            port: 7199
            targetPort: 7199
          - name: cql
            port: 9042
            targetPort: 9042
          - name: thrift
            port: 9160
            targetPort: 9160
          selector:
            app: cassandra-ephemeral
            release: databases-ephemeral
        ---
        # Source: databases-ephemeral/charts/elasticsearch-ephemeral/templates/es-svc.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: elasticsearch-ephemeral
          labels:
            wireService: elasticsearch-ephemeral
            app: elasticsearch-ephemeral
            chart: "elasticsearch-ephemeral-2.111.0"
            release: "databases-ephemeral"
            heritage: "Helm"
            component: elasticsearch-ephemeral
        spec:
          type: ClusterIP
          selector:
            component: elasticsearch-ephemeral
          ports:
          - name: http
            port: 9200
            targetPort: 9200
            protocol: TCP
          - name: transport
            port: 9300
            targetPort: 9300
            protocol: TCP
        ---
        # Source: databases-ephemeral/charts/redis-ephemeral/charts/redis-ephemeral/templates/headless-svc.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: redis-ephemeral-headless
          namespace: "default"
          labels:
            app: redis-ephemeral
            chart: redis-ephemeral-11.3.4
            release: databases-ephemeral
            heritage: Helm
        spec:
          type: ClusterIP
          clusterIP: None
          ports:
            - name: redis
              port: 6379
              targetPort: redis
          selector:
            app: redis-ephemeral
            release: databases-ephemeral
        ---
        # Source: databases-ephemeral/charts/redis-ephemeral/charts/redis-ephemeral/templates/redis-master-svc.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: redis-ephemeral-master
          namespace: "default"
          labels:
            app: redis-ephemeral
            chart: redis-ephemeral-11.3.4
            release: databases-ephemeral
            heritage: Helm
        spec:
          type: ClusterIP
          ports:
            - name: redis
              port: 6379
              targetPort: redis
          selector:
            app: redis-ephemeral
            release: databases-ephemeral
            role: master
        ---
        # Source: databases-ephemeral/charts/elasticsearch-ephemeral/templates/es.yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: elasticsearch-ephemeral
          labels:
            wireService: elasticsearch-ephemeral
            app: elasticsearch-ephemeral
            chart: "elasticsearch-ephemeral-2.111.0"
            release: "databases-ephemeral"
            heritage: "Helm"
            component: elasticsearch-ephemeral
        spec:
          replicas: 1
          selector:
            matchLabels:
              component: elasticsearch-ephemeral
          template:
            metadata:
              labels:
                component: elasticsearch-ephemeral
            spec:
              containers:
              - name: es
                image: "elasticsearch:6.7.1"
                env:
                - name: MAX_HEAP_SIZE
                  value: "2048"
                - name: HEAP_NEWSIZE
                  value: "800M"
                - name: "bootstrap.system_call_filter"
                  value: "false"
                - name: "discovery.type"
                  value: "single-node"
                ports:
                - containerPort: 9200
                  name: http
                  protocol: TCP
                - containerPort: 9300
                  name: transport
                  protocol: TCP
                volumeMounts:
                - name: storage
                  mountPath: /data
                resources:
                    limits:
                      cpu: 2000m
                      memory: 4Gi
                    requests:
                      cpu: 250m
                      memory: 500Mi
              volumes:
                - emptyDir:
                    medium: ""
                  name: "storage"
        ---
        # Source: databases-ephemeral/charts/cassandra-ephemeral/charts/cassandra-ephemeral/templates/statefulset.yaml
        apiVersion: apps/v1
        kind: StatefulSet
        metadata:
          name: cassandra-ephemeral
          labels:
            app: cassandra-ephemeral
            chart: cassandra-ephemeral-0.13.3
            release: databases-ephemeral
            heritage: Helm
        spec:
          selector:
            matchLabels:
              app: cassandra-ephemeral
              release: databases-ephemeral
          serviceName: cassandra-ephemeral
          replicas: 1
          podManagementPolicy: OrderedReady
          updateStrategy:
            type: RollingUpdate
          template:
            metadata:
              labels:
                app: cassandra-ephemeral
                release: databases-ephemeral
            spec:
              hostNetwork: false
              containers:
              - name: cassandra-ephemeral
                image: "cassandra:3.11.3"
                imagePullPolicy: "IfNotPresent"
                resources:
                  limits:
                    cpu: "4"
                    memory: 4.0Gi
                  requests:
                    cpu: "1"
                    memory: 2.0Gi
                env:
                - name: CASSANDRA_SEEDS
                  value: "cassandra-ephemeral-0.cassandra-ephemeral.default.svc.cluster.local"
                - name: MAX_HEAP_SIZE
                  value: "2048M"
                - name: HEAP_NEWSIZE
                  value: "1024M"
                - name: CASSANDRA_ENDPOINT_SNITCH
                  value: "SimpleSnitch"
                - name: CASSANDRA_CLUSTER_NAME
                  value: "cassandra"
                - name: CASSANDRA_DC
                  value: "DC1"
                - name: CASSANDRA_RACK
                  value: "RAC1"
                - name: CASSANDRA_START_RPC
                  value: "false"
                - name: POD_IP
                  valueFrom:
                    fieldRef:
                      fieldPath: status.podIP
                livenessProbe:
                  exec:
                    command: [ "/bin/sh", "-c", "nodetool status" ]
                  initialDelaySeconds: 90
                  periodSeconds: 30
                  timeoutSeconds: 5
                  successThreshold: 1
                  failureThreshold: 3
                readinessProbe:
                  exec:
                    command: [ "/bin/sh", "-c", "nodetool status | grep -E \"^UN\\s+${POD_IP}\"" ]
                  initialDelaySeconds: 90
                  periodSeconds: 30
                  timeoutSeconds: 5
                  successThreshold: 1
                  failureThreshold: 3
                ports:
                - name: intra
                  containerPort: 7000
                - name: tls
                  containerPort: 7001
                - name: jmx
                  containerPort: 7199
                - name: cql
                  containerPort: 9042
                - name: thrift
                  containerPort: 9160
                volumeMounts:
                - name: data
                  mountPath: /var/lib/cassandra
                lifecycle:
                  preStop:
                    exec:
                      command: ["/bin/sh", "-c", "exec nodetool decommission"]
              terminationGracePeriodSeconds: 30
              volumes:
              - name: data
                emptyDir: {}
        ---
        # Source: databases-ephemeral/charts/redis-ephemeral/charts/redis-ephemeral/templates/redis-master-statefulset.yaml
        apiVersion: apps/v1
        kind: StatefulSet
        metadata:
          name: redis-ephemeral-master
          namespace: "default"
          labels:
            app: redis-ephemeral
            chart: redis-ephemeral-11.3.4
            release: databases-ephemeral
            heritage: Helm
        spec:
          selector:
            matchLabels:
              app: redis-ephemeral
              release: databases-ephemeral
              role: master
          serviceName: redis-ephemeral-headless
          template:
            metadata:
              labels:
                app: redis-ephemeral
                chart: redis-ephemeral-11.3.4
                release: databases-ephemeral
                role: master
              annotations:
                checksum/health: e8c90bae4ee68e3ea33f86992512385397556e9993eb7bbd613035880121814b
                checksum/configmap: f3cb092ae316f13c0503c3bcf837885791c9f5365d6168ea83b3c45f40743f5a
                checksum/secret: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
            spec:
        
              securityContext:
                fsGroup: 1001
              serviceAccountName: default
              containers:
                - name: redis-ephemeral
                  image: docker.io/bitnami/redis:6.0.9-debian-10-r0
                  imagePullPolicy: "IfNotPresent"
                  securityContext:
                    runAsUser: 1001
                  command:
                    - /bin/bash
                    - -c
                    - /opt/bitnami/scripts/start-scripts/start-master.sh
                  env:
                    - name: REDIS_REPLICATION_MODE
                      value: master
                    - name: ALLOW_EMPTY_PASSWORD
                      value: "yes"
                    - name: REDIS_TLS_ENABLED
                      value: "no"
                    - name: REDIS_PORT
                      value: "6379"
                  ports:
                    - name: redis
                      containerPort: 6379
                  livenessProbe:
                    initialDelaySeconds: 5
                    periodSeconds: 5
                    # One second longer than command timeout should prevent generation of zombie processes.
                    timeoutSeconds: 6
                    successThreshold: 1
                    failureThreshold: 5
                    exec:
                      command:
                        - sh
                        - -c
                        - /health/ping_liveness_local.sh 5
                  readinessProbe:
                    initialDelaySeconds: 5
                    periodSeconds: 5
                    timeoutSeconds: 2
                    successThreshold: 1
                    failureThreshold: 5
                    exec:
                      command:
                        - sh
                        - -c
                        - /health/ping_readiness_local.sh 1
                  resources:
                    limits:
                      cpu: 1000m
                      memory: 1024Mi
                    requests:
                      cpu: 500m
                      memory: 512Mi
                  volumeMounts:
                    - name: start-scripts
                      mountPath: /opt/bitnami/scripts/start-scripts
                    - name: health
                      mountPath: /health
                    - name: redis-data
                      mountPath: /data
                      subPath:
                    - name: config
                      mountPath: /opt/bitnami/redis/mounted-etc
                    - name: redis-tmp-conf
                      mountPath: /opt/bitnami/redis/etc/
              volumes:
                - name: start-scripts
                  configMap:
                    name: redis-ephemeral-scripts
                    defaultMode: 0755
                - name: health
                  configMap:
                    name: redis-ephemeral-health
                    defaultMode: 0755
                - name: config
                  configMap:
                    name: redis-ephemeral
                - name: "redis-data"
                  emptyDir: {}
                - name: redis-tmp-conf
                  emptyDir: {}
          updateStrategy:
            type: RollingUpdate
        
        NOTES:
        You now have an in-memory, non-persistent, non-highly-available set of databases:
        
        * cassandra-ephemeral
        * elasticsearch-ephemeral
        * redis-ephemeral
        
        !! WARNING WARNING !!
        This is fine for testing and demo purposes, but NOT for a production use case.
        !! WARNING WARNING !!
        
        Note that before use of these databases for wire-server components, an index (in the case of elasticsearch) and a set of cassandra-migrations (in the case of cassandra) have to be applied. This comes bundled with the wire-server chart (see cassandra-migrations and elastic
        search-index charts for details)
[17:03:52] # Running command «helm upgrade --install fake-aws wire/fake-aws --wait --debug» on 192.168.1.121
        bash-4.4# helm upgrade --install fake-aws wire/fake-aws --wait --debug
        history.go:56: [debug] getting history for release fake-aws
        Release "fake-aws" does not exist. Installing it now.
        install.go:173: [debug] Original chart version: ""
        install.go:190: [debug] CHART PATH: /root/.cache/helm/repository/fake-aws-2.111.0.tgz
        
        client.go:122: [debug] creating 13 resource(s)
        wait.go:53: [debug] beginning wait for 13 resources with timeout of 5m0s
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-s3. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-s3. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-s3. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-s3. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-s3. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sns. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/fake-aws-sqs. 0 out of 1 expected pods are ready
        client.go:282: [debug] Starting delete for "fake-aws-s3-make-bucket-job" Job
        client.go:311: [debug] jobs.batch "fake-aws-s3-make-bucket-job" not found
        client.go:122: [debug] creating 1 resource(s)
        client.go:491: [debug] Watching for changes to Job fake-aws-s3-make-bucket-job with timeout of 5m0s
        client.go:519: [debug] Add/Modify event for fake-aws-s3-make-bucket-job: ADDED
        client.go:558: [debug] fake-aws-s3-make-bucket-job: Jobs active: 1, jobs failed: 0, jobs succeeded: 0
        client.go:519: [debug] Add/Modify event for fake-aws-s3-make-bucket-job: MODIFIED
        client.go:282: [debug] Starting delete for "fake-aws-s3-make-bucket-job" Job
        NAME: fake-aws
        LAST DEPLOYED: Thu Aug 12 15:02:14 2021
        NAMESPACE: default
        STATUS: deployed
        REVISION: 1
        TEST SUITE: None
        USER-SUPPLIED VALUES:
        {}
        
        COMPUTED VALUES:
        fake-aws-s3:
          enabled: true
          global: {}
          minio:
            DeploymentUpdate:
              maxSurge: 100%
              maxUnavailable: 0
              type: RollingUpdate
            StatefulSetUpdate:
              updateStrategy: RollingUpdate
            accessKey: dummykey
            affinity: {}
            azuregateway:
              enabled: false
              replicas: 4
            bucketRoot: ""
            buckets:
            - name: dummy-bucket
              policy: none
              purge: true
            - name: assets
              policy: none
              purge: false
            - name: public
              policy: public
              purge: false
            certsPath: /etc/minio/certs/
            clusterDomain: cluster.local
            configPathmc: /etc/minio/mc/
            defaultBucket:
              enabled: false
              name: bucket
              policy: none
              purge: false
            drivesPerNode: 1
            environment:
              MINIO_BROWSER: "off"
            etcd:
              clientCert: ""
              clientCertKey: ""
              corednsPathPrefix: ""
              endpoints: []
              pathPrefix: ""
            existingSecret: ""
            extraArgs: []
            fullnameOverride: fake-aws-s3
            gcsgateway:
              enabled: false
              gcsKeyJson: ""
              projectId: ""
              replicas: 4
            global: {}
            helmKubectlJqImage:
              pullPolicy: IfNotPresent
              repository: bskim45/helm-kubectl-jq
              tag: 3.1.0
            image:
              pullPolicy: IfNotPresent
              repository: minio/minio
              tag: RELEASE.2020-10-18T21-54-12Z
            imagePullSecrets: []
            ingress:
              annotations: {}
              enabled: false
              hosts:
              - chart-example.local
              labels: {}
              path: /
              tls: []
            makeBucketJob:
              resources:
                requests:
                  memory: 128Mi
              securityContext:
                enabled: false
                fsGroup: 1000
                runAsGroup: 1000
                runAsUser: 1000
            mcImage:
              pullPolicy: IfNotPresent
              repository: minio/mc
              tag: RELEASE.2020-10-03T02-54-56Z
            metrics:
              serviceMonitor:
                additionalLabels: {}
                enabled: false
            mode: standalone
            mountPath: /export
            nameOverride: ""
            nasgateway:
              enabled: false
              replicas: 4
            networkPolicy:
              allowExternal: true
              enabled: false
            nodeSelector: {}
            persistence:
              VolumeName: ""
              accessMode: ReadWriteOnce
              enabled: false
              existingClaim: ""
              size: 500Gi
              storageClass: ""
              subPath: ""
            podAnnotations: {}
            podDisruptionBudget:
              enabled: false
              maxUnavailable: 1
            podLabels: {}
            priorityClassName: ""
            replicas: 4
            resources:
              requests:
                memory: 4Gi
            s3gateway:
              accessKey: ""
              enabled: false
              replicas: 4
              secretKey: ""
              serviceEndpoint: ""
            secretKey: dummysecret
            securityContext:
              enabled: true
              fsGroup: 1000
              runAsGroup: 1000
              runAsUser: 1000
            service:
              annotations: {}
              externalIPs: []
              nodePort: 32000
              port: 9000
              type: ClusterIP
            serviceAccount:
              create: true
            tls:
              certSecret: ""
              enabled: false
              privateKey: private.key
              publicCrt: public.crt
            tolerations: []
            trustedCertsSecret: ""
            updatePrometheusJob:
              securityContext:
                enabled: false
                fsGroup: 1000
                runAsGroup: 1000
                runAsUser: 1000
            zones: 1
        fake-aws-ses:
          enabled: false
          global: {}
          image:
            repository: localstack/localstack
            tag: 0.8.7
          resources:
            limits:
              cpu: 200m
              memory: 500Mi
            requests:
              cpu: 100m
              memory: 100Mi
          service:
            externalPort: 4569
            internalPort: 4579
        fake-aws-sns:
          applications:
          - credential: testkey
            name: integration-test
            platform: GCM
          - credential: testprivatekey
            name: integration-test
            platform: APNS_SANDBOX
          - credential: testprivatekey
            name: integration-com.wire.ent
            platform: APNS_SANDBOX
          enabled: true
          global: {}
          image:
            repository: localstack/localstack
            tag: 0.8.7
          resources:
            limits:
              cpu: 200m
              memory: 500Mi
            requests:
              cpu: 100m
              memory: 100Mi
          service:
            externalPort: 4575
            internalPort: 4575
        fake-aws-sqs:
          enabled: true
          global: {}
          image:
            repository: airdock/fake-sqs
            tag: 0.3.1
          queueNames:
          - integration-team-events.fifo
          - integration-brig-events
          - integration-brig-events-internal
          - integration-gundeck-events
          resources:
            limits:
              cpu: 1000m
              memory: 1000Mi
            requests:
              cpu: 100m
              memory: 256Mi
          service:
            httpPort: 4568
        
        HOOKS:
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/post-install-create-bucket-job.yaml
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: fake-aws-s3-make-bucket-job
          labels:
            app: minio-make-bucket-job
            chart: minio-8.0.3
            release: fake-aws
            heritage: Helm
          annotations:
            "helm.sh/hook": post-install,post-upgrade
            "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
        spec:
          template:
            metadata:
              labels:
                app: minio-job
                release: fake-aws
            spec:
              restartPolicy: OnFailure
              volumes:
                - name: minio-configuration
                  projected:
                    sources:
                    - configMap:
                        name: fake-aws-s3
                    - secret:
                        name: fake-aws-s3
              serviceAccountName: "fake-aws-s3"
              containers:
              - name: minio-mc
                image: "minio/mc:RELEASE.2020-10-03T02-54-56Z"
                imagePullPolicy: IfNotPresent
                command: ["/bin/sh", "/config/initialize"]
                env:
                  - name: MINIO_ENDPOINT
                    value: fake-aws-s3
                  - name: MINIO_PORT
                    value: "9000"
                volumeMounts:
                  - name: minio-configuration
                    mountPath: /config
                resources:
                  requests:
                    memory: 128Mi
        MANIFEST:
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/post-install-prometheus-metrics-serviceaccount.yaml
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: fake-aws-s3-update-prometheus-secret
          labels:
            app: minio-update-prometheus-secret
            chart: minio-8.0.3
            release: fake-aws
            heritage: Helm
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/serviceaccount.yaml
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: "fake-aws-s3"
          namespace: "default"
          labels:
            app: minio
            chart: minio-8.0.3
            release: "fake-aws"
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/secrets.yaml
        apiVersion: v1
        kind: Secret
        metadata:
          name: fake-aws-s3
          labels:
            app: minio
            chart: minio-8.0.3
            release: fake-aws
            heritage: Helm
        type: Opaque
        data:
          accesskey: "ZHVtbXlrZXk="
          secretkey: "ZHVtbXlzZWNyZXQ="
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/configmap.yaml
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: fake-aws-s3
          labels:
            app: minio
            chart: minio-8.0.3
            release: fake-aws
            heritage: Helm
        data:
          initialize: |-
            #!/bin/sh
            set -e ; # Have script exit in the event of a failed command.
            MC_CONFIG_DIR="/etc/minio/mc/"
            MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
        
            # connectToMinio
            # Use a check-sleep-check loop to wait for Minio service to be available
            connectToMinio() {
              SCHEME=$1
              ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
              set -e ; # fail if we can't read the keys.
              ACCESS=$(cat /config/accesskey) ; SECRET=$(cat /config/secretkey) ;
              set +e ; # The connections to minio are allowed to fail.
              echo "Connecting to Minio server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
              MC_COMMAND="${MC} config host add myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
              $MC_COMMAND ;
              STATUS=$? ;
              until [ $STATUS = 0 ]
              do
                ATTEMPTS=`expr $ATTEMPTS + 1` ;
                echo \"Failed attempts: $ATTEMPTS\" ;
                if [ $ATTEMPTS -gt $LIMIT ]; then
                  exit 1 ;
                fi ;
                sleep 2 ; # 1 second intervals between attempts
                $MC_COMMAND ;
                STATUS=$? ;
              done ;
              set -e ; # reset `e` as active
              return 0
            }
        
            # checkBucketExists ($bucket)
            # Check if the bucket exists, by using the exit code of `mc ls`
            checkBucketExists() {
              BUCKET=$1
              CMD=$(${MC} ls myminio/$BUCKET > /dev/null 2>&1)
              return $?
            }
        
            # createBucket ($bucket, $policy, $purge)
            # Ensure bucket exists, purging if asked to
            createBucket() {
              BUCKET=$1
              POLICY=$2
              PURGE=$3
              VERSIONING=$4
        
              # Purge the bucket, if set & exists
              # Since PURGE is user input, check explicitly for `true`
              if [ $PURGE = true ]; then
                if checkBucketExists $BUCKET ; then
                  echo "Purging bucket '$BUCKET'."
                  set +e ; # don't exit if this fails
                  ${MC} rm -r --force myminio/$BUCKET
                  set -e ; # reset `e` as active
                else
                  echo "Bucket '$BUCKET' does not exist, skipping purge."
                fi
              fi
        
              # Create the bucket if it does not exist
              if ! checkBucketExists $BUCKET ; then
                echo "Creating bucket '$BUCKET'"
                ${MC} mb myminio/$BUCKET
              else
                echo "Bucket '$BUCKET' already exists."
              fi
        
        
              # set versioning for bucket
              if [ ! -z $VERSIONING ] ; then
                if [ $VERSIONING = true ] ; then
                    echo "Enabling versioning for '$BUCKET'"
                    ${MC} version enable myminio/$BUCKET
                elif [ $VERSIONING = false ] ; then
                    echo "Suspending versioning for '$BUCKET'"
                    ${MC} version suspend myminio/$BUCKET
                fi
              else
                  echo "Bucket '$BUCKET' versioning unchanged."
              fi
        
              # At this point, the bucket should exist, skip checking for existence
              # Set policy on the bucket
              echo "Setting policy of bucket '$BUCKET' to '$POLICY'."
              ${MC} policy set $POLICY myminio/$BUCKET
            }
        
            # Try connecting to Minio instance
            scheme=http
            connectToMinio $scheme
            # Create the buckets
            createBucket dummy-bucket none true
            createBucket assets none false
            createBucket public public false
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/post-install-prometheus-metrics-role.yaml
        apiVersion: rbac.authorization.k8s.io/v1
        kind: Role
        metadata:
          name: fake-aws-s3-update-prometheus-secret
          labels:
            app: minio-update-prometheus-secret
            chart: minio-8.0.3
            release: fake-aws
            heritage: Helm
        rules:
          - apiGroups:
              - ""
            resources:
              - secrets
            verbs:
              - get
              - create
              - update
              - patch
            resourceNames:
              - fake-aws-s3-prometheus
          - apiGroups:
              - ""
            resources:
              - secrets
            verbs:
              - create
          - apiGroups:
              - monitoring.coreos.com
            resources:
              - servicemonitors
            verbs:
              - get
            resourceNames:
              - fake-aws-s3
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/post-install-prometheus-metrics-rolebinding.yaml
        apiVersion: rbac.authorization.k8s.io/v1
        kind: RoleBinding
        metadata:
          name: fake-aws-s3-update-prometheus-secret
          labels:
            app: minio-update-prometheus-secret
            chart: minio-8.0.3
            release: fake-aws
            heritage: Helm
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: Role
          name: fake-aws-s3-update-prometheus-secret
        subjects:
          - kind: ServiceAccount
            name: fake-aws-s3-update-prometheus-secret
            namespace: "default"
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/service.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: fake-aws-s3
          labels:
            app: minio
            chart: minio-8.0.3
            release: fake-aws
            heritage: Helm
        spec:
          type: ClusterIP
          ports:
            - name: http
              port: 9000
              protocol: TCP
              targetPort: 9000
          selector:
            app: minio
            release: fake-aws
        ---
        # Source: fake-aws/charts/fake-aws-sns/templates/service.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: fake-aws-sns
          labels:
            app: fake-aws-sns
            chart: "fake-aws-sns-2.111.0"
            release: "fake-aws"
            heritage: "Helm"
        spec:
          type: ClusterIP
          selector:
            app: fake-aws-sns
          ports:
            - name: http
              port: 4575
              targetPort: 4575
              protocol: TCP
        ---
        # Source: fake-aws/charts/fake-aws-sqs/templates/service.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: fake-aws-sqs
          labels:
            app: fake-aws-sqs
            chart: "fake-aws-sqs-2.111.0"
            release: "fake-aws"
            heritage: "Helm"
        spec:
          type: ClusterIP
          selector:
            app: fake-aws-sqs
          ports:
            - name: http
              port: 4568
              targetPort: 4568
              protocol: TCP
        ---
        # Source: fake-aws/charts/fake-aws-s3/charts/minio/templates/deployment.yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: fake-aws-s3
          labels:
            app: minio
            chart: minio-8.0.3
            release: fake-aws
            heritage: Helm
        spec:
          strategy:
            type: RollingUpdate
            rollingUpdate:
              maxSurge: 100%
              maxUnavailable: 0
          selector:
            matchLabels:
              app: minio
              release: fake-aws
          template:
            metadata:
              name: fake-aws-s3
              labels:
                app: minio
                release: fake-aws
              annotations:
                checksum/secrets: e309d074ad8b38e7ca5627c8f7d956390f5af83e0d5a16c45aa5611fb2519f52
                checksum/config: cc64be52d6c6c9e047232e55d24877c2227a6b5a0c1f5fded18ef0375936a50b
            spec:
              serviceAccountName: "fake-aws-s3"
              containers:
                - name: minio
                  image: "minio/minio:RELEASE.2020-10-18T21-54-12Z"
                  imagePullPolicy: IfNotPresent
                  command:
                    - "/bin/sh"
                    - "-ce"
                    - "/usr/bin/docker-entrypoint.sh minio -S /etc/minio/certs/ server /export"
                  volumeMounts:
                  ports:
                    - name: http
                      containerPort: 9000
                  env:
                    - name: MINIO_ACCESS_KEY
                      valueFrom:
                        secretKeyRef:
                          name: fake-aws-s3
                          key: accesskey
                    - name: MINIO_SECRET_KEY
                      valueFrom:
                        secretKeyRef:
                          name: fake-aws-s3
                          key: secretkey
                    - name: MINIO_BROWSER
                      value: "off"
                  resources:
                    requests:
                      memory: 4Gi
              volumes:
                - name: export
                  emptyDir: {}
                - name: minio-user
                  secret:
                    secretName: fake-aws-s3
        ---
        # Source: fake-aws/charts/fake-aws-s3/templates/reaper.yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: fake-aws-s3-reaper
          labels:
            app: fake-aws-s3-reaper
            chart: "fake-aws-s3-2.111.0"
            release: "fake-aws"
            heritage: "Helm"
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: fake-aws-s3-reaper
          template:
            metadata:
              labels:
                app: fake-aws-s3-reaper
            spec:
              containers:
              - name: initiate-fake-aws-s3
                image: mesosphere/aws-cli:1.14.5
                command: [/bin/sh]
                args:
                - -c
                - |
                  echo 'Creating AWS resources'
                  while true
                  do
                      AWS_SECRET_ACCESS_KEY=dummysecret AWS_ACCESS_KEY_ID=dummykey aws s3 --endpoint http://fake-aws-s3:9000 mb s3://bucket | grep -ev "BucketAlreadyOwnedByYou"
                      sleep 10
                  done
        ---
        # Source: fake-aws/charts/fake-aws-sns/templates/deployment.yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: fake-aws-sns
          labels:
            app: fake-aws-sns
            chart: "fake-aws-sns-2.111.0"
            release: "fake-aws"
            heritage: "Helm"
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: fake-aws-sns
          template:
            metadata:
              labels:
                app: fake-aws-sns
            spec:
              containers:
              - name: fake-aws-sns
                image: "localstack/localstack:0.8.7"
                env:
                  - name: DEBUG
                    value: "1"
                  - name: DEFAULT_REGION
                    value: "eu-west-1"
                  - name: SERVICES
                    value: "sns"
                ports:
                - containerPort: 4575
                  name: http
                  protocol: TCP
                volumeMounts:
                - name: storage
                  mountPath: /data
                resources:
                    limits:
                      cpu: 200m
                      memory: 500Mi
                    requests:
                      cpu: 100m
                      memory: 100Mi
              - name: initiate-fake-aws-sns
                image: mesosphere/aws-cli:1.14.5
                command: [/bin/sh]
                args:
                - -c
                - |
                  exec_until_ready() {
                      until $1; do echo 'service not ready yet'; sleep 1; done
                  }
                  application_exists() {
                      OUTPUT=$(aws --endpoint-url=http://localhost:4575 sns list-platform-applications | grep $1 | wc -l)
                      echo $OUTPUT
                  }
                  echo 'Creating AWS resources'
                  aws configure set aws_access_key_id dummy
                  aws configure set aws_secret_access_key dummy
                  aws configure set region eu-west-1
        
                  while true
                  do
        
                          APPLICATION=$(application_exists "GCM/integration-test")
                          if [ "$APPLICATION" == "1" ]
                            then echo "Application integration-test exists, no need to re-create"
                            else exec_until_ready "aws --endpoint-url=http://localhost:4575 sns create-platform-application --name integration-test --platform GCM --attributes PlatformCredential=testkey"
                          fi
        
                          APPLICATION=$(application_exists "APNS_SANDBOX/integration-test")
                          if [ "$APPLICATION" == "1" ]
                            then echo "Application integration-test exists, no need to re-create"
                            else exec_until_ready "aws --endpoint-url=http://localhost:4575 sns create-platform-application --name integration-test --platform APNS_SANDBOX --attributes PlatformCredential=testprivatekey"
                          fi
        
                          APPLICATION=$(application_exists "APNS_SANDBOX/integration-com.wire.ent")
                          if [ "$APPLICATION" == "1" ]
                            then echo "Application integration-com.wire.ent exists, no need to re-create"
                            else exec_until_ready "aws --endpoint-url=http://localhost:4575 sns create-platform-application --name integration-com.wire.ent --platform APNS_SANDBOX --attributes PlatformCredential=testprivatekey"
                          fi
        
                      echo "Resources created, sleeping for 10, to keep this container (and thus the pod) alive"
                      sleep 10
                  done
              volumes:
                - emptyDir: {}
                  name: "storage"
        ---
        # Source: fake-aws/charts/fake-aws-sqs/templates/deployment.yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: fake-aws-sqs
          labels:
            app: fake-aws-sqs
            chart: "fake-aws-sqs-2.111.0"
            release: "fake-aws"
            heritage: "Helm"
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: fake-aws-sqs
          template:
            metadata:
              labels:
                app: fake-aws-sqs
            spec:
              containers:
              - name: fake-aws-sqs
                image: "airdock/fake-sqs:0.3.1"
                ports:
                - containerPort: 4568
                  name: http
                  protocol: TCP
                volumeMounts:
                - name: storage
                  mountPath: /data
                resources:
                    limits:
                      cpu: 1000m
                      memory: 1000Mi
                    requests:
                      cpu: 100m
                      memory: 256Mi
              - name: initiate-fake-aws-sqs
                image: mesosphere/aws-cli:1.14.5
                command: [/bin/sh]
                args:
                - -c
                - |
                  exec_until_ready() {
                      until $1; do echo 'service not ready yet'; sleep 1; done
                  }
                  queue_exists() {
                      # NOTE: we use the '"' to match the queue name more exactly (otherwise there is some overlap)
                      OUTPUT=$(aws --endpoint-url=http://localhost:4568 sqs list-queues | grep $1'"' | wc -l)
                      echo $OUTPUT
                  }
        
                  echo 'Creating AWS resources'
                  aws configure set aws_access_key_id dummy
                  aws configure set aws_secret_access_key dummy
                  aws configure set region eu-west-1
        
                  while true
                  do
                      # Recreate resources if needed
        
                          QUEUE=$(queue_exists "integration-team-events.fifo")
                          if [ "$QUEUE" == "1" ]
                            then echo "Queue integration-team-events.fifo exists, no need to re-create"
                            else exec_until_ready "aws --endpoint-url=http://localhost:4568 sqs create-queue --queue-name integration-team-events.fifo"
                          fi
        
                          QUEUE=$(queue_exists "integration-brig-events")
                          if [ "$QUEUE" == "1" ]
                            then echo "Queue integration-brig-events exists, no need to re-create"
                            else exec_until_ready "aws --endpoint-url=http://localhost:4568 sqs create-queue --queue-name integration-brig-events"
                          fi
        
                          QUEUE=$(queue_exists "integration-brig-events-internal")
                          if [ "$QUEUE" == "1" ]
                            then echo "Queue integration-brig-events-internal exists, no need to re-create"
                            else exec_until_ready "aws --endpoint-url=http://localhost:4568 sqs create-queue --queue-name integration-brig-events-internal"
                          fi
        
                          QUEUE=$(queue_exists "integration-gundeck-events")
                          if [ "$QUEUE" == "1" ]
                            then echo "Queue integration-gundeck-events exists, no need to re-create"
                            else exec_until_ready "aws --endpoint-url=http://localhost:4568 sqs create-queue --queue-name integration-gundeck-events"
                          fi
        
        
                      echo 'Sleeping 10'
                      sleep 10
                  done
              volumes:
                - emptyDir: {}
                  name: "storage"
        
        NOTES:
        You can reach the fake AWS services at:
        SNS      : http://fake-aws-sns:4575
        SQS      : http://fake-aws-sqs:4568
          queues:
            - integration-team-events.fifo
            - integration-brig-events
            - integration-brig-events-internal
            - integration-gundeck-events
        S3       : http://fake-aws-s3:9000
          bucket: bucket
[17:03:58] # Running command «kubectl get pods -A» on 192.168.1.121
        bash-4.4# kubectl get pods -A
        NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE
        default       cassandra-ephemeral-0                      1/1     Running   0          4m27s
        default       elasticsearch-ephemeral-86f4b8ff6f-thxn2   1/1     Running   0          4m27s
        default       fake-aws-s3-77d9447b8f-9gx46               1/1     Running   0          100s
        default       fake-aws-s3-reaper-78d9f58dd4-ngq6k        1/1     Running   0          100s
        default       fake-aws-sns-6c7c4b7479-9bkf2              2/2     Running   0          100s
        default       fake-aws-sqs-59fbfbcbd4-gwmzd              2/2     Running   0          100s
        default       redis-ephemeral-master-0                   1/1     Running   0          4m27s
        kube-system   coredns-7677f9bb54-kv2pk                   1/1     Running   0          6m43s
        kube-system   coredns-7677f9bb54-pp6sc                   0/1     Pending   0          6m36s
        kube-system   dns-autoscaler-5b7b5c9b6f-mcvnc            1/1     Running   0          6m38s
        kube-system   kube-apiserver-kubenode01                  1/1     Running   0          8m32s
        kube-system   kube-controller-manager-kubenode01         1/1     Running   0          8m32s
        kube-system   kube-flannel-z8lgq                         1/1     Running   0          7m22s
        kube-system   kube-proxy-4sc5k                           1/1     Running   0          7m26s
        kube-system   kube-scheduler-kubenode01                  1/1     Running   1          8m32s
        kube-system   nodelocaldns-z5465                         1/1     Running   0          6m35s
[17:04:32] # Running command «helm upgrade --install smtp wire/demo-smtp --wait --debug» on 192.168.1.121
        bash-4.4# helm upgrade --install smtp wire/demo-smtp --wait --debug
        history.go:56: [debug] getting history for release smtp
        Release "smtp" does not exist. Installing it now.
        install.go:173: [debug] Original chart version: ""
        install.go:190: [debug] CHART PATH: /root/.cache/helm/repository/demo-smtp-2.111.0.tgz
        
        client.go:122: [debug] creating 2 resource(s)
        wait.go:53: [debug] beginning wait for 2 resources with timeout of 5m0s
        wait.go:244: [debug] Deployment is not ready: default/demo-smtp. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/demo-smtp. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/demo-smtp. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/demo-smtp. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/demo-smtp. 0 out of 1 expected pods are ready
        wait.go:244: [debug] Deployment is not ready: default/demo-smtp. 0 out of 1 expected pods are ready
        NAME: smtp
        LAST DEPLOYED: Thu Aug 12 15:04:13 2021
        NAMESPACE: default
        STATUS: deployed
        REVISION: 1
        TEST SUITE: None
        USER-SUPPLIED VALUES:
        {}
        
        COMPUTED VALUES:
        envVars: {}
        fullnameOverride: demo-smtp
        image: quay.io/wire/namshi-smtp:aa63b8
        replicaCount: 1
        resources:
          limits:
            cpu: 500m
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 128Mi
        service:
          port: 25
        
        HOOKS:
        MANIFEST:
        ---
        # Source: demo-smtp/templates/service.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: demo-smtp
          labels:
            app: demo-smtp
            chart: demo-smtp-2.111.0
            release: smtp
            heritage: Helm
        spec:
          type:
          ports:
            - port: 25
              targetPort: smtp
              protocol: TCP
              name: smtp
          selector:
            app: demo-smtp
            release: smtp
        ---
        # Source: demo-smtp/templates/deployment.yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: demo-smtp
          labels:
            app: demo-smtp
            chart: demo-smtp-2.111.0
            release: smtp
            heritage: Helm
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: demo-smtp
              release: smtp
          template:
            metadata:
              labels:
                app: demo-smtp
                release: smtp
            spec:
              containers:
                - name: demo-smtp
                  image: "quay.io/wire/namshi-smtp:aa63b8"
                  env:
                  ports:
                    - name: smtp
                      containerPort: 25
                      protocol: TCP
                  resources:
                    limits:
                      cpu: 500m
                      memory: 500Mi
                    requests:
                      cpu: 100m
                      memory: 128Mi
        
[17:04:38] # Running command «kubectl get pods -A» on 192.168.1.121
        bash-4.4# kubectl get pods -A
        NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE
        default       cassandra-ephemeral-0                      1/1     Running   0          5m6s
        default       demo-smtp-85557f6877-qxk2p                 1/1     Running   0          21s
        default       elasticsearch-ephemeral-86f4b8ff6f-thxn2   1/1     Running   0          5m6s
        default       fake-aws-s3-77d9447b8f-9gx46               1/1     Running   0          2m19s
        default       fake-aws-s3-reaper-78d9f58dd4-ngq6k        1/1     Running   0          2m19s
        default       fake-aws-sns-6c7c4b7479-9bkf2              2/2     Running   0          2m19s
        default       fake-aws-sqs-59fbfbcbd4-gwmzd              2/2     Running   0          2m19s
        default       redis-ephemeral-master-0                   1/1     Running   0          5m6s
        kube-system   coredns-7677f9bb54-kv2pk                   1/1     Running   0          7m22s
        kube-system   coredns-7677f9bb54-pp6sc                   0/1     Pending   0          7m15s
        kube-system   dns-autoscaler-5b7b5c9b6f-mcvnc            1/1     Running   0          7m17s
        kube-system   kube-apiserver-kubenode01                  1/1     Running   0          9m11s
        kube-system   kube-controller-manager-kubenode01         1/1     Running   0          9m11s
        kube-system   kube-flannel-z8lgq                         1/1     Running   0          8m1s
        kube-system   kube-proxy-4sc5k                           1/1     Running   0          8m5s
        kube-system   kube-scheduler-kubenode01                  1/1     Running   1          9m11s
        kube-system   nodelocaldns-z5465                         1/1     Running   0          7m14s
[17:04:44] # Running command «free -m && uptime» on 192.168.1.121
        bash-4.4# free -m && uptime
                      total        used        free      shared  buff/cache   available
        Mem:           2928         265         541           0        2121        2514
        Swap:          3943           0        3943
         15:04:41 up 34 min,  load average: 0.38, 0.45, 0.58
[17:04:49] # Running command «free -m && uptime» on 95.216.208.159
        wire@arthur-demo:~$ free -m && uptime
                      total        used        free      shared  buff/cache   available
        Mem:          15661        4948        3819           2        6893       10657
        Swap:             0           0           0
         17:04:46 up 42 min,  0 users,  load average: 1.34, 1.06, 0.60
[17:04:55] # Running command «ls -l» on 192.168.1.121
        bash-4.4# ls -l
        total 120
        -rw-rw-r--  1 1000 1000 2752 Aug 12 14:38 Makefile
        -rw-rw-r--  1 1000 1000 8198 Aug 12 14:38 README.md
        -rw-rw-r--  1 1000 1000  477 Aug 12 14:38 admin_users.yml
        -rw-rw-r--  1 1000 1000  382 Aug 12 14:38 ansible.cfg
        -rw-rw-r--  1 1000 1000   75 Aug 12 14:38 bootstrap.yml
        -rw-rw-r--  1 1000 1000  511 Aug 12 14:38 cassandra-verify-ntp.yml
        -rw-rw-r--  1 1000 1000  918 Aug 12 14:38 cassandra.yml
        -rw-rw-r--  1 1000 1000 3068 Aug 12 14:38 elasticsearch.yml
        drwxrwxr-x  3 1000 1000 4096 Aug 12 14:38 files
        -rw-rw-r--  1 1000 1000 1086 Aug 12 14:38 get-logs.yml
        -rw-rw-r--  1 1000 1000 1266 Aug 12 14:38 helm_external.yml
        drwxrwxr-x  3 1000 1000 4096 Aug 12 14:38 host_vars
        drwxrwxr-x  5 1000 1000 4096 Aug 12 14:57 inventory
        -rw-rw-r--  1 1000 1000  689 Aug 12 14:38 iptables.yml
        -rw-rw-r--  1 1000 1000 1762 Aug 12 14:38 kube-minio-static-files.yml
        -rw-rw-r--  1 1000 1000 1332 Aug 12 14:38 kubernetes.yml
        -rw-rw-r--  1 1000 1000  821 Aug 12 14:38 kubernetes_logging.yml
        -rw-rw-r--  1 1000 1000 2767 Aug 12 14:38 minio.yml
        -rw-rw-r--  1 1000 1000 1552 Aug 12 14:38 provision-sft.yml
        -rw-rw-r--  1 1000 1000 3241 Aug 12 14:38 registry.yml
        -rw-rw-r--  1 1000 1000  821 Aug 12 14:38 restund.yml
        drwxrwxr-x  4 1000 1000 4096 Aug 12 14:38 roles
        drwxrwxr-x 18 1000 1000 4096 Aug 12 14:38 roles-external
        -rw-rw-r--  1 1000 1000  947 Aug 12 14:38 seed-offline-docker.yml
        -rw-rw-r--  1 1000 1000 1928 Aug 12 14:38 setup-offline-sources.yml
        drwxrwxr-x  2 1000 1000 4096 Aug 12 14:38 tasks
        drwxrwxr-x  2 1000 1000 4096 Aug 12 14:38 templates
        -rw-rw-r--  1 1000 1000 1098 Aug 12 14:38 tinc.yml
[17:05:01] # Running command «pwd» on 192.168.1.121
        bash-4.4# pwd
        /wire-server-deploy/ansible
[17:05:06] # Running command «cd ~/wire-server-deploy» on 192.168.1.121
        bash-4.4# cd ~/wire-server-deploy
        bash: cd: /root/wire-server-deploy: No such file or directory
[17:05:12] # Running command «ls -l» on 192.168.1.121
        bash-4.4# ls -l
        total 120
        -rw-rw-r--  1 1000 1000 2752 Aug 12 14:38 Makefile
        -rw-rw-r--  1 1000 1000 8198 Aug 12 14:38 README.md
        -rw-rw-r--  1 1000 1000  477 Aug 12 14:38 admin_users.yml
        -rw-rw-r--  1 1000 1000  382 Aug 12 14:38 ansible.cfg
        -rw-rw-r--  1 1000 1000   75 Aug 12 14:38 bootstrap.yml
        -rw-rw-r--  1 1000 1000  511 Aug 12 14:38 cassandra-verify-ntp.yml
        -rw-rw-r--  1 1000 1000  918 Aug 12 14:38 cassandra.yml
        -rw-rw-r--  1 1000 1000 3068 Aug 12 14:38 elasticsearch.yml
        drwxrwxr-x  3 1000 1000 4096 Aug 12 14:38 files
        -rw-rw-r--  1 1000 1000 1086 Aug 12 14:38 get-logs.yml
        -rw-rw-r--  1 1000 1000 1266 Aug 12 14:38 helm_external.yml
        drwxrwxr-x  3 1000 1000 4096 Aug 12 14:38 host_vars
        drwxrwxr-x  5 1000 1000 4096 Aug 12 14:57 inventory
        -rw-rw-r--  1 1000 1000  689 Aug 12 14:38 iptables.yml
        -rw-rw-r--  1 1000 1000 1762 Aug 12 14:38 kube-minio-static-files.yml
        -rw-rw-r--  1 1000 1000 1332 Aug 12 14:38 kubernetes.yml
        -rw-rw-r--  1 1000 1000  821 Aug 12 14:38 kubernetes_logging.yml
        -rw-rw-r--  1 1000 1000 2767 Aug 12 14:38 minio.yml
        -rw-rw-r--  1 1000 1000 1552 Aug 12 14:38 provision-sft.yml
        -rw-rw-r--  1 1000 1000 3241 Aug 12 14:38 registry.yml
        -rw-rw-r--  1 1000 1000  821 Aug 12 14:38 restund.yml
        drwxrwxr-x  4 1000 1000 4096 Aug 12 14:38 roles
        drwxrwxr-x 18 1000 1000 4096 Aug 12 14:38 roles-external
        -rw-rw-r--  1 1000 1000  947 Aug 12 14:38 seed-offline-docker.yml
        -rw-rw-r--  1 1000 1000 1928 Aug 12 14:38 setup-offline-sources.yml
        drwxrwxr-x  2 1000 1000 4096 Aug 12 14:38 tasks
        drwxrwxr-x  2 1000 1000 4096 Aug 12 14:38 templates
        -rw-rw-r--  1 1000 1000 1098 Aug 12 14:38 tinc.yml
[17:05:18] # Running command «pwd» on 192.168.1.121
        bash-4.4# pwd
        /wire-server-deploy/ansible
[17:05:24] # Running command «cd wire-server/» on 192.168.1.121
        bash-4.4# cd wire-server/
        bash: cd: wire-server/: No such file or directory
[17:05:30] # Running command «ls -l» on 192.168.1.121
        bash-4.4# ls -l
        total 120
        -rw-rw-r--  1 1000 1000 2752 Aug 12 14:38 Makefile
        -rw-rw-r--  1 1000 1000 8198 Aug 12 14:38 README.md
        -rw-rw-r--  1 1000 1000  477 Aug 12 14:38 admin_users.yml
        -rw-rw-r--  1 1000 1000  382 Aug 12 14:38 ansible.cfg
        -rw-rw-r--  1 1000 1000   75 Aug 12 14:38 bootstrap.yml
        -rw-rw-r--  1 1000 1000  511 Aug 12 14:38 cassandra-verify-ntp.yml
        -rw-rw-r--  1 1000 1000  918 Aug 12 14:38 cassandra.yml
        -rw-rw-r--  1 1000 1000 3068 Aug 12 14:38 elasticsearch.yml
        drwxrwxr-x  3 1000 1000 4096 Aug 12 14:38 files
        -rw-rw-r--  1 1000 1000 1086 Aug 12 14:38 get-logs.yml
        -rw-rw-r--  1 1000 1000 1266 Aug 12 14:38 helm_external.yml
        drwxrwxr-x  3 1000 1000 4096 Aug 12 14:38 host_vars
        drwxrwxr-x  5 1000 1000 4096 Aug 12 14:57 inventory
        -rw-rw-r--  1 1000 1000  689 Aug 12 14:38 iptables.yml
        -rw-rw-r--  1 1000 1000 1762 Aug 12 14:38 kube-minio-static-files.yml
        -rw-rw-r--  1 1000 1000 1332 Aug 12 14:38 kubernetes.yml
        -rw-rw-r--  1 1000 1000  821 Aug 12 14:38 kubernetes_logging.yml
        -rw-rw-r--  1 1000 1000 2767 Aug 12 14:38 minio.yml
        -rw-rw-r--  1 1000 1000 1552 Aug 12 14:38 provision-sft.yml
        -rw-rw-r--  1 1000 1000 3241 Aug 12 14:38 registry.yml
        -rw-rw-r--  1 1000 1000  821 Aug 12 14:38 restund.yml
        drwxrwxr-x  4 1000 1000 4096 Aug 12 14:38 roles
        drwxrwxr-x 18 1000 1000 4096 Aug 12 14:38 roles-external
        -rw-rw-r--  1 1000 1000  947 Aug 12 14:38 seed-offline-docker.yml
        -rw-rw-r--  1 1000 1000 1928 Aug 12 14:38 setup-offline-sources.yml
        drwxrwxr-x  2 1000 1000 4096 Aug 12 14:38 tasks
        drwxrwxr-x  2 1000 1000 4096 Aug 12 14:38 templates
        -rw-rw-r--  1 1000 1000 1098 Aug 12 14:38 tinc.yml
[17:05:36] # Running command «pwd» on 192.168.1.121
        bash-4.4# pwd
        /wire-server-deploy/ansible
[17:05:44] # Running command «helm upgrade --install wire-server wire/wire-server -f values.yaml -f secrets.yaml --wait --debug» on 192.168.1.121
        bash-4.4# helm upgrade --install wire-server wire/wire-server -f values.yaml -f secrets.yaml --wait --debug
        history.go:56: [debug] getting history for release wire-server
        Release "wire-server" does not exist. Installing it now.
        install.go:173: [debug] Original chart version: ""
        install.go:190: [debug] CHART PATH: /root/.cache/helm/repository/wire-server-2.111.0.tgz
        
        Error: open values.yaml: no such file or directory
        helm.go:81: [debug] open values.yaml: no such file or directory
[17:05:50] # Running command «cd ~/wire-server-deploy» on 192.168.1.121
        bash-4.4# cd ~/wire-server-deploy
        bash: cd: /root/wire-server-deploy: No such file or directory
